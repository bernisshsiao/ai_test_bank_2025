<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <title>iPAS AI應用規劃師 經典題庫 - L23101 機率統計在機器學習中的應用</title>
    <style>
        /* RWD設定，讓整體版面在不同裝置都有良好顯示 */
        * {
            box-sizing: border-box;
        }
        body {
            margin: 0;
            padding: 0;
            font-family: "Microsoft JhengHei", sans-serif;
            background: #f5f5f5;
            /* Changed default text color to black */
            color: #000000;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #ffffff;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        h1, h2 {
            text-align: center;
            margin-bottom: 10px;
        }
        h1 {
            margin-top: 20px;
            font-size: 1.8rem;
            color: #2c3e50;
        }
        .header-container {
            background: linear-gradient(135deg, #3498db, #2c3e50);
            color: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 5px;
            text-align: center;
        }
        .header-container h1 {
            margin: 0;
            color: white;
            font-size: 2rem;
        }
        /* 出題方向區塊樣式 */
        .directions-container {
            background-color: #fffbeb;
            padding: 15px;
            margin-bottom: 20px;
            border-left: 5px solid #f1c40f;
            border-radius: 5px;
        }
        .directions-title {
            font-size: 1.2rem;
            font-weight: bold;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        .directions-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
            gap: 10px;
        }
        .direction-item {
            display: flex;
            align-items: center;
            padding: 10px;
            background-color: white;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        .direction-item:hover {
            background-color: #f1c40f;
            color: white;
        }
        .direction-number {
            width: 25px;
            height: 25px;
            background-color: #f1c40f;
            color: white;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            margin-right: 10px;
            font-weight: bold;
        }
        .direction-item:hover .direction-number {
            background-color: white;
            color: #f1c40f;
        }
        /* 問題卡片樣式 */
        .questions-container {
            display: grid;
            grid-template-columns: 1fr;
            gap: 20px;
        }
        .question-card {
            background-color: white;
            border-radius: 5px;
            padding: 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            transition: transform 0.3s;
        }
        .question-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        .question-header {
            display: flex;
            justify-content: space-between;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 1px solid #eee;
        }
        .question-id {
            font-weight: bold;
            color: #3498db;
        }
        .question-frequency { /* Renamed from importance for consistency */
            color: #e74c3c;
            font-weight: bold;
        }
        .question-content {
            font-size: 1.1rem;
            margin-bottom: 15px;
            line-height: 1.6; /* Increased */
        }
        .options-container {
            display: grid;
            grid-template-columns: 1fr;
            gap: 10px;
            margin-bottom: 20px;
        }
        .option-item {
            display: flex;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
            align-items: flex-start; /* Align items to the start */
        }
        .option-item:hover {
            background-color: #e9ecef;
        }
        .option-item.correct {
            background-color: #d4edda;
            border-left: 5px solid #28a745;
        }
        .option-item.correct:hover {
            background-color: #c3e6cb;
        }
        .option-label {
            width: 25px;
            height: 25px;
            background-color: #3498db;
            color: white;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            margin-right: 10px;
            font-weight: bold;
            flex-shrink: 0; /* Prevent label from shrinking */
        }
        .option-item.correct .option-label {
            background-color: #28a745;
        }
        .option-text {
             line-height: 1.6; /* Increased */
         }
        .explanation-container {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin-top: 10px;
            display: block; /* Initially shown */
        }
        .explanation-header {
            font-weight: bold;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        .explanation-content {
            line-height: 1.7; /* Increased further */
        }
        /* 控制區塊樣式 */
        .controls {
            display: flex;
            justify-content: space-between;
            margin-bottom: 20px;
            flex-wrap: wrap;
            gap: 10px; /* Add gap for better spacing */
        }
        .filter-container, .search-container, .star-filter-container { /* Added star filter container */
            margin-bottom: 10px;
            display: flex; /* Align items nicely */
            align-items: center; /* Vertically align */
        }
        .filter-label, .search-label, .star-filter-label { /* Added star filter label */
            font-weight: bold;
            margin-right: 10px;
            white-space: nowrap; /* Prevent label wrapping */
        }
        select, input[type="text"] {
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 5px;
            font-family: inherit;
            flex-grow: 1; /* Allow input/select to grow */
            min-width: 150px; /* Ensure minimum width */
        }
         input[type="text"] {
            flex-grow: 2; /* Allow search input to be wider */
         }
        button {
            padding: 8px 15px;
            background-color: #3498db;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-family: inherit;
            transition: background-color 0.3s;
            margin-left: 5px; /* Add margin for buttons */
        }
        button:hover {
            background-color: #2980b9;
        }
        /* RWD調整 */
        @media (max-width: 992px) { /* Adjust breakpoint */
             .controls {
                flex-direction: column;
                align-items: stretch; /* Make items full width */
            }
            .filter-container, .search-container, .star-filter-container {
                width: 100%;
            }
             select, input[type="text"] {
                 width: auto; /* Reset width */
                 flex-grow: 1; /* Allow growth */
             }
        }
        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            .directions-grid {
                grid-template-columns: 1fr;
            }
        }
        /* 顯示/隱藏解析的按鈕 */
        .toggle-explanations {
            margin-bottom: 10px; /* Adjusted margin */
            display: flex; /* Align button */
            align-items: center; /* Vertically align */
        }
        /* 返回頂部按鈕 */
        .back-to-top {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background-color: #3498db;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: none; /* Hidden by default */
            justify-content: center;
            align-items: center;
            cursor: pointer;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            transition: background-color 0.3s, opacity 0.3s;
            z-index: 1000;
            opacity: 0.7;
        }
        .back-to-top:hover {
            background-color: #2980b9;
            opacity: 1;
        }
        /* 進度指示器 */
        .progress-container {
            width: 100%;
            height: 5px;
            background-color: #f1f1f1;
            position: fixed;
            top: 0;
            left: 0;
            z-index: 1001;
        }
        .progress-bar {
            height: 5px;
            background-color: #3498db;
            width: 0%;
        }
         /* Message for no results */
         #noResultsMessage {
             display: none; /* Hidden by default */
             text-align: center;
             padding: 20px;
             color: #777;
             font-size: 1.1rem;
             margin-top: 20px;
             background-color: #f9f9f9;
             border-radius: 5px;
         }
    </style>
</head>
<body>
    <div class="progress-container">
        <div class="progress-bar" id="progressBar"></div>
    </div>

    <div class="container">
        <div class="header-container">
            <h1>iPAS AI應用規劃師 經典題庫</h1>
            <div>L23101 機率統計在機器學習中的應用</div>
        </div>

        <div class="controls">
            <div class="filter-container">
                <label for="directionFilter" class="filter-label">篩選出題方向：</label>
                <select id="directionFilter">
                    <option value="all">全部方向</option>
                    <option value="1">基本機率概念與定理</option>
                    <option value="2">常用機率分佈</option>
                    <option value="3">統計推斷：估計與假設檢定</option>
                    <option value="4">貝氏定理與貝氏推斷</option>
                    <option value="5">最大概似估計 (MLE)</option>
                    <option value="6">資訊理論基礎</option>
                    <option value="7">統計學在模型評估與選擇中的應用</option>
                    <option value="8">機率統計於特定ML模型之應用</option>
                </select>
            </div>

            <div class="star-filter-container">
                <label for="starFilter" class="star-filter-label">篩選重要性：</label>
                <select id="starFilter">
                    <option value="all">全部重要性</option>
                    <option value="5">★★★★★</option>
                    <option value="4">★★★★</option>
                    <option value="3">★★★</option>
                    <option value="2">★★</option>
                    <option value="1">★</option>
                </select>
            </div>

            <div class="search-container">
                <label for="searchInput" class="search-label">搜尋：</label>
                <input type="text" id="searchInput" placeholder="輸入關鍵字...">
                <button id="searchButton">搜尋</button>
            </div>

                         <div class="toggle-explanations">
                 <button id="toggleExplanations">顯示/隱藏全部解析</button>
                 <button id="toggleAnswers">隱藏全部解答</button>
             </div>
        </div>

        <div class="directions-container">
            <div class="directions-title">出題方向</div>
            <div class="directions-grid" id="directionsGrid">
                 <div class="direction-item" onclick="filterByDirection(1)">
                     <div class="direction-number">1</div>
                     <div class="direction-text">基本機率概念與定理</div>
                 </div>
                 <div class="direction-item" onclick="filterByDirection(2)">
                     <div class="direction-number">2</div>
                     <div class="direction-text">常用機率分佈</div>
                 </div>
                 <div class="direction-item" onclick="filterByDirection(3)">
                     <div class="direction-number">3</div>
                     <div class="direction-text">統計推斷：估計與假設檢定</div>
                 </div>
                 <div class="direction-item" onclick="filterByDirection(4)">
                     <div class="direction-number">4</div>
                     <div class="direction-text">貝氏定理與貝氏推斷</div>
                 </div>
                  <div class="direction-item" onclick="filterByDirection(5)">
                     <div class="direction-number">5</div>
                     <div class="direction-text">最大概似估計 (MLE)</div>
                 </div>
                 <div class="direction-item" onclick="filterByDirection(6)">
                     <div class="direction-number">6</div>
                     <div class="direction-text">資訊理論基礎</div>
                 </div>
                 <div class="direction-item" onclick="filterByDirection(7)">
                     <div class="direction-number">7</div>
                     <div class="direction-text">統計學在模型評估與選擇中的應用</div>
                 </div>
                 <div class="direction-item" onclick="filterByDirection(8)">
                     <div class="direction-number">8</div>
                     <div class="direction-text">機率統計於特定ML模型之應用</div>
                 </div>
            </div>
        </div>

        <div class="questions-container" id="questionsContainer">

            <!-- Question 1 -->
            <div class="question-card" data-direction="1" data-stars="5">
                <div class="question-header">
                    <div class="question-id">#1</div>
                    <div class="question-frequency">★★★★★</div>
                </div>
                <div class="question-content"><strong style="color: blue;">條件機率</strong> <strong style="color: purple;">P(A|B)</strong> 的定義是什麼？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">事件 A 發生的<strong style="color: blue;">機率</strong></div>
                    </div>
                    <div class="option-item " data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text">事件 B 發生的<strong style="color: blue;">機率</strong></div>
                    </div>
                     <div class="option-item correct" data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text">在<strong style="background-color: #ffff0030;">事件 B 已經發生的條件下</strong>，事件 A 發生的<strong style="color: blue;">機率</strong></div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">事件 A 和事件 B 同時發生的<strong style="color: blue;">機率</strong></div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">
                        <strong style="color: blue;">條件機率</strong> <strong style="color: purple;">P(A|B)</strong> 是<strong style="color: blue;">機率論</strong>中的基本概念，讀作「在B發生的條件下A的機率」。它衡量的是當我們已知事件 B 已經發生時，事件 A 發生的可能性。其數學定義為 <strong style="color: purple;">P(A|B) = P(A∩B) / P(B)</strong>，其中 <strong style="color: purple;">P(A∩B)</strong> 是 A 和 B 同時發生的<strong style="color: blue;">機率</strong>（<strong style="color: blue;">聯合機率</strong>），<strong style="color: purple;">P(B)</strong> 是 B 發生的<strong style="color: blue;">機率</strong>（<strong style="color: blue;">邊際機率</strong>），且 <strong style="color: purple;">P(B)</strong> > 0。<strong style="color: blue;">條件機率</strong>在<strong style="color: blue;">機器學習</strong>中廣泛應用，例如在<strong style="color: blue;">貝氏分類器</strong>、<strong style="color: blue;">機率圖模型</strong>等。
                    </div>
                </div>
            </div>

            <!-- Question 2 -->
            <div class="question-card" data-direction="2" data-stars="4">
                <div class="question-header">
                    <div class="question-id">#2</div>
                    <div class="question-frequency">★★★★</div>
                </div>
                <div class="question-content">在<strong style="color: blue;">機器學習</strong>中，常用來描述<strong style="color: blue;">連續型隨機變數</strong>（例如，身高、體重、溫度）的<strong style="color: blue;">機率分佈</strong>是？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text"><strong style="color: blue;">柏努力分佈</strong>（<strong style="color: red;">Bernoulli Distribution</strong>）</div>
                    </div>
                    <div class="option-item " data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><strong style="color: blue;">二項式分佈</strong>（<strong style="color: red;">Binomial Distribution</strong>）</div>
                    </div>
                    <div class="option-item correct" data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text"><strong style="color: blue;">常態分佈</strong>（<strong style="color: red;">Normal Distribution</strong>）或稱<strong style="color: blue;">高斯分佈</strong>（<strong style="color: red;">Gaussian Distribution</strong>）</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text"><strong style="color: blue;">泊松分佈</strong>（<strong style="color: red;">Poisson Distribution</strong>）</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">
                        <strong style="color: blue;">常態分佈</strong>（<strong style="color: blue;">高斯分佈</strong>）是描述<strong style="background-color: #ffff0030;">連續型隨機變數</strong>最常用和最重要的<strong style="color: blue;">機率分佈</strong>之一。它的<strong style="color: blue;">機率密度函數</strong>呈現<strong style="background-color: #ffff0030;">鐘形曲線</strong>，由<strong style="color: blue;">平均值</strong>（μ）和<strong style="color: blue;">標準差</strong>（σ）兩個參數決定。許多自然現象和測量誤差都近似服從<strong style="color: blue;">常態分佈</strong>（依據<strong style="color: blue;">中央極限定理</strong>）。在<strong style="color: blue;">機器學習</strong>中，<strong style="color: blue;">常態分佈</strong>常用於假設數據分佈（如<strong style="color: blue;">高斯混合模型</strong> <strong style="color: purple;">GMM</strong>）、模型<strong style="color: blue;">噪聲</strong>（如<strong style="color: blue;">線性回歸</strong>中的誤差項）或作為參數的<strong style="color: blue;">先驗分佈</strong>（如<strong style="color: blue;">貝氏線性回歸</strong>）。<strong style="color: blue;">柏努力分佈</strong>描述單次試驗成功或失敗，<strong style="color: blue;">二項式分佈</strong>描述n次獨立<strong style="color: blue;">柏努力試驗</strong>的成功次數，<strong style="color: blue;">泊松分佈</strong>描述單位時間或空間內事件發生的次數，這些通常用於<strong style="color: blue;">離散型變數</strong>。
                    </div>
                </div>
            </div>

            <!-- Question 3 -->
            <div class="question-card" data-direction="3" data-stars="4">
                <div class="question-header">
                    <div class="question-id">#3</div>
                    <div class="question-frequency">★★★★</div>
                </div>
                <div class="question-content">在<strong style="color: blue;">假設檢定</strong>（<strong style="color: red;">Hypothesis Testing</strong>）中，<strong style="color: purple;">P</strong>值（<strong style="color: red;">P-value</strong>）代表什麼意義？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text"><strong style="color: blue;">虛無假設</strong>（<strong style="color: red;">Null Hypothesis</strong>, <strong style="color: purple;">H0</strong>）為真的<strong style="color: blue;">機率</strong>。</div>
                    </div>
                    <div class="option-item correct" data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text">在<strong style="color: blue;">虛無假設</strong>為真的前提下，<strong style="background-color: #ffff0030;">觀察到當前樣本結果或更極端結果的機率</strong>。</div>
                    </div>
                     <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text"><strong style="color: blue;">對立假設</strong>（<strong style="color: red;">Alternative Hypothesis</strong>, <strong style="color: purple;">H1</strong>）為真的<strong style="color: blue;">機率</strong>。</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">犯<strong style="color: blue;">第一型錯誤</strong>（<strong style="color: red;">Type I Error</strong>）的<strong style="color: blue;">機率</strong>上限，即<strong style="color: blue;">顯著水準</strong>（<strong style="color: red;">Significance Level</strong>, α）。</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">
                        <strong style="color: purple;">P</strong>值是<strong style="color: blue;">假設檢定</strong>中的一個關鍵指標。它的確切定義是：如果<strong style="color: blue;">虛無假設</strong> <strong style="color: purple;">H0</strong> 為真，那麼觀測到（或計算出）至少與當前樣本<strong style="color: blue;">統計量</strong>一樣極端或更極端的結果的<strong style="color: blue;">機率</strong>。<strong style="color: purple;">P</strong>值衡量的是樣本結果與<strong style="color: blue;">虛無假設</strong>之間的不一致程度。如果<strong style="color: purple;">P</strong>值非常小（通常小於預設的<strong style="color: blue;">顯著水準</strong>α，如0.05），則意味著在<strong style="color: purple;">H0</strong>為真的情況下，觀測到如此極端的樣本結果是非常不可能的，因此我們有強烈的證據<strong style="background-color: #ffff0030;">拒絕H0</strong>，支持<strong style="color: blue;">對立假設</strong> <strong style="color: purple;">H1</strong>。注意，<strong style="color: purple;">P</strong>值不是<strong style="color: purple;">H0</strong>為真的<strong style="color: blue;">機率</strong>（選項A），也不是<strong style="color: purple;">H1</strong>為真的<strong style="color: blue;">機率</strong>（選項C）。<strong style="color: blue;">顯著水準</strong>α是我們事先設定的、願意容忍犯<strong style="color: blue;">第一型錯誤</strong>（錯誤地拒絕真實的<strong style="color: purple;">H0</strong>）的<strong style="color: blue;">機率</strong>上限（選項D），<strong style="color: purple;">P</strong>值是用來與α比較以做出決策的。
                    </div>
                </div>
            </div>

             <!-- Question 4 -->
            <div class="question-card" data-direction="4" data-stars="5">
                 <div class="question-header">
                     <div class="question-id">#4</div>
                     <div class="question-frequency">★★★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">貝氏定理</strong>（<strong style="color: red;">Bayes' Theorem</strong>）描述了在獲得新的證據（觀察數據）後，如何更新對一個假設的信任程度（<strong style="color: blue;">機率</strong>）。其數學表達式 <strong style="color: purple;">P(H|E) = [P(E|H) * P(H)] / P(E)</strong> 中，<strong style="color: purple;">P(H)</strong> 代表什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">後驗機率</strong>（<strong style="color: red;">Posterior Probability</strong>）：觀察到證據<strong style="color: purple;">E</strong>後，假設<strong style="color: purple;">H</strong>為真的<strong style="color: blue;">機率</strong>。</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">概似度</strong>（<strong style="color: red;">Likelihood</strong>）：假設<strong style="color: purple;">H</strong>為真時，觀察到證據<strong style="color: purple;">E</strong>的<strong style="color: blue;">機率</strong>。</div></div>
                     <div class="option-item correct" data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">先驗機率</strong>（<strong style="color: red;">Prior Probability</strong>）：在觀察到任何證據之前，假設<strong style="color: purple;">H</strong>為真的<strong style="background-color: #ffff0030;">初始機率</strong>（主觀信任度）。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">證據的<strong style="color: blue;">邊際機率</strong>（<strong style="color: red;">Marginal Probability of Evidence</strong>）：觀察到證據<strong style="color: purple;">E</strong>的總<strong style="color: blue;">機率</strong>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">貝氏定理</strong>是 <strong style="color: purple;">P(H|E) = [P(E|H) * P(H)] / P(E)</strong>。其中各項的意義如下：<br>
                        <ul>
                            <li><strong style="color: purple;">P(H|E)</strong>：<strong style="color: blue;">後驗機率</strong>（<strong style="color: red;">Posterior</strong>），是我們最終關心的，即看到證據 <strong style="color: purple;">E</strong> 之後，假設 <strong style="color: purple;">H</strong> 成立的<strong style="color: blue;">機率</strong>。</li>
                            <li><strong style="color: purple;">P(E|H)</strong>：<strong style="color: blue;">概似度</strong>（<strong style="color: red;">Likelihood</strong>），表示如果假設 <strong style="color: purple;">H</strong> 成立，我們觀察到證據 <strong style="color: purple;">E</strong> 的可能性有多大。</li>
                            <li><strong style="color: purple;">P(H)</strong>：<strong style="color: blue;">先驗機率</strong>（<strong style="color: red;">Prior</strong>），表示在看到任何證據 <strong style="color: purple;">E</strong> 之前，我們對假設 <strong style="color: purple;">H</strong> 成立的<strong style="background-color: #ffff0030;">初始信念或機率</strong>。</li>
                            <li><strong style="color: purple;">P(E)</strong>：證據的<strong style="color: blue;">邊際機率</strong>（<strong style="color: red;">Evidence or Marginal Likelihood</strong>），是觀察到證據 <strong style="color: purple;">E</strong> 的總<strong style="color: blue;">機率</strong>，作為歸一化常數。</li>
                        </ul>
                        <strong style="color: blue;">貝氏定理</strong>提供了一個框架，說明如何結合<strong style="color: blue;">先驗知識</strong>（<strong style="color: purple;">P(H)</strong>）和新的數據證據（通過<strong style="color: blue;">概似度</strong> <strong style="color: purple;">P(E|H)</strong>體現）來更新我們的信念，得到<strong style="color: blue;">後驗機率</strong>（<strong style="color: purple;">P(H|E)</strong>）。這在<strong style="color: blue;">貝氏統計</strong>和許多<strong style="color: blue;">機器學習模型</strong>（如<strong style="color: blue;">樸素貝氏分類器</strong>、<strong style="color: blue;">貝氏網路</strong>）中是核心思想。
                    </div>
                 </div>
             </div>

            <!-- Question 5 -->
            <div class="question-card" data-direction="5" data-stars="5">
                 <div class="question-header">
                     <div class="question-id">#5</div>
                     <div class="question-frequency">★★★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">最大概似估計</strong>（<strong style="color: red;">Maximum Likelihood Estimation</strong>, <strong style="color: purple;">MLE</strong>）是一種常用的<strong style="color: blue;">參數估計</strong>方法。其基本思想是？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">選擇使<strong style="color: blue;">先驗機率</strong>最大化的參數值。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">選擇使<strong style="background-color: #ffff0030;">觀測到的數據樣本出現的機率</strong>（<strong style="color: blue;">概似度</strong>）<strong style="background-color: #ffff0030;">最大化</strong>的參數值。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">選擇使<strong style="color: blue;">後驗機率</strong>最大化的參數值（這是<strong style="color: blue;">最大後驗估計</strong> <strong style="color: purple;">MAP</strong>）。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">選擇使模型預測誤差最小化的參數值（這更接近<strong style="color: blue;">損失函數</strong>最小化）。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: purple;">MLE</strong> 的核心思想是：我們已經觀測到了一組數據樣本 <strong style="color: purple;">D</strong>，我們想要找到一組模型參數 <strong style="color: purple;">θ</strong>，使得在該參數 <strong style="color: purple;">θ</strong> 下，觀測到這組數據 <strong style="color: purple;">D</strong> 的<strong style="color: blue;">機率</strong>（即<strong style="color: blue;">概似函數</strong> <strong style="color: purple;">L(θ|D) = P(D|θ)</strong>）達到<strong style="background-color: #ffff0030;">最大</strong>。換句話說，<strong style="color: purple;">MLE</strong> 尋找的參數 <strong style="color: purple;">θ</strong> 是最能「解釋」或「擬合」我們所觀測到的數據的參數。許多<strong style="color: blue;">機器學習模型</strong>的<strong style="color: blue;">參數估計</strong>都基於<strong style="color: purple;">MLE</strong>原理，例如<strong style="color: blue;">線性回歸</strong>（假設誤差為高斯分佈時）、<strong style="color: blue;">邏輯回歸</strong>等。<strong style="color: blue;">最大後驗估計</strong>（<strong style="color: purple;">MAP</strong>）則是在<strong style="color: purple;">MLE</strong>的基礎上，額外考慮了參數的<strong style="color: blue;">先驗分佈</strong>，尋找使<strong style="color: blue;">後驗機率</strong> <strong style="color: purple;">P(θ|D) ∝ P(D|θ)P(θ)</strong> 最大化的參數。
                    </div>
                 </div>
             </div>

            <!-- Question 6 -->
            <div class="question-card" data-direction="6" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#6</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">資訊理論</strong>中，<strong style="color: blue;">熵</strong>（<strong style="color: red;">Entropy</strong>）衡量的是一個<strong style="color: blue;">隨機變數</strong>的什麼特性？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">平均值</strong>（<strong style="color: red;">Mean</strong>）</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="background-color: #ffff0030;">不確定性</strong>（<strong style="color: red;">Uncertainty</strong>）或<strong style="background-color: #ffff0030;">資訊量</strong>（<strong style="color: red;">Amount of Information</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">變異數</strong>（<strong style="color: red;">Variance</strong>）</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">與另一個<strong style="color: blue;">變數</strong>的<strong style="color: blue;">相關性</strong>（<strong style="color: red;">Correlation</strong>）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">熵</strong>（通常用 <strong style="color: purple;">H(X)</strong> 表示）是<strong style="color: blue;">資訊理論</strong>中的核心概念，用於量化一個<strong style="color: blue;">隨機變數</strong> <strong style="color: purple;">X</strong> 的<strong style="background-color: #ffff0030;">不確定性程度</strong>。<strong style="color: blue;">熵</strong>越高，表示該<strong style="color: blue;">變數</strong>的取值越不確定，或者說，要確定該<strong style="color: blue;">變數</strong>的具體取值所需要的平均<strong style="color: blue;">資訊量</strong>越大。對於一個<strong style="color: blue;">離散隨機變數</strong> <strong style="color: purple;">X</strong>，其<strong style="color: blue;">熵</strong>定義為 <strong style="color: purple;">H(X) = -Σ [P(x) * log(P(x))]</strong>，其中 <strong style="color: purple;">P(x)</strong> 是 <strong style="color: purple;">X</strong> 取值為 <strong style="color: purple;">x</strong> 的<strong style="color: blue;">機率</strong>，<strong style="color: red;">log</strong> 通常以2為底（單位是<strong style="color: blue;">位元</strong> <strong style="color: red;">bits</strong>）。當所有取值的<strong style="color: blue;">機率</strong>都相等時（即最不確定的情況），<strong style="color: blue;">熵</strong>達到最大值。當某個取值的<strong style="color: blue;">機率</strong>為1（即完全確定的情況）時，<strong style="color: blue;">熵</strong>為0。<strong style="color: blue;">熵</strong>的概念在<strong style="color: blue;">機器學習</strong>中有多種應用，如<strong style="color: blue;">決策樹</strong>中的<strong style="color: blue;">信息增益</strong>、<strong style="color: blue;">交叉熵損失函數</strong>等。
                    </div>
                 </div>
             </div>

            <!-- Question 7 -->
            <div class="question-card" data-direction="7" data-stars="5">
                <div class="question-header">
                    <div class="question-id">#7</div>
                    <div class="question-frequency">★★★★★</div>
                </div>
                <div class="question-content">在評估<strong style="color: blue;">二元分類模型</strong>的性能時，<strong style="color: blue;">混淆矩陣</strong>（<strong style="color: red;">Confusion Matrix</strong>）包含了四個基本指標：<strong style="color: blue;">真正</strong>（<strong style="color: red;">True Positive</strong>, <strong style="color: purple;">TP</strong>）、<strong style="color: blue;">假正</strong>（<strong style="color: red;">False Positive</strong>, <strong style="color: purple;">FP</strong>）、<strong style="color: blue;">真負</strong>（<strong style="color: red;">True Negative</strong>, <strong style="color: purple;">TN</strong>）、<strong style="color: blue;">假負</strong>（<strong style="color: red;">False Negative</strong>, <strong style="color: purple;">FN</strong>）。<strong style="color: blue;">召回率</strong>（<strong style="color: red;">Recall</strong>）或稱<strong style="color: blue;">敏感度</strong>（<strong style="color: red;">Sensitivity</strong>）的計算公式是？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">(<strong style="color: purple;">TP</strong> + <strong style="color: purple;">TN</strong>) / (<strong style="color: purple;">TP</strong> + <strong style="color: purple;">FP</strong> + <strong style="color: purple;">TN</strong> + <strong style="color: purple;">FN</strong>) （<strong style="color: blue;">準確率</strong> <strong style="color: red;">Accuracy</strong>）</div>
                    </div>
                    <div class="option-item " data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><strong style="color: purple;">TP</strong> / (<strong style="color: purple;">TP</strong> + <strong style="color: purple;">FP</strong>) （<strong style="color: blue;">精確率</strong> <strong style="color: red;">Precision</strong>）</div>
                    </div>
                     <div class="option-item correct" data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text"><strong style="color: purple;">TP</strong> / (<strong style="color: purple;">TP</strong> + <strong style="color: purple;">FN</strong>) （<strong style="color: blue;">召回率</strong> <strong style="color: red;">Recall</strong> / <strong style="color: red;">Sensitivity</strong>）</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text"><strong style="color: purple;">TN</strong> / (<strong style="color: purple;">TN</strong> + <strong style="color: purple;">FP</strong>) （<strong style="color: blue;">特異度</strong> <strong style="color: red;">Specificity</strong>）</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">
                        <strong style="color: blue;">混淆矩陣</strong>是評估<strong style="color: blue;">分類模型</strong>性能的基礎。各指標定義如下：<br>
                        <ul>
                            <li><strong style="color: purple;">TP</strong>：實際為正，預測也為正。</li>
                            <li><strong style="color: purple;">FP</strong>：實際為負，預測為正（<strong style="color: blue;">第一型錯誤</strong>）。</li>
                            <li><strong style="color: purple;">TN</strong>：實際為負，預測也為負。</li>
                            <li><strong style="color: purple;">FN</strong>：實際為正，預測為負（<strong style="color: blue;">第二型錯誤</strong>）。</li>
                        </ul>
                        常用的評估指標：<br>
                        <ul>
                            <li><strong style="color: blue;">準確率</strong> (<strong style="color: red;">Accuracy</strong>) = (<strong style="color: purple;">TP</strong>+<strong style="color: purple;">TN</strong>) / Total：整體預測正確的比例。</li>
                            <li><strong style="color: blue;">精確率</strong> (<strong style="color: red;">Precision</strong>) = <strong style="color: purple;">TP</strong> / (<strong style="color: purple;">TP</strong>+<strong style="color: purple;">FP</strong>)：預測為正的樣本中，實際也為正的比例（預測得準不準？）。</li>
                            <li><b><strong style="color: blue;">召回率</strong> (<strong style="color: red;">Recall</strong>) / <strong style="color: blue;">敏感度</strong> (<strong style="color: red;">Sensitivity</strong>) = <strong style="color: purple;">TP</strong> / (<strong style="color: purple;">TP</strong>+<strong style="color: purple;">FN</strong>)</b>：<strong style="background-color: #ffff0030;">實際為正的樣本中，被模型成功預測為正的比例</strong>（找得全不全？）。</li>
                            <li><strong style="color: blue;">特異度</strong> (<strong style="color: red;">Specificity</strong>) = <strong style="color: purple;">TN</strong> / (<strong style="color: purple;">TN</strong>+<strong style="color: purple;">FP</strong>)：實際為負的樣本中，被模型成功預測為負的比例。</li>
                            <li><strong style="color: purple;">F1</strong> 分數 (<strong style="color: red;">F1 Score</strong>) = 2 * (<strong style="color: blue;">Precision</strong> * <strong style="color: blue;">Recall</strong>) / (<strong style="color: blue;">Precision</strong> + <strong style="color: blue;">Recall</strong>)：<strong style="color: blue;">精確率</strong>和<strong style="color: blue;">召回率</strong>的<strong style="color: blue;">調和平均數</strong>。</li>
                        </ul>
                        <strong style="color: blue;">召回率</strong>衡量模型找出所有正樣本的能力，在某些場景（如疾病篩檢）中非常重要。
                    </div>
                </div>
            </div>

            <!-- Question 8 -->
            <div class="question-card" data-direction="8" data-stars="4">
                <div class="question-header">
                    <div class="question-id">#8</div>
                    <div class="question-frequency">★★★★</div>
                </div>
                <div class="question-content"><strong style="color: blue;">樸素貝氏分類器</strong>（<strong style="color: red;">Naive Bayes Classifier</strong>）的核心假設是什麼？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">所有<strong style="color: blue;">特徵</strong>之間是線性相關的。</div>
                    </div>
                    <div class="option-item correct" data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text">給定類別標籤的條件下，所有<strong style="color: blue;">特徵</strong>之間是<strong style="background-color: #ffff0030;">條件獨立的</strong>（<strong style="color: red;">Conditional Independence</strong>）。</div>
                    </div>
                     <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text">所有<strong style="color: blue;">特徵</strong>都服從<strong style="color: blue;">常態分佈</strong>。</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">類別標籤的<strong style="color: blue;">先驗機率</strong>必須相等。</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">
                        <strong style="color: blue;">樸素貝氏分類器</strong>是一種基於<strong style="color: blue;">貝氏定理</strong>的簡單且高效的<strong style="color: blue;">分類</strong><strong style="color: blue;">演算法</strong>。它之所以被稱為「樸素」（<strong style="color: red;">Naive</strong>），是因為它做出了一個很強的假設：在給定樣本的類別標籤 <strong style="color: purple;">C</strong> 的條件下，樣本的各個<strong style="color: blue;">特徵</strong> <strong style="color: purple;">F1, F2, ..., Fn</strong> 之間是<strong style="background-color: #ffff0030;">相互條件獨立</strong>的。也就是說，<strong style="color: purple;">P(F1, F2, ..., Fn | C) = P(F1|C) * P(F2|C) * ... * P(Fn|C)</strong>。這個假設大大簡化了計算<strong style="color: blue;">聯合機率</strong>的複雜度，使得模型易於訓練和應用，尤其在<strong style="color: blue;">文本分類</strong>等高維度<strong style="color: blue;">特徵</strong>空間中表現良好。儘管這個獨立性假設在現實中往往不成立，但<strong style="color: blue;">樸素貝氏分類器</strong>在實務中仍然常常取得不錯的效果。
                    </div>
                </div>
            </div>

            <!-- Question 9 -->
            <div class="question-card" data-direction="3" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#9</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">統計推斷</strong>中，<strong style="color: blue;">信賴區間</strong>（<strong style="color: red;">Confidence Interval</strong>）提供的是什麼資訊？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">總體參數</strong>（<strong style="color: red;">Population Parameter</strong>）的確切值。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">一個<strong style="background-color: #ffff0030;">估計的區間</strong>，我們有一定信心（例如95%）認為<strong style="color: blue;">總體參數</strong>會落入該區間內。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">樣本統計量</strong>（<strong style="color: red;">Sample Statistic</strong>）的可能範圍。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">拒絕<strong style="color: blue;">虛無假設</strong>的<strong style="color: blue;">機率</strong>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        我們通常無法知道<strong style="color: blue;">總體參數</strong>（例如，所有用戶的平均年齡）的真實值，只能通過<strong style="color: blue;">抽樣</strong>得到樣本數據，並計算<strong style="color: blue;">樣本統計量</strong>（如樣本平均年齡）來估計<strong style="color: blue;">總體參數</strong>。<strong style="color: blue;">點估計</strong>（<strong style="color: red;">Point Estimate</strong>）只給出一個單一的估計值，而<strong style="color: blue;">信賴區間</strong>則提供了一個<strong style="background-color: #ffff0030;">區間估計</strong>。一個 95% 的<strong style="color: blue;">信賴區間</strong>意味著，如果我們重複進行<strong style="color: blue;">抽樣</strong>和構建<strong style="color: blue;">信賴區間</strong>的過程很多次，大約有 95% 的區間會包含真實的<strong style="color: blue;">總體參數</strong>。它反映了樣本估計的<strong style="background-color: #ffff0030;">不確定性程度</strong>，區間越寬表示不確定性越大。
                    </div>
                 </div>
             </div>

             <!-- Question 10 -->
            <div class="question-card" data-direction="6" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#10</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: purple;">KL</strong> <strong style="color: blue;">散度</strong>（<strong style="color: red;">Kullback-Leibler Divergence</strong>），也稱為<strong style="color: blue;">相對熵</strong>（<strong style="color: red;">Relative Entropy</strong>），主要用來衡量什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">兩個<strong style="color: blue;">隨機變數</strong>之間的線性<strong style="color: blue;">相關</strong>程度。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">兩個<strong style="color: blue;">機率分佈</strong>之間的<strong style="background-color: #ffff0030;">差異或距離</strong>（但它不是真正的距離度量，因為不對稱）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">單一<strong style="color: blue;">機率分佈</strong>的<strong style="color: blue;">不確定性</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">一個<strong style="color: blue;">變數</strong>包含關於另一個<strong style="color: blue;">變數</strong>的<strong style="color: blue;">資訊量</strong>（<strong style="color: blue;">互信息</strong> <strong style="color: red;">Mutual Information</strong>）。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: purple;">KL</strong> <strong style="color: blue;">散度</strong> <strong style="color: purple;">D_KL(P || Q)</strong> 用於衡量一個<strong style="color: blue;">機率分佈</strong> P 與另一個參考<strong style="color: blue;">機率分佈</strong> Q 之間的<strong style="background-color: #ffff0030;">差異程度</strong>。它量化了如果我們用分佈 Q 來近似分佈 P 時，會損失多少資訊。<strong style="color: purple;">KL</strong> <strong style="color: blue;">散度</strong>總是≥0，當且僅當 P 和 Q 完全相同時等於0。然而，<strong style="color: purple;">KL</strong> <strong style="color: blue;">散度</strong>不是對稱的，即 <strong style="color: purple;">D_KL(P || Q) ≠ D_KL(Q || P)</strong>，因此它不是一個嚴格意義上的距離度量。在<strong style="color: blue;">機器學習</strong>中，<strong style="color: purple;">KL</strong> <strong style="color: blue;">散度</strong>常用於：(1) <strong style="color: blue;">變分推斷</strong>（<strong style="color: red;">Variational Inference</strong>）中衡量近似<strong style="color: blue;">後驗分佈</strong>與真實<strong style="color: blue;">後驗分佈</strong>的差異。(2) 評估<strong style="color: blue;">生成模型</strong>（如<strong style="color: purple;">VAE</strong>, <strong style="color: purple;">GAN</strong>）生成的分佈與真實數據分佈的相似度。(3) 比較不同模型的輸出分佈等。單一分佈的<strong style="color: blue;">不確定性</strong>由<strong style="color: blue;">熵</strong>衡量，兩個<strong style="color: blue;">變數</strong>的<strong style="color: blue;">資訊量</strong>由<strong style="color: blue;">互信息</strong>衡量。
                    </div>
                 </div>
             </div>

             <!-- Question 11 -->
             <div class="question-card" data-direction="1" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#11</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">如果事件 A 和事件 B 是<strong style="background-color: #ffff0030;">相互獨立</strong>（<strong style="color: red;">Independent</strong>）的，那麼它們同時發生的<strong style="color: blue;">機率</strong> <strong style="color: purple;">P(A∩B)</strong> 等於？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: purple;">P(A) + P(B)</strong></div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: purple;">P(A) * P(B)</strong></div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: purple;">P(A|B)</strong></div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: purple;">P(B|A)</strong></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        事件<strong style="background-color: #ffff0030;">獨立性</strong>意味著一個事件的發生不影響另一個事件發生的<strong style="color: blue;">機率</strong>。如果 A 和 B <strong style="background-color: #ffff0030;">相互獨立</strong>，則 <strong style="color: purple;">P(A|B) = P(A)</strong> 且 <strong style="color: purple;">P(B|A) = P(B)</strong>。根據<strong style="color: blue;">條件機率</strong>的定義 <strong style="color: purple;">P(A|B) = P(A∩B) / P(B)</strong>，將 <strong style="color: purple;">P(A|B) = P(A)</strong> 代入，可得 <strong style="color: purple;">P(A) = P(A∩B) / P(B)</strong>，因此 <strong style="color: purple;">P(A∩B) = P(A) * P(B)</strong>。這是獨立事件<strong style="color: blue;">聯合機率</strong>的計算公式，在許多<strong style="color: blue;">機率模型</strong>和假設中（如<strong style="color: blue;">樸素貝氏</strong>）非常重要。
                    </div>
                 </div>
             </div>

             <!-- Question 12 -->
             <div class="question-card" data-direction="2" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#12</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">哪種<strong style="color: blue;">機率分佈</strong>常用來模擬在<strong style="background-color: #ffff0030;">固定次數</strong>的<strong style="background-color: #ffff0030;">獨立試驗</strong>中，某事件發生的<strong style="background-color: #ffff0030;">次數</strong>，且每次試驗只有<strong style="background-color: #ffff0030;">兩種可能結果</strong>（成功或失敗）且<strong style="background-color: #ffff0030;">成功機率固定</strong>？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">常態分佈</strong>（<strong style="color: red;">Normal Distribution</strong>）</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">二項式分佈</strong>（<strong style="color: red;">Binomial Distribution</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">指數分佈</strong>（<strong style="color: red;">Exponential Distribution</strong>）</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">均勻分佈</strong>（<strong style="color: red;">Uniform Distribution</strong>）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">二項式分佈</strong> <strong style="color: purple;">B(n, p)</strong> 描述了進行 <strong style="color: purple;">n</strong> 次<strong style="background-color: #ffff0030;">獨立</strong>的、<strong style="background-color: #ffff0030;">成功機率為 p</strong> 的<strong style="color: blue;">柏努力試驗</strong>（<strong style="color: red;">Bernoulli trial</strong>）中，成功事件發生的總<strong style="background-color: #ffff0030;">次數 k</strong> 的<strong style="color: blue;">機率</strong>。其<strong style="color: blue;">機率質量函數</strong>為 <strong style="color: purple;">P(X=k) = C(n, k) * p^k * (1-p)^(n-k)</strong>，其中 <strong style="color: purple;">C(n, k)</strong> 是組合數。例如，拋擲一枚不公正硬幣10次（n=10），每次正面朝上的<strong style="color: blue;">機率</strong>為0.6（p=0.6），那麼恰好出現7次正面（k=7）的<strong style="color: blue;">機率</strong>就可以用<strong style="color: blue;">二項式分佈</strong>計算。<strong style="color: blue;">二項式分佈</strong>在<strong style="color: purple;">A/B測試</strong>結果分析、品質控制等領域有應用。
                    </div>
                 </div>
             </div>

             <!-- Question 13 -->
             <div class="question-card" data-direction="3" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#13</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content">在進行<strong style="color: blue;">假設檢定</strong>時，如果我們<strong style="background-color: #ffff0030;">錯誤地拒絕了一個實際上為真的虛無假設</strong>（<strong style="color: purple;">H0</strong>），我們稱之為犯了什麼類型的錯誤？</div>
                 <div class="options-container">
                     <div class="option-item correct" data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">第一型錯誤</strong>（<strong style="color: red;">Type I Error</strong>）或<strong style="color: blue;">偽陽性</strong>（<strong style="color: red;">False Positive</strong>）</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">第二型錯誤</strong>（<strong style="color: red;">Type II Error</strong>）或<strong style="color: blue;">偽陰性</strong>（<strong style="color: red;">False Negative</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">標準誤差</strong>（<strong style="color: red;">Standard Error</strong>）</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">抽樣誤差</strong>（<strong style="color: red;">Sampling Error</strong>）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">假設檢定</strong>中可能發生兩種錯誤：<br>
                        <ul>
                            <li><b><strong style="color: blue;">第一型錯誤</strong> (<strong style="color: red;">Type I Error</strong>, α)</b>：<strong style="color: blue;">虛無假設</strong> <strong style="color: purple;">H0</strong> 本身是真的，但我們的<strong style="color: blue;">檢定</strong>結果卻<strong style="background-color: #ffff0030;">拒絕</strong>了 <strong style="color: purple;">H0</strong>（判斷為假）。發生這種錯誤的<strong style="color: blue;">機率</strong>通常用 <strong style="color: purple;">α</strong> 表示，即<strong style="color: blue;">顯著水準</strong>。也稱為<strong style="color: blue;">偽陽性</strong>（<strong style="color: red;">False Positive</strong>）。</li>
                            <li><strong style="color: blue;">第二型錯誤</strong> (<strong style="color: red;">Type II Error</strong>, β)：<strong style="color: blue;">虛無假設</strong> <strong style="color: purple;">H0</strong> 本身是假的（即<strong style="color: blue;">對立假設</strong> <strong style="color: purple;">H1</strong> 為真），但我們的<strong style="color: blue;">檢定</strong>結果卻<strong style="background-color: #ffff0030;">未能拒絕</strong> <strong style="color: purple;">H0</strong>（判斷為真）。發生這種錯誤的<strong style="color: blue;">機率</strong>用 <strong style="color: purple;">β</strong> 表示。也稱為<strong style="color: blue;">偽陰性</strong>（<strong style="color: red;">False Negative</strong>）。<strong style="color: blue;">檢定力</strong>（<strong style="color: red;">Power</strong>）定義為 1-β，即正確拒絕錯誤的<strong style="color: purple;">H0</strong>的<strong style="color: blue;">機率</strong>。</li>
                        </ul>
                        在<strong style="color: blue;">假設檢定</strong>中，我們通常會控制犯<strong style="color: blue;">第一型錯誤</strong>的<strong style="color: blue;">機率</strong> <strong style="color: purple;">α</strong>（例如設定為0.05），並希望盡可能降低犯<strong style="color: blue;">第二型錯誤</strong>的<strong style="color: blue;">機率</strong> <strong style="color: purple;">β</strong>（即提高<strong style="color: blue;">檢定力</strong>）。
                    </div>
                 </div>
             </div>

            <!-- Question 14 -->
            <div class="question-card" data-direction="4" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#14</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">貝氏推斷</strong>（<strong style="color: red;">Bayesian Inference</strong>）與<strong style="color: blue;">頻率學派推斷</strong>（<strong style="color: red;">Frequentist Inference</strong>）的主要區別在於<strong style="color: blue;">貝氏推斷</strong>如何看待模型參數？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">貝氏推斷</strong>認為參數是未知的常數，<strong style="color: blue;">頻率學派</strong>認為參數是<strong style="color: blue;">隨機變數</strong>。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">貝氏推斷</strong>將模型參數視為具有<strong style="color: blue;">機率分佈</strong>（<strong style="color: blue;">先驗分佈</strong>和<strong style="color: blue;">後驗分佈</strong>）的<strong style="color: blue;">隨機變數</strong>，而<strong style="color: blue;">頻率學派</strong>通常將參數視為<strong style="background-color: #ffff0030;">未知的固定常數</strong>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">貝氏推斷</strong>不使用<strong style="color: blue;">機率</strong>，<strong style="color: blue;">頻率學派</strong>使用<strong style="color: blue;">機率</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">兩者沒有本質區別。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        這是<strong style="color: blue;">貝氏學派</strong>和<strong style="color: blue;">頻率學派</strong>觀點的一個核心差異。<strong style="color: blue;">頻率學派</strong>認為，<strong style="color: blue;">總體參數</strong>是一個<strong style="background-color: #ffff0030;">固定但未知的值</strong>，而數據是隨機抽樣的結果，<strong style="color: blue;">機率</strong>描述的是在多次重複實驗中事件發生的頻率。因此，<strong style="color: blue;">頻率學派</strong>的<strong style="color: blue;">推斷</strong>（如<strong style="color: blue;">信賴區間</strong>、<strong style="color: purple;">P</strong>值）是關於數據的，而不是關於參數本身的<strong style="color: blue;">機率</strong>。相比之下，<strong style="color: blue;">貝氏學派</strong>認為參數也是不確定的，可以用<strong style="color: blue;">機率分佈</strong>來描述我們對其的信念。我們有一個關於參數的<strong style="color: blue;">先驗分佈</strong>（代表初始信念），然後根據觀測到的數據，利用<strong style="color: blue;">貝氏定理</strong>更新這個信念，得到參數的<strong style="color: blue;">後驗分佈</strong>。<strong style="color: blue;">後驗分佈</strong>包含了數據給出的關於參數的所有信息。
                    </div>
                 </div>
             </div>

            <!-- Question 15 -->
            <div class="question-card" data-direction="5" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#15</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content">假設我們觀察到一系列<strong style="color: blue;">獨立同分佈</strong>（<strong style="color: red;">Independent and Identically Distributed</strong>, <strong style="color: purple;">i.i.d.</strong>）的數據點 <strong style="color: purple;">D = {x1, x2, ..., xn}</strong>，並且我們假設這些數據來自某個由參數 <strong style="color: purple;">θ</strong> 控制的<strong style="color: blue;">機率分佈</strong> <strong style="color: purple;">P(x|θ)</strong>。那麼，數據集 <strong style="color: purple;">D</strong> 的<strong style="color: blue;">概似函數</strong> <strong style="color: purple;">L(θ|D)</strong> 通常如何表示？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">Σ <strong style="color: purple;">P(xi|θ)</strong> （<strong style="color: blue;">機率</strong>之和）</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">Π <strong style="color: purple;">P(xi|θ)</strong> （各數據點<strong style="color: blue;">機率</strong>的<strong style="background-color: #ffff0030;">乘積</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">max( <strong style="color: purple;">P(xi|θ)</strong> ) （最大<strong style="color: blue;">機率</strong>）</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: purple;">P(θ|D)</strong> （<strong style="color: blue;">後驗機率</strong>）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">概似函數</strong> <strong style="color: purple;">L(θ|D)</strong> 定義為在給定參數 <strong style="color: purple;">θ</strong> 的條件下，觀測到數據集 <strong style="color: purple;">D</strong> 的<strong style="color: blue;">機率</strong>，即 <strong style="color: purple;">L(θ|D) = P(D|θ)</strong>。由於假設數據點是<strong style="background-color: #ffff0030;">獨立同分佈</strong> (<strong style="color: purple;">i.i.d.</strong>) 的，觀測到整個數據集 <strong style="color: purple;">D</strong> 的<strong style="color: blue;">聯合機率</strong>等於觀測到每個數據點 <strong style="color: purple;">xi</strong> 的<strong style="color: blue;">機率</strong>的<strong style="background-color: #ffff0030;">乘積</strong>。因此，<strong style="color: purple;">L(θ|D) = P(x1, x2, ..., xn | θ) = P(x1|θ) * P(x2|θ) * ... * P(xn|θ) = Π P(xi|θ)</strong>。<strong style="color: blue;">最大概似估計</strong>（<strong style="color: purple;">MLE</strong>）的目標就是找到使這個乘積（即<strong style="color: blue;">概似函數</strong>）最大化的參數 <strong style="color: purple;">θ</strong>。為了計算方便，通常會對<strong style="color: blue;">概似函數</strong>取對數，變成求解<strong style="color: blue;">對數概似函數</strong> <strong style="color: purple;">log L(θ|D) = Σ log P(xi|θ)</strong> 的最大化問題。
                    </div>
                 </div>
             </div>

             <!-- Question 16 -->
             <div class="question-card" data-direction="6" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#16</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">交叉熵</strong>（<strong style="color: red;">Cross-Entropy</strong>）<strong style="color: blue;">損失函數</strong>在<strong style="color: blue;">機器學習</strong><strong style="color: blue;">分類</strong>任務中被廣泛使用，例如訓練<strong style="color: blue;">神經網路</strong>。它衡量的是什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">模型預測的<strong style="color: blue;">平均絕對誤差</strong>（<strong style="color: red;">Mean Absolute Error</strong>, <strong style="color: purple;">MAE</strong>）。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">模型預測的<strong style="color: blue;">機率分佈</strong>與真實標籤的<strong style="color: blue;">機率分佈</strong>（通常是 <strong style="color: red;">one-hot</strong> 編碼）之間的<strong style="background-color: #ffff0030;">差異</strong>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">模型參數的總和。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">數據集中類別的<strong style="color: blue;">不平衡</strong>程度。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">交叉熵</strong>源於<strong style="color: blue;">資訊理論</strong>，可以看作是衡量<strong style="background-color: #ffff0030;">兩個機率分佈之間差異</strong>的一種方式（與<strong style="color: purple;">KL</strong><strong style="color: blue;">散度</strong>密切相關）。在<strong style="color: blue;">分類</strong>任務中，真實標籤可以表示為一個<strong style="color: blue;">機率分佈</strong>（例如，對於第 i 類，其<strong style="color: blue;">機率</strong>為1，其他類為0，即 <strong style="color: red;">one-hot</strong> 編碼，記為 p(y)）。模型的輸出（通常是 <strong style="color: red;">Softmax</strong> 層的輸出）也表示一個預測的<strong style="color: blue;">機率分佈</strong>（記為 q(y)）。<strong style="color: blue;">交叉熵損失函數</strong> <strong style="color: purple;">H(p, q) = - Σ [p(y) * log(q(y))]</strong> 計算了這兩個分佈之間的「距離」。當模型的預測分佈 q(y) 與真實分佈 p(y) 越接近時，<strong style="color: blue;">交叉熵損失</strong>越小。最小化<strong style="color: blue;">交叉熵損失</strong>等價於最大化模型預測正確類別的<strong style="color: blue;">對數概似度</strong>，因此它成為<strong style="color: blue;">分類</strong>問題中常用的<strong style="color: blue;">目標函數</strong>。
                    </div>
                 </div>
             </div>

             <!-- Question 17 -->
             <div class="question-card" data-direction="7" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#17</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">機器學習</strong>中，為了評估模型在<strong style="background-color: #ffff0030;">未見過數據上的泛化能力</strong>，並避免<strong style="color: blue;">過擬合</strong>（<strong style="color: red;">Overfitting</strong>），常用的<strong style="color: blue;">統計學</strong>方法是？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">僅使用全部數據進行訓練，並在<strong style="color: blue;">訓練集</strong>上評估性能。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">交叉驗證</strong>（<strong style="color: red;">Cross-Validation</strong>），例如 <strong style="color: purple;">K</strong> 折交叉驗證（<strong style="color: red;">K-Fold Cross-Validation</strong>）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">主成分分析</strong>（<strong style="color: red;">Principal Component Analysis</strong>, <strong style="color: purple;">PCA</strong>）。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">聚類分析</strong>（<strong style="color: red;">Clustering</strong>）。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        如果只在<strong style="color: blue;">訓練數據</strong>上評估模型性能，可能會得到過於樂觀的結果，因為模型可能只是「記住」了<strong style="color: blue;">訓練數據</strong>（<strong style="color: blue;">過擬合</strong>），而無法很好地<strong style="background-color: #ffff0030;">泛化</strong>到新的、未見過的數據。<strong style="color: blue;">交叉驗證</strong>是一種更可靠的評估模型<strong style="color: blue;">泛化能力</strong>的方法。<strong style="color: purple;">K</strong> 折交叉驗證將原始數據集隨機劃分成 <strong style="color: purple;">K</strong> 個大小相近的子集（折）。然後進行 <strong style="color: purple;">K</strong> 次訓練和驗證：每次選擇其中一個子集作為<strong style="color: blue;">驗證集</strong>，其餘 <strong style="color: purple;">K</strong>-1 個子集作為<strong style="color: blue;">訓練集</strong>。模型在<strong style="color: blue;">訓練集</strong>上訓練後，在<strong style="color: blue;">驗證集</strong>上評估性能。最後將 <strong style="color: purple;">K</strong> 次的性能指標（如<strong style="color: blue;">準確率</strong>、<strong style="color: purple;">F1</strong>分數）平均，得到對模型<strong style="color: blue;">泛化能力</strong>的<strong style="background-color: #ffff0030;">更穩健的估計</strong>。這有助於模型選擇和<strong style="color: blue;">超參數</strong>調整，並檢測<strong style="color: blue;">過擬合</strong>。
                    </div>
                 </div>
             </div>

             <!-- Question 18 -->
             <div class="question-card" data-direction="8" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#18</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">線性回歸模型</strong>（<strong style="color: red;">Linear Regression</strong>）通常假設<strong style="color: blue;">誤差項</strong>（<strong style="color: red;">Error Term</strong>）服從什麼<strong style="color: blue;">機率分佈</strong>？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">均勻分佈</strong>（<strong style="color: red;">Uniform Distribution</strong>）</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">常態分佈</strong>（<strong style="color: red;">Normal Distribution</strong>），且具有零<strong style="color: blue;">均值</strong>和固定<strong style="color: blue;">變異數</strong>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">泊松分佈</strong>（<strong style="color: red;">Poisson Distribution</strong>）</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">伽瑪分佈</strong>（<strong style="color: red;">Gamma Distribution</strong>）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        標準的<strong style="color: blue;">線性回歸模型</strong>（特別是<strong style="color: blue;">普通最小平方法</strong> <strong style="color: purple;">OLS</strong>）有幾個關鍵假設，其中之一是關於<strong style="color: blue;">誤差項</strong> <strong style="color: purple;">ε</strong> (即實際值 y 與模型預測值 ŷ 之間的差異) 的假設。通常假設<strong style="color: blue;">誤差項</strong>是<strong style="color: blue;">獨立同分佈</strong>的，並且服從<strong style="background-color: #ffff0030;">均值為零</strong>、<strong style="background-color: #ffff0030;">變異數為 σ^2</strong> 的<strong style="color: blue;">常態分佈</strong>，即 <strong style="color: purple;">ε ~ N(0, σ^2)</strong>。這個假設對於進行<strong style="color: blue;">統計推斷</strong>（如計算係數的<strong style="color: blue;">信賴區間</strong>、進行<strong style="color: blue;">假設檢定</strong>）是重要的。當這個假設成立時，<strong style="color: blue;">最小平方法</strong>估計等價於<strong style="color: blue;">最大概似估計</strong>。即使<strong style="color: blue;">誤差項</strong>不完全服從<strong style="color: blue;">常態分佈</strong>，只要樣本量足夠大，根據<strong style="color: blue;">中央極限定理</strong>，係數的估計值通常仍會近似<strong style="color: blue;">常態分佈</strong>。
                    </div>
                 </div>
             </div>

            <!-- Question 19 -->
            <div class="question-card" data-direction="1" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#19</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">隨機變數</strong>的<strong style="color: blue;">期望值</strong>（<strong style="color: red;">Expected Value</strong>） <strong style="color: purple;">E[X]</strong> 代表了該<strong style="color: blue;">變數</strong>的什麼特性？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">最可能出現的值（<strong style="color: blue;">眾數</strong> <strong style="color: red;">Mode</strong>）。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="background-color: #ffff0030;">加權平均值</strong>，反映了<strong style="color: blue;">隨機變數</strong>取值的<strong style="background-color: #ffff0030;">中心趨勢</strong>或長期平均水平。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">數值的分散程度（<strong style="color: blue;">變異數</strong> <strong style="color: red;">Variance</strong>）。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">排序後位於中間的值（<strong style="color: blue;">中位數</strong> <strong style="color: red;">Median</strong>）。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">期望值</strong>，也稱為<strong style="color: blue;">均值</strong>（<strong style="color: red;">Mean</strong>），是<strong style="color: blue;">隨機變數</strong>所有可能取值按照其發生<strong style="color: blue;">機率</strong>進行<strong style="background-color: #ffff0030;">加權的平均值</strong>。對於<strong style="color: blue;">離散隨機變數</strong> <strong style="color: purple;">X</strong>，<strong style="color: purple;">E[X] = Σ [x * P(X=x)]</strong>；對於<strong style="color: blue;">連續隨機變數</strong> <strong style="color: purple;">X</strong>，<strong style="color: purple;">E[X] = ∫ [x * f(x)] dx</strong>，其中 <strong style="color: purple;">f(x)</strong> 是<strong style="color: blue;">機率密度函數</strong>。<strong style="color: blue;">期望值</strong>描述了<strong style="color: blue;">隨機變數</strong>取值的平均水平或<strong style="background-color: #ffff0030;">中心位置</strong>，是衡量其<strong style="color: blue;">中心趨勢</strong>最重要的指標之一。
                    </div>
                 </div>
             </div>

            <!-- Question 20 -->
            <div class="question-card" data-direction="2" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#20</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">指數分佈</strong>（<strong style="color: red;">Exponential Distribution</strong>）通常用來模擬什麼類型事件發生的<strong style="background-color: #ffff0030;">時間間隔</strong>？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">固定時間內事件發生的總次數。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">獨立<strong style="color: blue;">隨機事件</strong><strong style="background-color: #ffff0030;">連續兩次發生之間</strong>的<strong style="color: blue;">時間間隔</strong>（假設事件發生率恆定）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">一組測量值的誤差大小。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">在n次試驗中成功的次數。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">指數分佈</strong>是一種<strong style="color: blue;">連續機率分佈</strong>，它描述了在<strong style="color: blue;">泊松過程</strong>中，獨立事件首次發生所需的時間，或者<strong style="background-color: #ffff0030;">連續兩次事件發生之間的時間間隔</strong>。假設事件以恆定的平均速率 <strong style="color: purple;">λ</strong> 發生，那麼事件之間的<strong style="color: blue;">時間間隔</strong> <strong style="color: purple;">T</strong> 就服從<strong style="color: blue;">指數分佈</strong>，其<strong style="color: blue;">機率密度函數</strong>為 <strong style="color: purple;">f(t; λ) = λ * exp(-λt)</strong>，<strong style="color: purple;">t ≥ 0</strong>。<strong style="color: blue;">指數分佈</strong>具有「<strong style="color: blue;">無記憶性</strong>」（<strong style="color: red;">Memorylessness</strong>）的特性。它常用於<strong style="color: blue;">可靠性工程</strong>（模擬設備壽命）、<strong style="color: blue;">排隊理論</strong>（模擬顧客到達間隔時間或服務時間）等領域。<strong style="color: blue;">泊松分佈</strong>描述固定時間內事件發生次數（選項A），<strong style="color: blue;">常態分佈</strong>描述測量誤差（選項C），<strong style="color: blue;">二項式分佈</strong>描述成功次數（選項D）。
                    </div>
                 </div>
             </div>

             <!-- Question 21 -->
             <div class="question-card" data-direction="3" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#21</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">統計學</strong>中的<strong style="color: blue;">自助法</strong>（<strong style="color: red;">Bootstrap</strong>）是一種什麼樣的技術？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">一種數據<strong style="color: blue;">加密</strong>方法。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">一種<strong style="color: blue;">重抽樣</strong>（<strong style="color: red;">Resampling</strong>）技術，通過從原始樣本中<strong style="background-color: #ffff0030;">有放回地重複抽樣</strong>來模擬多個樣本，用於估計<strong style="color: blue;">統計量</strong>的<strong style="color: blue;">抽樣分佈</strong>或構建<strong style="color: blue;">信賴區間</strong>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">一種<strong style="color: blue;">特徵選擇</strong>方法。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">一種<strong style="color: blue;">數據視覺化</strong>工具。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">自助法</strong>是一種<strong style="color: blue;">非參數</strong>的<strong style="color: blue;">統計推斷</strong>方法。當我們只有一個樣本，但想了解某個<strong style="color: blue;">統計量</strong>（如<strong style="color: blue;">樣本中位數</strong>、<strong style="color: blue;">相關係數</strong>）的<strong style="color: blue;">抽樣分佈</strong>（即如果我們能從<strong style="color: blue;">總體</strong>中抽取很多個樣本，這個<strong style="color: blue;">統計量</strong>會如何變化）時，<strong style="color: blue;">自助法</strong>提供了一種模擬方法。它從原始樣本（大小為n）中<strong style="background-color: #ffff0030;">有放回地</strong>（<strong style="color: red;">with replacement</strong>）抽取n個數據點，形成一個「<strong style="color: blue;">自助樣本</strong>」（<strong style="color: red;">Bootstrap Sample</strong>）。重複這個過程很多次（例如 B 次），得到 B 個<strong style="color: blue;">自助樣本</strong>。然後在每個<strong style="color: blue;">自助樣本</strong>上計算我們關心的<strong style="color: blue;">統計量</strong>，得到 B 個<strong style="color: blue;">統計量</strong>的值。這些值的經驗分佈就可以用來近似原始<strong style="color: blue;">統計量</strong>的<strong style="color: blue;">抽樣分佈</strong>，從而可以估計其<strong style="color: blue;">標準誤差</strong>、構建<strong style="color: blue;">信賴區間</strong>或進行<strong style="color: blue;">假設檢定</strong>。<strong style="color: red;">Bootstrap</strong> 在難以用解析方法推導<strong style="color: blue;">抽樣分佈</strong>時特別有用。
                    </div>
                 </div>
             </div>

             <!-- Question 22 -->
             <div class="question-card" data-direction="5" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#22</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">邏輯回歸</strong>（<strong style="color: red;">Logistic Regression</strong>）模型中，通常使用哪個函數將線性組合的輸入轉換為介於 0 和 1 之間的<strong style="color: blue;">機率</strong>值？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: purple;">ReLU</strong> (<strong style="color: red;">Rectified Linear Unit</strong>) 函數</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: red;">Sigmoid</strong> 函數（或稱 <strong style="color: red;">Logistic</strong> 函數）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: red;">Tanh</strong> (<strong style="color: red;">Hyperbolic Tangent</strong>) 函數</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">線性函數</strong> (<strong style="color: red;">Linear function</strong>)</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">邏輯回歸</strong>是一種用於<strong style="color: blue;">二元分類</strong>問題的<strong style="color: blue;">廣義線性模型</strong>。它首先計算輸入<strong style="color: blue;">特徵</strong>的線性組合 <strong style="color: purple;">z = w^T * x + b</strong>，然後將這個結果 <strong style="color: purple;">z</strong> 通過一個稱為 <strong style="color: red;">Sigmoid</strong>（或 <strong style="color: red;">Logistic</strong>）函數的非線性轉換，得到一個<strong style="background-color: #ffff0030;">介於 0 和 1 之間</strong>的輸出值，這個輸出值可以解釋為樣本屬於正類別的<strong style="color: blue;">機率</strong>。<strong style="color: red;">Sigmoid</strong> 函數的表達式為 <strong style="color: purple;">σ(z) = 1 / (1 + exp(-z))</strong>。它的輸出值平滑地從 0 過渡到 1，形狀像一個 "<strong style="color: purple;">S</strong>" 型曲線。通過最小化<strong style="color: blue;">交叉熵損失函數</strong>（其推導基於<strong style="color: blue;">最大概似估計</strong>），可以學習到模型的參數 <strong style="color: purple;">w</strong> 和 <strong style="color: purple;">b</strong>。
                    </div>
                 </div>
             </div>

            <!-- Question 23 -->
            <div class="question-card" data-direction="7" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#23</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: purple;">ROC</strong> <strong style="color: blue;">曲線</strong>（<strong style="color: red;">Receiver Operating Characteristic Curve</strong>）是評估<strong style="color: blue;">二元分類模型</strong>性能的常用工具，其繪製的是哪兩個指標之間的關係？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">精確率</strong>（<strong style="color: red;">Precision</strong>） vs <strong style="color: blue;">召回率</strong>（<strong style="color: red;">Recall</strong>）</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">真陽性率</strong>（<strong style="color: red;">True Positive Rate</strong>, <strong style="color: purple;">TPR</strong>，即<strong style="color: blue;">召回率</strong>） vs <strong style="color: blue;">假陽性率</strong>（<strong style="color: red;">False Positive Rate</strong>, <strong style="color: purple;">FPR</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">準確率</strong>（<strong style="color: red;">Accuracy</strong>） vs 模型複雜度</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">損失函數</strong>值（<strong style="color: red;">Loss</strong>） vs 訓練迭代次數</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: purple;">ROC</strong> <strong style="color: blue;">曲線</strong>展示了當<strong style="color: blue;">分類模型</strong>的決策<strong style="color: blue;">閾值</strong>（<strong style="color: red;">Threshold</strong>）變化時，<strong style="color: blue;">真陽性率</strong>（<strong style="color: purple;">TPR</strong>，也等於<strong style="color: blue;">召回率</strong> <strong style="color: red;">Sensitivity</strong>）和<strong style="color: blue;">假陽性率</strong>（<strong style="color: purple;">FPR</strong>，等於 1 - <strong style="color: blue;">特異度</strong> <strong style="color: red;">Specificity</strong>）之間的<strong style="background-color: #ffff0030;">權衡關係</strong>。橫軸通常是 <strong style="color: purple;">FPR = FP / (FP + TN)</strong>，縱軸是 <strong style="color: purple;">TPR = TP / (TP + FN)</strong>。通過改變<strong style="color: blue;">閾值</strong>（例如，模型輸出<strong style="color: blue;">機率</strong>大於多少才判斷為正類），可以得到一系列 (<strong style="color: purple;">FPR</strong>, <strong style="color: purple;">TPR</strong>) 點，連接這些點就形成了 <strong style="color: purple;">ROC</strong> <strong style="color: blue;">曲線</strong>。<strong style="color: blue;">曲線</strong>越靠近左上角（即 <strong style="color: purple;">TPR</strong> 高，<strong style="color: purple;">FPR</strong> 低），表示模型性能越好。<strong style="color: blue;">曲線下的面積</strong>（<strong style="color: red;">Area Under the Curve</strong>, <strong style="color: purple;">AUC</strong>）是一個常用的匯總指標，<strong style="color: purple;">AUC</strong> 值越接近 1 表示模型區分正負樣本的能力越強（<strong style="color: purple;">AUC</strong>=0.5 表示隨機猜測）。<strong style="color: blue;">Precision-Recall</strong> <strong style="color: blue;">曲線</strong>是另一個評估工具，特別適用於類別不平衡的數據集。
                    </div>
                 </div>
             </div>

            <!-- Question 24 -->
            <div class="question-card" data-direction="8" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#24</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">決策樹</strong>（<strong style="color: red;">Decision Tree</strong>）<strong style="color: blue;">算法</strong>中，選擇哪個<strong style="color: blue;">特徵</strong>來進行節點<strong style="color: blue;">分裂</strong>時，常用的基於<strong style="color: blue;">資訊理論</strong>的標準是？</div>
                 <div class="options-container">
                     <div class="option-item correct" data-option="A"><div class="option-label">A</div><div class="option-text">最小化<strong style="color: blue;">基尼不純度</strong>（<strong style="color: red;">Gini Impurity</strong>）或最大化<strong style="color: blue;">信息增益</strong>（<strong style="color: red;">Information Gain</strong>）/增益率（<strong style="color: red;">Gain Ratio</strong>）。</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text">最大化<strong style="color: blue;">基尼不純度</strong>（<strong style="color: red;">Gini Impurity</strong>）或最小化<strong style="color: blue;">信息增益</strong>（<strong style="color: red;">Information Gain</strong>）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">選擇數值範圍最大的<strong style="color: blue;">特徵</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">隨機選擇一個<strong style="color: blue;">特徵</strong>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">決策樹</strong>的構建過程是一個遞迴地選擇最佳<strong style="color: blue;">特徵</strong>來<strong style="color: blue;">分裂</strong>數據集，以使得<strong style="color: blue;">分裂</strong>後的子集盡可能「純淨」（即包含的樣本盡量屬於同一類別）。常用的<strong style="color: blue;">分裂</strong>標準包括：<br>
                        <ul>
                            <li><strong style="color: blue;">信息增益</strong> (<strong style="color: red;">Information Gain</strong>, 用於 <strong style="color: purple;">ID3</strong> <strong style="color: blue;">算法</strong>)：計算<strong style="color: blue;">分裂</strong>前的<strong style="color: blue;">熵</strong>與<strong style="color: blue;">分裂</strong>後各子集<strong style="color: blue;">熵</strong>的加權平均之差。選擇<strong style="color: blue;">信息增益</strong>最大的<strong style="color: blue;">特徵</strong>進行<strong style="color: blue;">分裂</strong>，意味著這次<strong style="color: blue;">分裂</strong>能最大程度地減少數據的<strong style="color: blue;">不確定性</strong>。</li>
                            <li><strong style="color: blue;">信息增益率</strong> (<strong style="color: red;">Gain Ratio</strong>, 用於 <strong style="color: purple;">C4.5</strong> <strong style="color: blue;">算法</strong>)：<strong style="color: blue;">信息增益</strong>除以<strong style="color: blue;">特徵</strong>本身的<strong style="color: blue;">熵</strong>（固有值），用於校正<strong style="color: blue;">信息增益</strong>偏向於選擇取值多的<strong style="color: blue;">特徵</strong>的問題。</li>
                            <li><strong style="color: blue;">基尼不純度</strong> (<strong style="color: red;">Gini Impurity</strong>, 用於 <strong style="color: purple;">CART</strong> <strong style="color: blue;">算法</strong>)：衡量從數據集中隨機抽取兩個樣本，其類別標籤不一致的<strong style="color: blue;">機率</strong>。<strong style="color: blue;">基尼不純度</strong>越小，表示數據集越純淨。<strong style="color: blue;">分裂</strong>時選擇使得<strong style="color: blue;">分裂</strong>後子集<strong style="color: blue;">基尼不純度</strong>加權平均<strong style="background-color: #ffff0030;">最小化</strong>的<strong style="color: blue;">特徵</strong>。</li>
                        </ul>
                        因此，目標是<strong style="background-color: #ffff0030;">最大化信息增益</strong>（或增益率）或者<strong style="background-color: #ffff0030;">最小化基尼不純度</strong>。
                    </div>
                 </div>
             </div>

            <!-- Question 25 -->
            <div class="question-card" data-direction="1" data-stars="1">
                 <div class="question-header">
                     <div class="question-id">#25</div>
                     <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">機率</strong>的取值範圍是多少？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">介於 -1 和 1 之間。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="background-color: #ffff0030;">介於 0 和 1 之間</strong>（包含 0 和 1）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">可以是任何實數。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">只能是 0 或 1。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        根據<strong style="color: blue;">機率公理</strong>（<strong style="color: red;">Axioms of Probability</strong>），任何事件 A 的<strong style="color: blue;">機率</strong> <strong style="color: purple;">P(A)</strong> 必須滿足 <strong style="background-color: #ffff0030;">0 ≤ P(A) ≤ 1</strong>。<strong style="color: blue;">機率</strong>為 0 表示該事件不可能發生，<strong style="color: blue;">機率</strong>為 1 表示該事件必然發生。<strong style="color: blue;">機率</strong>值介於 0 和 1 之間表示事件發生的可能性大小。<strong style="color: blue;">機率</strong>不可能是負數，也不可能大於 1。
                    </div>
                 </div>
             </div>

            <!-- Question 26 -->
             <div class="question-card" data-direction="4" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#26</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">最大後驗估計</strong>（<strong style="color: red;">Maximum A Posteriori</strong>, <strong style="color: purple;">MAP</strong>）與<strong style="color: blue;">最大概似估計</strong>（<strong style="color: purple;">MLE</strong>）的主要區別在於 <strong style="color: purple;">MAP</strong> 引入了什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">數據的<strong style="color: blue;">邊際機率</strong>。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">模型參數的<strong style="color: blue;">先驗分佈</strong>（<strong style="color: red;">Prior Distribution</strong>）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">模型的複雜度懲罰項（與<strong style="color: blue;">正規化</strong>相關，但<strong style="color: purple;">MAP</strong>是從<strong style="color: blue;">貝氏</strong>角度引入）。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">交叉驗證</strong>的結果。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: purple;">MLE</strong> 尋找使<strong style="color: blue;">概似函數</strong> <strong style="color: purple;">P(D|θ)</strong> 最大化的參數 <strong style="color: purple;">θ</strong>。而 <strong style="color: purple;">MAP</strong> 則尋找使<strong style="color: blue;">後驗機率</strong> <strong style="color: purple;">P(θ|D)</strong> 最大化的參數 <strong style="color: purple;">θ</strong>。根據<strong style="color: blue;">貝氏定理</strong>，<strong style="color: purple;">P(θ|D) ∝ P(D|θ) * P(θ)</strong>，其中 <strong style="color: purple;">P(D|θ)</strong> 是<strong style="color: blue;">概似函數</strong>，<strong style="color: purple;">P(θ)</strong> 是參數 <strong style="color: purple;">θ</strong> 的<strong style="color: blue;">先驗分佈</strong>，代表了我們在看到數據之前對 <strong style="color: purple;">θ</strong> 的信念。因此，<strong style="color: purple;">MAP</strong> 估計相當於在 <strong style="color: purple;">MLE</strong> 的基礎上，<strong style="background-color: #ffff0030;">額外考慮了先驗知識 P(θ)</strong>。當<strong style="color: blue;">先驗分佈</strong> <strong style="color: purple;">P(θ)</strong> 是一個<strong style="color: blue;">均勻分佈</strong>（即對所有參數值一視同仁）時，<strong style="color: purple;">MAP</strong> 估計等價於 <strong style="color: purple;">MLE</strong> 估計。引入<strong style="color: blue;">先驗分佈</strong>可以看作是一種<strong style="color: blue;">正規化</strong>（<strong style="color: red;">Regularization</strong>）手段，有助於防止<strong style="color: blue;">過擬合</strong>，特別是在數據量較少時。例如，使用<strong style="color: blue;">高斯先驗</strong>對應 <strong style="color: purple;">L2</strong> <strong style="color: blue;">正規化</strong>，使用<strong style="color: blue;">拉普拉斯先驗</strong>對應 <strong style="color: purple;">L1</strong> <strong style="color: blue;">正規化</strong>。
                    </div>
                 </div>
             </div>

             <!-- Question 27 -->
             <div class="question-card" data-direction="5" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#27</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">當我們假設數據來自<strong style="color: blue;">常態分佈</strong> <strong style="color: purple;">N(μ, σ^2)</strong> 時，使用<strong style="color: blue;">最大概似估計</strong>（<strong style="color: purple;">MLE</strong>）來估計參數 <strong style="color: purple;">μ</strong> 和 <strong style="color: purple;">σ^2</strong>，通常會得到什麼結果？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: purple;">μ</strong> 的估計值是<strong style="color: blue;">樣本中位數</strong>，<strong style="color: purple;">σ^2</strong> 的估計值是樣本<strong style="color: blue;">四分位距</strong>。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: purple;">μ</strong> 的估計值是<strong style="color: blue;">樣本均值</strong>（<strong style="color: red;">Sample Mean</strong>），<strong style="color: purple;">σ^2</strong> 的估計值是<strong style="color: blue;">樣本變異數</strong>（<strong style="color: red;">Sample Variance</strong>，除以n的版本）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: purple;">μ</strong> 的估計值是<strong style="color: blue;">樣本眾數</strong>，<strong style="color: purple;">σ^2</strong> 的估計值也是<strong style="color: blue;">樣本眾數</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">無法通過<strong style="color: purple;">MLE</strong>估計這兩個參數。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        對於來自<strong style="color: blue;">常態分佈</strong> <strong style="color: purple;">N(μ, σ^2)</strong> 的 <strong style="color: purple;">i.i.d.</strong> 樣本 <strong style="color: purple;">{x1, ..., xn}</strong>，其<strong style="color: blue;">對數概似函數</strong>為 <strong style="color: purple;">log L(μ, σ^2 | D) = -n/2 * log(2πσ^2) - Σ[(xi - μ)^2] / (2σ^2)</strong>。通過對 <strong style="color: purple;">μ</strong> 和 <strong style="color: purple;">σ^2</strong> 分別求偏導並令其為零，可以解得使<strong style="color: blue;">對數概似函數</strong>最大化的參數估計值。結果是：<strong style="color: purple;">μ</strong> 的 <strong style="color: purple;">MLE</strong> 估計值恰好是<strong style="color: blue;">樣本均值</strong>（<strong style="color: purple;">x̄ = Σxi / n</strong>），而 <strong style="color: purple;">σ^2</strong> 的 <strong style="color: purple;">MLE</strong> 估計值是<strong style="color: blue;">樣本變異數</strong>（<strong style="color: purple;">Σ(xi - x̄)^2 / n</strong>）。需要注意的是，<strong style="color: purple;">σ^2</strong> 的 <strong style="color: purple;">MLE</strong> 估計是有偏的（<strong style="color: red;">biased</strong>），而無偏的<strong style="color: blue;">樣本變異數</strong>估計通常是除以 n-1。
                    </div>
                 </div>
             </div>

            <!-- Question 28 -->
            <div class="question-card" data-direction="7" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#28</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">赤池資訊量準則</strong>（<strong style="color: red;">Akaike Information Criterion</strong>, <strong style="color: purple;">AIC</strong>）和<strong style="color: blue;">貝氏資訊量準則</strong>（<strong style="color: red;">Bayesian Information Criterion</strong>, <strong style="color: purple;">BIC</strong>）常用於<strong style="color: blue;">模型選擇</strong>。它們在評估模型<strong style="color: blue;">擬合優度</strong>的同時，都加入了對什麼的<strong style="background-color: #ffff0030;">懲罰項</strong>？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">訓練數據的大小。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">模型的<strong style="color: blue;">複雜度</strong>（通常用模型參數的數量來衡量）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">模型訓練所需的時間。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">模型的<strong style="color: blue;">可解釋性</strong>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: purple;">AIC</strong> 和 <strong style="color: purple;">BIC</strong> 都是基於<strong style="color: blue;">資訊理論</strong>的<strong style="color: blue;">模型選擇</strong>標準，用於在一組候選模型中選擇最佳模型。它們都試圖在模型的<strong style="color: blue;">擬合優度</strong>（通常用最大化<strong style="color: blue;">對數概似值</strong>來衡量）和模型的<strong style="color: blue;">複雜度</strong>之間取得平衡。公式通常表示為：<br>
                        <ul>
                            <li><strong style="color: purple;">AIC</strong> = -2 * <strong style="color: purple;">log(L)</strong> + 2 * <strong style="color: purple;">k</strong></li>
                            <li><strong style="color: purple;">BIC</strong> = -2 * <strong style="color: purple;">log(L)</strong> + <strong style="color: purple;">k</strong> * <strong style="color: purple;">log(n)</strong></li>
                        </ul>
                        其中 <strong style="color: purple;">L</strong> 是模型的最大<strong style="color: blue;">概似值</strong>，<strong style="color: purple;">k</strong> 是模型中自由參數的數量，<strong style="color: purple;">n</strong> 是樣本大小。第一項 -2*<strong style="color: purple;">log(L)</strong> 衡量模型的擬合程度（越小越好），第二項是<strong style="background-color: #ffff0030;">懲罰項</strong>，對<strong style="color: blue;">模型複雜度</strong>（參數數量 <strong style="color: purple;">k</strong>）進行懲罰。<strong style="color: purple;">AIC</strong> 和 <strong style="color: purple;">BIC</strong> 都傾向於選擇擬合數據好且相對簡單的模型。<strong style="color: purple;">BIC</strong> 對模型複雜度的懲罰通常比 <strong style="color: purple;">AIC</strong> 更重（因為 <strong style="color: purple;">log(n)</strong> 通常大於 2），因此傾向於選擇更簡單的模型。模型選擇時通常選擇 <strong style="color: purple;">AIC</strong> 或 <strong style="color: purple;">BIC</strong> 值最小的模型。
                    </div>
                 </div>
             </div>

            <!-- Question 29 -->
            <div class="question-card" data-direction="8" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#29</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">高斯混合模型</strong>（<strong style="color: red;">Gaussian Mixture Model</strong>, <strong style="color: purple;">GMM</strong>）是一種常用的<strong style="color: blue;">聚類算法</strong>，它假設數據是由幾個什麼分佈混合而成的？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">均勻分佈</strong>（<strong style="color: red;">Uniform Distribution</strong>）</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">高斯分佈</strong>（<strong style="color: red;">Gaussian Distribution</strong>）或稱<strong style="color: blue;">常態分佈</strong></div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">柏努力分佈</strong>（<strong style="color: red;">Bernoulli Distribution</strong>）</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">指數分佈</strong>（<strong style="color: red;">Exponential Distribution</strong>）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: purple;">GMM</strong> 是一種基於<strong style="color: blue;">機率模型</strong>的<strong style="color: blue;">聚類</strong>方法。它假設觀測到的數據點是由 <strong style="color: purple;">K</strong> 個不同的<strong style="background-color: #ffff0030;">高斯（常態）分佈</strong>成分（<strong style="color: red;">Components</strong>）以一定的權重（混合係數）混合生成的。每個<strong style="color: blue;">高斯</strong>成分代表一個潛在的簇（<strong style="color: red;">Cluster</strong>），並由其自身的<strong style="color: blue;">均值向量</strong>和<strong style="color: blue;">共變異數矩陣</strong>參數化。<strong style="color: purple;">GMM</strong> 的目標是通過最大化數據的<strong style="color: blue;">對數概似度</strong>，來估計每個成分的參數（<strong style="color: blue;">均值</strong>、<strong style="color: blue;">共變異數</strong>）以及每個數據點屬於各個成分的<strong style="color: blue;">機率</strong>（責任 <strong style="color: red;">responsibility</strong>）。常用的估計方法是<strong style="color: blue;">期望最大化</strong>（<strong style="color: red;">Expectation-Maximization</strong>, <strong style="color: purple;">EM</strong>）<strong style="color: blue;">算法</strong>。<strong style="color: purple;">GMM</strong> 相比 <strong style="color: purple;">K-means</strong> 的優點是它可以處理非球形的簇，並且提供數據點屬於每個簇的軟分配（<strong style="color: blue;">機率</strong>）。
                    </div>
                 </div>
             </div>

            <!-- Question 30 -->
             <div class="question-card" data-direction="1" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#30</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">隨機變數</strong>的<strong style="color: blue;">變異數</strong>（<strong style="color: red;">Variance</strong>） <strong style="color: purple;">Var(X)</strong> 衡量的是該<strong style="color: blue;">變數</strong>的什麼特性？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">中心趨勢</strong>（<strong style="color: blue;">期望值</strong>）。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">取值相對於其<strong style="color: blue;">期望值</strong>的<strong style="background-color: #ffff0030;">離散程度或波動幅度</strong>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">取正值的<strong style="color: blue;">機率</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">與另一個<strong style="color: blue;">變數</strong>的協變關係（<strong style="color: blue;">共變異數</strong> <strong style="color: red;">Covariance</strong>）。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">變異數</strong>是衡量<strong style="color: blue;">隨機變數</strong>取值<strong style="background-color: #ffff0030;">分散程度</strong>的常用指標。它定義為<strong style="color: blue;">隨機變數</strong>與其<strong style="color: blue;">期望值</strong>之差的平方的<strong style="color: blue;">期望值</strong>，即 <strong style="color: purple;">Var(X) = E[(X - E[X])^2]</strong>。<strong style="color: blue;">變異數</strong>越大，表示數據點越分散，偏離<strong style="color: blue;">平均值</strong>的程度越大；<strong style="color: blue;">變異數</strong>越小，表示數據點越集中在<strong style="color: blue;">平均值</strong>附近。<strong style="color: blue;">標準差</strong>（<strong style="color: red;">Standard Deviation</strong>）是<strong style="color: blue;">變異數</strong>的平方根，它與原始數據具有相同的單位，更易於解釋。<strong style="color: blue;">變異數</strong>在<strong style="color: blue;">統計學</strong>和<strong style="color: blue;">機器學習</strong>中用於描述數據波動性、評估估計量精度、以及在某些<strong style="color: blue;">算法</strong>（如<strong style="color: purple;">PCA</strong>）中。
                    </div>
                 </div>
             </div>

            <!-- Question 31 -->
            <div class="question-card" data-direction="2" data-stars="1">
                <div class="question-header">
                    <div class="question-id">#31</div>
                    <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content">如果一個<strong style="color: blue;">隨機實驗</strong>只有<strong style="background-color: #ffff0030;">兩種可能</strong>的結果（例如，成功/失敗，正面/反面），且只進行<strong style="background-color: #ffff0030;">一次試驗</strong>，描述這個實驗結果的<strong style="color: blue;">機率分佈</strong>是？</div>
                 <div class="options-container">
                    <div class="option-item correct" data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text"><strong style="color: blue;">柏努力分佈</strong>（<strong style="color: red;">Bernoulli Distribution</strong>）</div>
                    </div>
                    <div class="option-item " data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><strong style="color: blue;">二項式分佈</strong>（<strong style="color: red;">Binomial Distribution</strong>）</div>
                    </div>
                    <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text"><strong style="color: blue;">幾何分佈</strong>（<strong style="color: red;">Geometric Distribution</strong>）</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text"><strong style="color: blue;">常態分佈</strong>（<strong style="color: red;">Normal Distribution</strong>）</div>
                    </div>
                 </div>
                 <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">
                        <strong style="color: blue;">柏努力分佈</strong>是描述<strong style="background-color: #ffff0030;">單次隨機試驗</strong>結果的最簡單的<strong style="color: blue;">離散機率分佈</strong>。該試驗只有兩種可能的互斥結果，通常稱為「成功」（值為1）和「失敗」（值為0）。如果成功的<strong style="color: blue;">機率</strong>為 p，則失敗的<strong style="color: blue;">機率</strong>為 1-p。其<strong style="color: blue;">機率質量函數</strong>為 <strong style="color: purple;">P(X=x) = p^x * (1-p)^(1-x)</strong>，其中 x 只能取 0 或 1。<strong style="color: blue;">二項式分佈</strong>是 n 次獨立<strong style="color: blue;">柏努力試驗</strong>中成功次數的分佈。<strong style="color: blue;">幾何分佈</strong>是得到第一次成功所需的試驗次數的分佈。
                    </div>
                 </div>
             </div>

            <!-- Question 32 -->
            <div class="question-card" data-direction="3" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#32</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">統計學</strong>中，<strong style="color: blue;">中央極限定理</strong>（<strong style="color: red;">Central Limit Theorem</strong>, <strong style="color: purple;">CLT</strong>）說明了什麼重要的結論？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">任何<strong style="color: blue;">隨機變數</strong>都服從<strong style="color: blue;">常態分佈</strong>。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">只要<strong style="background-color: #ffff0030;">樣本量足夠大</strong>，從任意<strong style="color: blue;">總體</strong>（具有有限<strong style="color: blue;">變異數</strong>）中抽取的獨立隨機樣本的<strong style="color: blue;">平均值</strong>的<strong style="color: blue;">分佈</strong>會<strong style="background-color: #ffff0030;">近似於常態分佈</strong>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">樣本均值</strong>總等於<strong style="color: blue;">總體均值</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">樣本變異數</strong>總等於<strong style="color: blue;">總體變異數</strong>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">中央極限定理</strong>是<strong style="color: blue;">機率論</strong>和<strong style="color: blue;">統計學</strong>中最核心的定理之一。它指出，無論原始<strong style="color: blue;">總體</strong>的<strong style="color: blue;">分佈</strong>是什麼（只要其<strong style="color: blue;">均值</strong>和<strong style="color: blue;">變異數</strong>存在且有限），當我們從該<strong style="color: blue;">總體</strong>中抽取<strong style="background-color: #ffff0030;">大量</strong>（通常認為n≥30即可認為足夠大）<strong style="color: blue;">獨立同分佈</strong>的隨機樣本時，這些樣本的<strong style="color: blue;">平均值</strong>（<strong style="color: red;">Sample Mean</strong>）的<strong style="color: blue;">抽樣分佈</strong>將會<strong style="background-color: #ffff0030;">趨近於常態分佈</strong>。這個<strong style="color: blue;">常態分佈</strong>的<strong style="color: blue;">均值</strong>等於原始<strong style="color: blue;">總體</strong>的<strong style="color: blue;">均值</strong>，其<strong style="color: blue;">變異數</strong>等於原始<strong style="color: blue;">總體</strong>的<strong style="color: blue;">變異數</strong>除以樣本量 n。<strong style="color: purple;">CLT</strong> 使得我們可以利用<strong style="color: blue;">常態分佈</strong>的性質來對<strong style="color: blue;">樣本均值</strong>進行<strong style="color: blue;">統計推斷</strong>（如構建<strong style="color: blue;">信賴區間</strong>、進行<strong style="color: blue;">假設檢定</strong>），即使我們不知道原始<strong style="color: blue;">總體</strong>的<strong style="color: blue;">分佈</strong>形式。
                    </div>
                 </div>
             </div>

            <!-- Question 33 -->
             <div class="question-card" data-direction="4" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#33</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">貝氏定理</strong> <strong style="color: purple;">P(H|E) = [P(E|H) * P(H)] / P(E)</strong> 中，如果我們有多個互斥且窮盡的假設 <strong style="color: purple;">H1, H2, ..., Hk</strong>，那麼分母 <strong style="color: purple;">P(E)</strong>（證據的<strong style="color: blue;">邊際機率</strong>）可以如何計算？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">max( <strong style="color: purple;">P(E|Hi) * P(Hi)</strong> )</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">Σ [<strong style="color: purple;">P(E|Hi) * P(Hi)</strong>] （根據<strong style="color: blue;">全機率定理</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">Π [<strong style="color: purple;">P(E|Hi) * P(Hi)</strong>]</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">1 / <strong style="color: purple;">P(H|E)</strong></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        分母 <strong style="color: purple;">P(E)</strong> 在<strong style="color: blue;">貝氏定理</strong>中作為歸一化常數，確保所有假設的<strong style="color: blue;">後驗機率</strong>之和為 1。它可以通過<strong style="color: blue;">全機率定理</strong>（<strong style="color: red;">Law of Total Probability</strong>）計算得到。如果假設 <strong style="color: purple;">H1, H2, ..., Hk</strong> 構成了一個<strong style="background-color: #ffff0030;">互斥</strong>（任意兩個假設不能同時為真）且<strong style="background-color: #ffff0030;">窮盡</strong>（所有可能情況都被包含在內）的事件劃分，那麼事件 <strong style="color: purple;">E</strong> 發生的總<strong style="color: blue;">機率</strong> <strong style="color: purple;">P(E)</strong> 等於在每個假設 <strong style="color: purple;">Hi</strong> 為真的條件下 <strong style="color: purple;">E</strong> 發生的<strong style="color: blue;">機率</strong> <strong style="color: purple;">P(E|Hi)</strong> 乘以該假設 <strong style="color: purple;">Hi</strong> 本身發生的<strong style="color: blue;">先驗機率</strong> <strong style="color: purple;">P(Hi)</strong>，然後對所有假設求和。即 <strong style="color: purple;">P(E) = Σ [P(E|Hi) * P(Hi)]</strong>，其中 <strong style="color: purple;">i</strong> 從 1 到 k。
                    </div>
                 </div>
             </div>

            <!-- Question 34 -->
             <div class="question-card" data-direction="6" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#34</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">互信息</strong>（<strong style="color: red;">Mutual Information</strong>, <strong style="color: purple;">MI</strong>） <strong style="color: purple;">I(X; Y)</strong> 衡量的是兩個<strong style="color: blue;">隨機變數</strong> <strong style="color: purple;">X</strong> 和 <strong style="color: purple;">Y</strong> 之間的什麼關係？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">線性相關性</strong>（<strong style="color: red;">Linear Correlation</strong>）。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">統計依賴性</strong>，即知道一個<strong style="color: blue;">變數</strong>的值能夠<strong style="background-color: #ffff0030;">減少對另一個變數不確定性</strong>的程度。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">條件機率</strong> <strong style="color: purple;">P(X|Y)</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">兩個<strong style="color: blue;">變數</strong>的<strong style="color: blue;">熵</strong>之和 <strong style="color: purple;">H(X) + H(Y)</strong>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">互信息</strong> <strong style="color: purple;">I(X; Y)</strong> 是<strong style="color: blue;">資訊理論</strong>中用來量化兩個<strong style="color: blue;">隨機變數</strong>之間<strong style="background-color: #ffff0030;">相互依賴程度</strong>的指標。它表示通過觀測<strong style="color: blue;">變數</strong> <strong style="color: purple;">Y</strong>，我們能夠獲得多少關於<strong style="color: blue;">變數</strong> <strong style="color: purple;">X</strong> 的信息（反之亦然，因為<strong style="color: blue;">互信息</strong>是對稱的）。其計算公式可以表示為 <strong style="color: purple;">I(X; Y) = H(X) - H(X|Y) = H(Y) - H(Y|X) = H(X) + H(Y) - H(X, Y)</strong>，其中 <strong style="color: purple;">H(X)</strong> 是 <strong style="color: purple;">X</strong> 的<strong style="color: blue;">熵</strong>，<strong style="color: purple;">H(X|Y)</strong> 是給定 <strong style="color: purple;">Y</strong> 時 <strong style="color: purple;">X</strong> 的<strong style="color: blue;">條件熵</strong>，<strong style="color: purple;">H(X, Y)</strong> 是 <strong style="color: purple;">X</strong> 和 <strong style="color: purple;">Y</strong> 的<strong style="color: blue;">聯合熵</strong>。<strong style="color: blue;">互信息</strong>總是≥0，當且僅當 <strong style="color: purple;">X</strong> 和 <strong style="color: purple;">Y</strong> 相互獨立時等於0。<strong style="color: blue;">互信息</strong>在<strong style="color: blue;">機器學習</strong>中常用於<strong style="color: blue;">特徵選擇</strong>（選擇與<strong style="color: blue;">目標變數</strong><strong style="color: blue;">互信息</strong>最大的<strong style="color: blue;">特徵</strong>）、評估<strong style="color: blue;">聚類</strong>結果等。它能捕捉<strong style="color: blue;">變數</strong>間的<strong style="color: blue;">非線性</strong>依賴關係，比<strong style="color: blue;">線性相關係數</strong>更通用。
                    </div>
                 </div>
             </div>

             <!-- Question 35 -->
             <div class="question-card" data-direction="7" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#35</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">模型評估</strong>中，<strong style="color: blue;">偏誤</strong>（<strong style="color: red;">Bias</strong>）和<strong style="color: blue;">變異</strong>（<strong style="color: red;">Variance</strong>）是衡量模型性能的兩個重要方面。一個具有<strong style="background-color: #ffff0030;">高偏誤</strong>和<strong style="background-color: #ffff0030;">低變異</strong>的模型通常表現為？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">在<strong style="color: blue;">訓練集</strong>和<strong style="color: blue;">測試集</strong>上都表現良好（低錯誤率）。</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text">在<strong style="color: blue;">訓練集</strong>上表現好，但在<strong style="color: blue;">測試集</strong>上表現差（<strong style="color: blue;">過擬合</strong> <strong style="color: red;">Overfitting</strong>）。</div></div>
                     <div class="option-item correct" data-option="C"><div class="option-label">C</div><div class="option-text">在<strong style="color: blue;">訓練集</strong>和<strong style="color: blue;">測試集</strong>上都<strong style="background-color: #ffff0030;">表現差</strong>（<strong style="color: blue;">欠擬合</strong> <strong style="color: red;">Underfitting</strong>）。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">在<strong style="color: blue;">訓練集</strong>上表現差，但在<strong style="color: blue;">測試集</strong>上表現好（不常見）。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">偏誤-變異權衡</strong>（<strong style="color: red;">Bias-Variance Tradeoff</strong>）是<strong style="color: blue;">監督學習</strong>中的一個核心概念：<br>
                        <ul>
                            <li><strong style="color: blue;">偏誤 (Bias)</strong>：衡量模型預測值與真實值之間的系統性差異，即模型本身的假設與真實數據規律的偏離程度。<strong style="background-color: #ffff0030;">高偏誤</strong>通常意味著模型<strong style="background-color: #ffff0030;">過於簡單</strong>，未能捕捉數據中的複雜模式（<strong style="color: blue;">欠擬合</strong>）。</li>
                            <li><strong style="color: blue;">變異 (Variance)</strong>：衡量模型預測結果對於訓練數據微小變化的敏感程度。<strong style="background-color: #ffff0030;">高變異</strong>通常意味著模型<strong style="background-color: #ffff0030;">過於複雜</strong>，對訓練數據中的<strong style="color: blue;">噪聲</strong>或隨機性過度擬合，導致在不同訓練集上得到的模型差異很大，<strong style="color: blue;">泛化能力</strong>差（<strong style="color: blue;">過擬合</strong>）。</li>
                        </ul>
                        因此：<br>
                        <ul>
                            <li><strong style="background-color: #ffff0030;">高偏誤、低變異</strong>：模型簡單，對數據變化不敏感，但在<strong style="color: blue;">訓練集</strong>和<strong style="color: blue;">測試集</strong>上都<strong style="background-color: #ffff0030;">表現不佳</strong>（<strong style="color: blue;">欠擬合</strong>）。</li>
                            <li>低<strong style="color: blue;">偏誤</strong>、高<strong style="color: blue;">變異</strong>：模型複雜，能很好地擬合<strong style="color: blue;">訓練數據</strong>，但對數據變化敏感，在<strong style="color: blue;">測試集</strong>上表現差（<strong style="color: blue;">過擬合</strong>）。</li>
                            <li>低<strong style="color: blue;">偏誤</strong>、低<strong style="color: blue;">變異</strong>：理想情況，模型既能捕捉數據模式，又具有良好的<strong style="color: blue;">泛化能力</strong>。</li>
                        </ul>
                        目標是在<strong style="color: blue;">偏誤</strong>和<strong style="color: blue;">變異</strong>之間找到一個平衡點，以最小化總體的預期<strong style="color: blue;">泛化誤差</strong>。
                    </div>
                 </div>
             </div>

             <!-- Question 36 -->
             <div class="question-card" data-direction="8" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#36</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">期望最大化</strong>（<strong style="color: red;">Expectation-Maximization</strong>, <strong style="color: purple;">EM</strong>）<strong style="color: blue;">算法</strong>常用於估計含有<strong style="color: blue;">隱藏變數</strong>（<strong style="color: red;">Latent Variables</strong>）的<strong style="color: blue;">機率模型</strong>的參數。它主要包含哪兩個交替執行的步驟？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">梯度下降</strong>（<strong style="color: red;">Gradient Descent</strong>）和<strong style="color: blue;">隨機梯度下降</strong>（<strong style="color: red;">Stochastic Gradient Descent</strong>）。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">期望步驟</strong>（<strong style="color: red;">Expectation Step</strong>, <strong style="color: purple;">E-step</strong>）和<strong style="color: blue;">最大化步驟</strong>（<strong style="color: red;">Maximization Step</strong>, <strong style="color: purple;">M-step</strong>）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">特徵提取</strong>（<strong style="color: red;">Feature Extraction</strong>）和<strong style="color: blue;">特徵選擇</strong>（<strong style="color: red;">Feature Selection</strong>）。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">數據清洗</strong>（<strong style="color: red;">Data Cleaning</strong>）和<strong style="color: blue;">數據轉換</strong>（<strong style="color: red;">Data Transformation</strong>）。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: purple;">EM</strong> <strong style="color: blue;">算法</strong>是一種<strong style="background-color: #ffff0030;">迭代優化算法</strong>，特別適用於當模型包含無法直接觀測到的<strong style="color: blue;">隱藏變數</strong>時，估計模型參數的<strong style="color: blue;">最大概似解</strong>或<strong style="color: blue;">最大後驗解</strong>。它通過交替執行以下兩個步驟來逐步逼近最優解：<br>
                        <ol>
                            <li><strong style="background-color: #ffff0030;">期望步驟 (E-step)</strong>：在給定當前參數估計值和觀測數據的條件下，計算<strong style="color: blue;">隱藏變數</strong>的<strong style="color: blue;">期望值</strong>（或者更一般地說，計算完整數據<strong style="color: blue;">對數概似函數</strong>關於<strong style="color: blue;">隱藏變數</strong>條件分佈的<strong style="color: blue;">期望</strong>）。</li>
                            <li><strong style="background-color: #ffff0030;">最大化步驟 (M-step)</strong>：利用 <strong style="color: purple;">E-step</strong> 中計算出的<strong style="color: blue;">期望</strong>值（或期望的<strong style="color: blue;">對數概似函數</strong>），來最大化這個期望函數，從而得到新的參數估計值。</li>
                        </ol>
                        重複執行 <strong style="color: purple;">E-step</strong> 和 <strong style="color: purple;">M-step</strong>，直到參數收斂或達到最大迭代次數。<strong style="color: purple;">EM</strong> <strong style="color: blue;">算法</strong>常用於<strong style="color: blue;">高斯混合模型</strong>（<strong style="color: purple;">GMM</strong>）、<strong style="color: blue;">隱馬可夫模型</strong>（<strong style="color: purple;">HMM</strong>）等模型的參數估計。
                    </div>
                 </div>
             </div>

             <!-- Question 37 -->
             <div class="question-card" data-direction="1" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#37</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">全機率定理</strong>（<strong style="color: red;">Law of Total Probability</strong>）主要用於計算一個事件的什麼<strong style="color: blue;">機率</strong>？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">條件機率</strong> <strong style="color: purple;">P(A|B)</strong></div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">邊際機率</strong> <strong style="color: purple;">P(A)</strong></div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">聯合機率</strong> <strong style="color: purple;">P(A∩B)</strong></div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">互斥事件的<strong style="color: blue;">機率</strong></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">全機率定理</strong>提供了一種計算一個事件 A 的總<strong style="color: blue;">機率</strong>（即<strong style="color: blue;">邊際機率</strong> <strong style="color: purple;">P(A)</strong>）的方法，通過考慮導致事件 A 發生的所有<strong style="background-color: #ffff0030;">互斥且窮盡</strong>的途徑（由事件劃分 <strong style="color: purple;">B1, B2, ..., Bk</strong> 定義）。定理表明 <strong style="color: purple;">P(A) = Σ P(A|Bi) * P(Bi)</strong>，其中 <strong style="color: purple;">P(A|Bi)</strong> 是在事件 <strong style="color: purple;">Bi</strong> 發生的條件下事件 A 發生的<strong style="color: blue;">機率</strong>，<strong style="color: purple;">P(Bi)</strong> 是事件 <strong style="color: purple;">Bi</strong> 本身發生的<strong style="color: blue;">機率</strong>。它將一個複雜事件的<strong style="color: blue;">邊際機率</strong>分解為基於不同條件下的<strong style="color: blue;">條件機率</strong>的加權和，是推導<strong style="color: blue;">貝氏定理</strong>分母 <strong style="color: purple;">P(E)</strong> 的基礎。
                    </div>
                 </div>
             </div>

            <!-- Question 38 -->
            <div class="question-card" data-direction="2" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#38</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">泊松分佈</strong>（<strong style="color: red;">Poisson Distribution</strong>）通常用來模擬在一個固定的時間間隔或空間區域內，某種<strong style="color: blue;">隨機事件</strong>發生的什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">事件發生的時間點。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">事件發生的<strong style="background-color: #ffff0030;">次數</strong>（計數）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">事件發生的成功<strong style="color: blue;">機率</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">事件之間的間隔時間。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">泊松分佈</strong>是一種<strong style="color: blue;">離散機率分佈</strong>，用於描述在一個<strong style="background-color: #ffff0030;">固定的時間、空間、長度或面積等區間</strong>內，某種獨立事件平均發生 <strong style="color: purple;">λ</strong> 次時，實際發生 <strong style="color: purple;">k</strong> 次的<strong style="color: blue;">機率</strong>。其<strong style="color: blue;">機率質量函數</strong>為 <strong style="color: purple;">P(X=k) = (λ^k * exp(-λ)) / k!</strong>，其中 <strong style="color: purple;">k = 0, 1, 2, ...</strong>。<strong style="color: blue;">泊松分佈</strong>適用於描述稀有事件發生的<strong style="background-color: #ffff0030;">次數</strong>，例如一小時內到達某服務台的顧客數量、一頁書中的錯字數量、一個區域內的放射性衰變次數等，前提是事件的發生是獨立的且發生率在區間內是恆定的。<strong style="color: blue;">指數分佈</strong>則描述事件之間的間隔時間。
                    </div>
                 </div>
             </div>

            <!-- Question 39 -->
             <div class="question-card" data-direction="5" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#39</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">對數概似函數</strong>（<strong style="color: red;">Log-Likelihood Function</strong>）相比於原始<strong style="color: blue;">概似函數</strong>，在進行最大化求解時的主要優點是？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">其值域範圍更大。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">將<strong style="background-color: #ffff0030;">乘積運算轉換為求和運算</strong>，簡化了求導計算；且不會改變最大值點的位置。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">可以處理負的<strong style="color: blue;">機率</strong>值。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">使得<strong style="color: blue;">概似函數</strong>變為線性函數。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        原始<strong style="color: blue;">概似函數</strong> <strong style="color: purple;">L(θ|D)</strong> 是各個獨立樣本點<strong style="color: blue;">機率</strong>的<strong style="background-color: #ffff0030;">乘積</strong>：<strong style="color: purple;">L = Π P(xi|θ)</strong>。直接對這個乘積形式求導通常比較複雜。由於對數函數 <strong style="color: red;">log(x)</strong> 是單調遞增函數，最大化 <strong style="color: purple;">L</strong> 等價於最大化 <strong style="color: purple;">log(L)</strong>。取對數後，原來的乘積變成了<strong style="background-color: #ffff0030;">求和</strong>：<strong style="color: purple;">log L = Σ log P(xi|θ)</strong>。<strong style="background-color: #ffff0030;">求和形式</strong>的函數通常<strong style="background-color: #ffff0030;">更容易進行微分運算</strong>（例如求梯度），從而更容易找到最大值點。此外，由於原始<strong style="color: blue;">機率</strong>值通常很小，多個小數相乘可能導致數值下溢（<strong style="color: red;">underflow</strong>），而取對數後變為求和可以避免這個問題。因此，在實際應用中，幾乎總是優化<strong style="color: blue;">對數概似函數</strong>而非原始<strong style="color: blue;">概似函數</strong>。
                    </div>
                 </div>
             </div>

            <!-- Question 40 -->
            <div class="question-card" data-direction="7" data-stars="1">
                 <div class="question-header">
                     <div class="question-id">#40</div>
                     <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">分類</strong>問題中，<strong style="color: blue;">準確率</strong>（<strong style="color: red;">Accuracy</strong>）作為評估指標在哪種情況下可能具有誤導性？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">數據集非常大的時候。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">數據集存在嚴重的<strong style="background-color: #ffff0030;">類別不平衡</strong>（<strong style="color: red;">Class Imbalance</strong>）時。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">模型訓練時間很長的時候。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">模型使用了非線性轉換的時候。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">準確率</strong>計算的是模型預測正確的樣本占總樣本的比例。當數據集中各個類別的樣本數量差異很大時（<strong style="color: blue;">類別不平衡</strong>），<strong style="color: blue;">準確率</strong>可能會產生<strong style="background-color: #ffff0030;">誤導</strong>。例如，在一個數據集中，99% 的樣本屬於負類，只有 1% 屬於正類。一個簡單地將所有樣本都預測為負類的「模型」，其<strong style="color: blue;">準確率</strong>可以達到 99%，看起來很高，但它完全沒有識別出任何正類樣本，對於關心正類識別的任務（如欺詐檢測、罕見病診斷）來說是沒有價值的。在這種情況下，<strong style="color: blue;">精確率</strong>（<strong style="color: red;">Precision</strong>）、<strong style="color: blue;">召回率</strong>（<strong style="color: red;">Recall</strong>）、<strong style="color: purple;">F1</strong> 分數或 <strong style="color: purple;">ROC AUC</strong> 等指標更能反映模型在<strong style="color: blue;">少數類別</strong>上的性能。
                    </div>
                 </div>
             </div>

            <!-- Question 41 -->
             <div class="question-card" data-direction="8" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#41</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">支持向量機</strong>（<strong style="color: red;">Support Vector Machine</strong>, <strong style="color: purple;">SVM</strong>）的目標是找到一個能夠<strong style="background-color: #ffff0030;">最大化</strong>兩類樣本之間<strong style="color: blue;">間隔</strong>（<strong style="color: red;">Margin</strong>）的超平面。這個「<strong style="color: blue;">最大間隔</strong>」的概念與哪個<strong style="color: blue;">統計學</strong>思想有關？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">貝氏定理</strong></div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">結構風險最小化</strong>（<strong style="color: red;">Structural Risk Minimization</strong>），旨在平衡經驗風險（訓練誤差）和模型的複雜度（<strong style="color: blue;">泛化能力</strong>）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">最大概似估計</strong></div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">假設檢定</strong></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: purple;">SVM</strong> 的核心思想是找到一個<strong style="color: blue;">決策邊界</strong>（超平面），使得距離該邊界最近的兩類樣本點（稱為<strong style="color: blue;">支持向量</strong> <strong style="color: red;">Support Vectors</strong>）之間的距離（即<strong style="color: blue;">間隔</strong> <strong style="color: red;">Margin</strong>）<strong style="background-color: #ffff0030;">最大化</strong>。從<strong style="color: blue;">統計學習</strong>理論的角度看，<strong style="color: blue;">最大化間隔</strong>等價於最小化模型的 <strong style="color: purple;">VC</strong> 維（<strong style="color: red;">Vapnik–Chervonenkis dimension</strong>），這是一種衡量模型複雜度或容量的指標。<strong style="color: blue;">結構風險最小化</strong>原則指出，好的模型應該在最小化經驗風險（模型在<strong style="color: blue;">訓練數據</strong>上的誤差）的同時，也最小化置信風險（<strong style="color: red;">Confidence Risk</strong>，與模型複雜度相關，反映<strong style="color: blue;">泛化能力</strong>）。<strong style="color: purple;">SVM</strong> 通過<strong style="color: blue;">最大化間隔</strong>，隱式地控制了模型的複雜度，旨在獲得更好的<strong style="color: blue;">泛化性能</strong>，即使在經驗風險（訓練誤差）為零的情況下，也要選擇最「簡單」（間隔最大）的那個解。
                    </div>
                 </div>
             </div>

            <!-- Question 42 -->
            <div class="question-card" data-direction="1" data-stars="1">
                <div class="question-header">
                    <div class="question-id">#42</div>
                    <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content">一個公正的六面骰子，擲一次出現點數 3 的<strong style="color: blue;">機率</strong>是多少？</div>
                 <div class="options-container">
                    <div class="option-item correct" data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">1/6</div>
                    </div>
                    <div class="option-item " data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text">1/3</div>
                    </div>
                    <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text">1/2</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">1</div>
                    </div>
                 </div>
                 <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">
                        一個公正的六面骰子有 6 個可能的結果（點數 1 到 6），每個結果出現的<strong style="color: blue;">機率</strong>是相等的。樣本空間的大小是 6。事件“出現點數 3”只包含一個結果。因此，該事件的<strong style="color: blue;">機率</strong>是 1/6。
                    </div>
                 </div>
             </div>

             <!-- Question 43 -->
             <div class="question-card" data-direction="3" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#43</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">假設檢定</strong>中的<strong style="color: blue;">顯著水準</strong>（<strong style="color: red;">Significance Level</strong>, <strong style="color: purple;">α</strong>）通常設定為 0.05，這代表什麼意思？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">有 95% 的信心確定<strong style="color: blue;">對立假設</strong>為真。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">我們願意接受最多有 5% 的<strong style="color: blue;">機率</strong>犯<strong style="color: blue;">第一型錯誤</strong>（即<strong style="background-color: #ffff0030;">錯誤地拒絕一個真實的虛無假設</strong>）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: purple;">P</strong> 值必須等於 0.05 才能拒絕<strong style="color: blue;">虛無假設</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">有 5% 的<strong style="color: blue;">機率</strong>犯<strong style="color: blue;">第二型錯誤</strong>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">顯著水準</strong> <strong style="color: purple;">α</strong> 是研究者在進行<strong style="color: blue;">假設檢定</strong>前預先設定的一個閾值，代表了願意承擔犯<strong style="color: blue;">第一型錯誤</strong>（棄真錯誤）的<strong style="background-color: #ffff0030;">最大風險</strong>。設定 <strong style="color: purple;">α = 0.05</strong> 意味著，如果<strong style="color: blue;">虛無假設</strong> <strong style="color: purple;">H0</strong> 實際上是真的，我們仍然允許有 5% 的可能性會根據樣本數據做出拒絕 <strong style="color: purple;">H0</strong> 的錯誤決定。在做出決策時，我們會計算出 <strong style="color: purple;">P</strong> 值，如果 <strong style="color: purple;">P</strong> 值小於或等於 <strong style="color: purple;">α</strong> (<strong style="color: purple;">P ≤ α</strong>)，則拒絕 <strong style="color: purple;">H0</strong>；如果 <strong style="color: purple;">P</strong> 值大於 <strong style="color: purple;">α</strong> (<strong style="color: purple;">P > α</strong>)，則不拒絕 <strong style="color: purple;">H0</strong>。
                    </div>
                 </div>
             </div>

            <!-- Question 44 -->
            <div class="question-card" data-direction="5" data-stars="1">
                 <div class="question-header">
                     <div class="question-id">#44</div>
                     <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">最大概似估計</strong>（<strong style="color: purple;">MLE</strong>）是為了找到使哪個函數最大化的參數？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">損失函數</strong>（<strong style="color: red;">Loss Function</strong>）</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">概似函數</strong>（<strong style="color: red;">Likelihood Function</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">先驗機率</strong>（<strong style="color: red;">Prior Probability</strong>）</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">後驗機率</strong>（<strong style="color: red;">Posterior Probability</strong>）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        根據定義，<strong style="color: blue;">最大概似估計</strong>（<strong style="color: red;">Maximum Likelihood Estimation</strong>, <strong style="color: purple;">MLE</strong>）尋找的是能夠<strong style="background-color: #ffff0030;">最大化觀測數據出現機率</strong>（即<strong style="color: blue;">概似函數</strong> <strong style="color: purple;">L(θ|D) = P(D|θ)</strong>）的模型參數 <strong style="color: purple;">θ</strong>。<strong style="color: blue;">最小化損失函數</strong>是另一種常見的模型優化方法，但與<strong style="color: purple;">MLE</strong>不完全等價（雖然在某些情況下，如最小化平方誤差對應高斯<strong style="color: blue;">噪聲</strong>下的<strong style="color: purple;">MLE</strong>，最小化<strong style="color: blue;">交叉熵</strong>對應<strong style="color: blue;">分類</strong>問題的<strong style="color: purple;">MLE</strong>）。最大化<strong style="color: blue;">先驗機率</strong>與<strong style="color: blue;">參數估計</strong>無關。最大化<strong style="color: blue;">後驗機率</strong>是<strong style="color: blue;">最大後驗估計</strong>（<strong style="color: purple;">MAP</strong>）的目標。
                    </div>
                 </div>
             </div>

            <!-- Question 45 -->
             <div class="question-card" data-direction="6" data-stars="1">
                 <div class="question-header">
                     <div class="question-id">#45</div>
                     <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">資訊理論</strong>中用來度量<strong style="color: blue;">資訊量</strong>的基本單位通常是什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">赫茲（<strong style="color: red;">Hertz</strong>）</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">位元</strong>（<strong style="color: red;">Bit</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">焦耳（<strong style="color: red;">Joule</strong>）</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">牛頓（<strong style="color: red;">Newton</strong>）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        在<strong style="color: blue;">資訊理論</strong>中，<strong style="color: blue;">資訊量</strong>（例如<strong style="color: blue;">熵</strong>、<strong style="color: blue;">互信息</strong>）通常使用<strong style="color: blue;">位元</strong>（<strong style="color: red;">Bit</strong>）作為基本單位。這源於<strong style="color: blue;">資訊量</strong>通常定義為基於以 2 為底的對數（<strong style="color: red;">log base 2</strong>）。一個<strong style="color: blue;">位元</strong>代表了一個可以取兩種等可能狀態（如0或1，是或否）的系統所包含的<strong style="color: blue;">資訊量</strong>。赫茲是頻率單位，焦耳是能量單位，牛頓是力的單位。
                    </div>
                 </div>
             </div>

            <!-- Question 46 -->
            <div class="question-card" data-direction="7" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#46</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">正規化</strong>（<strong style="color: red;">Regularization</strong>）技術（如 <strong style="color: purple;">L1</strong> 或 <strong style="color: purple;">L2</strong> <strong style="color: blue;">正規化</strong>）在<strong style="color: blue;">機器學習模型</strong>訓練中常用來防止<strong style="color: blue;">過擬合</strong>。從<strong style="color: blue;">統計學</strong>角度看，加入<strong style="color: blue;">正規化</strong>項相當於在<strong style="color: blue;">參數估計</strong>中引入了什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">更多的訓練數據。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">對模型參數的<strong style="background-color: #ffff0030;">先驗信念或約束</strong>（相當於<strong style="color: blue;">貝氏推斷</strong>中的<strong style="color: blue;">先驗分佈</strong>）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">更高的模型複雜度。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">交叉驗證</strong>過程。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">正規化</strong>通過在原始的<strong style="color: blue;">損失函數</strong>（如<strong style="color: blue;">最小平方誤差</strong>或<strong style="color: blue;">交叉熵</strong>）上添加一個關於模型參數大小的懲罰項，來限制模型的複雜度，防止模型<strong style="color: blue;">過度擬合</strong>訓練數據。從<strong style="color: blue;">貝氏</strong>的角度來看，這等價於為模型參數引入了一個<strong style="color: blue;">先驗分佈</strong>，並進行<strong style="color: blue;">最大後驗估計</strong>（<strong style="color: purple;">MAP</strong>）。例如：<br>
                        <ul>
                            <li><strong style="color: purple;">L2</strong> <strong style="color: blue;">正規化</strong>（<strong style="color: blue;">權重衰減</strong> <strong style="color: red;">Weight Decay</strong>）：懲罰項是參數平方和 <strong style="color: purple;">λ||w||²</strong>。這相當於假設參數 <strong style="color: purple;">w</strong> 服從均值為 0 的<strong style="color: blue;">高斯先驗分佈</strong>。</li>
                            <li><strong style="color: purple;">L1</strong> <strong style="color: blue;">正規化</strong>（<strong style="color: red;">LASSO</strong>）：懲罰項是參數絕對值之和 <strong style="color: purple;">λ||w||₁</strong>。這相當於假設參數 <strong style="color: purple;">w</strong> 服從均值為 0 的<strong style="color: blue;">拉普拉斯先驗分佈</strong>。<strong style="color: purple;">L1</strong> <strong style="color: blue;">正規化</strong>傾向於產生稀疏解（使一些參數變為0），有助於<strong style="color: blue;">特徵選擇</strong>。</li>
                        </ul>
                        因此，<strong style="color: blue;">正規化</strong>可以被視為將關於參數的<strong style="color: blue;">先驗知識</strong>（例如，偏好更小或更稀疏的參數）納入模型學習過程的一種方式。
                    </div>
                 </div>
             </div>

            <!-- Question 47 -->
            <div class="question-card" data-direction="8" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#47</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">隱馬可夫模型</strong>（<strong style="color: red;">Hidden Markov Model</strong>, <strong style="color: purple;">HMM</strong>）是一種用於處理<strong style="color: blue;">序列數據</strong>的<strong style="color: blue;">機率模型</strong>。它包含一組觀察不到的<strong style="color: blue;">隱藏狀態</strong>和一組可觀測的輸出。模型基於哪兩個核心的<strong style="color: blue;">機率假設</strong>？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">觀察值之間相互獨立；<strong style="color: blue;">隱藏狀態</strong>之間相互獨立。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">齊次馬可夫性假設</strong>（當前<strong style="color: blue;">隱藏狀態</strong>只依賴於前一個<strong style="color: blue;">隱藏狀態</strong>）；<strong style="color: blue;">觀察獨立性假設</strong>（當前觀察值只依賴於當前的<strong style="color: blue;">隱藏狀態</strong>）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">所有<strong style="color: blue;">隱藏狀態</strong>都服從<strong style="color: blue;">高斯分佈</strong>；所有觀察值都服從<strong style="color: blue;">高斯分佈</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">隱藏狀態</strong>數量必須等於觀察值數量；狀態轉移<strong style="color: blue;">機率</strong>必須為 0.5。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: purple;">HMM</strong> 的兩個基本假設是：<br>
                        <ol>
                            <li><b><strong style="color: blue;">齊次馬可夫性假設</strong> (<strong style="color: red;">Homogeneous Markov Assumption</strong>)</b>：在時間 t 的<strong style="color: blue;">隱藏狀態</strong> <strong style="color: purple;">St</strong> 只取決於時間 t-1 的<strong style="color: blue;">隱藏狀態</strong> <strong style="color: purple;">S(t-1)</strong>，而與更早之前的狀態無關。即 <strong style="color: purple;">P(St | S(t-1), S(t-2), ..., S1) = P(St | S(t-1))</strong>。這描述了狀態之間的轉移關係。</li>
                            <li><b><strong style="color: blue;">觀察獨立性假設</strong> (<strong style="color: red;">Observation Independence Assumption</strong>)</b>：在時間 t 的觀察值 <strong style="color: purple;">Ot</strong> 只取決於時間 t 的<strong style="color: blue;">隱藏狀態</strong> <strong style="color: purple;">St</strong>，而與其他時間的狀態或觀察值無關。即 <strong style="color: purple;">P(Ot | St, S(t-1), ..., S1, O(t-1), ..., O1) = P(Ot | St)</strong>。這描述了狀態如何生成觀察值。</li>
                        </ol>
                        基於這兩個假設，<strong style="color: purple;">HMM</strong> 可以有效地對<strong style="color: blue;">序列數據</strong>進行建模，常用於<strong style="color: blue;">語音識別</strong>、<strong style="color: blue;">自然語言處理</strong>（如<strong style="color: blue;">詞性標註</strong>）、生物信息學等領域。模型的參數包括初始狀態<strong style="color: blue;">機率</strong>、狀態轉移<strong style="color: blue;">機率矩陣</strong>和觀察（發射）<strong style="color: blue;">機率矩陣</strong>，通常使用 <strong style="color: purple;">EM</strong> <strong style="color: blue;">算法</strong>（<strong style="color: red;">Baum-Welch</strong> <strong style="color: blue;">算法</strong>）進行學習。
                    </div>
                 </div>
             </div>

            <!-- Question 48 -->
            <div class="question-card" data-direction="1" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#48</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><strong style="color: blue;">大數法則</strong>（<strong style="color: red;">Law of Large Numbers</strong>, <strong style="color: purple;">LLN</strong>）告訴我們，當<strong style="color: blue;">獨立同分佈</strong>的<strong style="color: blue;">隨機試驗</strong>次數趨於無窮時，<strong style="color: blue;">樣本平均值</strong>會趨近於？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">0</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">隨機變數</strong>的<strong style="color: blue;">期望值</strong>（<strong style="color: blue;">總體均值</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><strong style="color: blue;">隨機變數</strong>的<strong style="color: blue;">變異數</strong></div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><strong style="color: blue;">樣本中位數</strong></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">大數法則</strong>是<strong style="color: blue;">機率論</strong>中的另一個基石性定理。它有<strong style="color: blue;">弱大數法則</strong>（<strong style="color: red;">Weak Law of Large Numbers</strong>, <strong style="color: purple;">WLLN</strong>）和<strong style="color: blue;">強大數法則</strong>（<strong style="color: red;">Strong Law of Large Numbers</strong>, <strong style="color: purple;">SLLN</strong>）兩種形式，但核心思想都是一樣的：隨著試驗次數 <strong style="color: purple;">n</strong> 的增加，從<strong style="color: blue;">獨立同分佈</strong>的<strong style="color: blue;">隨機變數</strong> <strong style="color: purple;">X1, ..., Xn</strong> 得到的<strong style="color: blue;">樣本平均值</strong> <strong style="color: purple;">X̄n = (X1 + ... + Xn) / n</strong> 會<strong style="background-color: #ffff0030;">越來越接近</strong>該<strong style="color: blue;">隨機變數</strong>的真實<strong style="color: blue;">期望值</strong> <strong style="color: purple;">E[X]</strong>（即<strong style="color: blue;">總體均值</strong> <strong style="color: purple;">μ</strong>）。<strong style="color: purple;">WLLN</strong> 描述的是<strong style="color: blue;">樣本均值</strong>依<strong style="color: blue;">機率</strong>收斂於<strong style="color: blue;">期望值</strong>，<strong style="color: purple;">SLLN</strong> 描述的是<strong style="color: blue;">樣本均值</strong>幾乎必然收斂於<strong style="color: blue;">期望值</strong>。<strong style="color: blue;">大數法則</strong>為使用<strong style="color: blue;">樣本均值</strong>來估計<strong style="color: blue;">總體均值</strong>提供了理論基礎，也是<strong style="color: blue;">頻率學派</strong>對<strong style="color: blue;">機率</strong>解釋的基礎之一（事件的<strong style="color: blue;">機率</strong>是其在大量重複試驗中發生的相對頻率的極限）。
                    </div>
                 </div>
             </div>

             <!-- Question 49 -->
             <div class="question-card" data-direction="4" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#49</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">在<strong style="color: blue;">貝氏網路</strong>（<strong style="color: red;">Bayesian Network</strong>）中，節點代表<strong style="color: blue;">隨機變數</strong>，有向邊代表<strong style="color: blue;">變數</strong>之間的什麼關係？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><strong style="color: blue;">線性相關</strong>關係</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><strong style="color: blue;">條件依賴關係</strong>（<strong style="color: red;">Conditional Dependencies</strong>）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">時間先後順序</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">物理<strong style="color: blue;">因果關係</strong>（不一定）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        <strong style="color: blue;">貝氏網路</strong>是一種<strong style="color: blue;">機率圖模型</strong>（<strong style="color: red;">Probabilistic Graphical Model</strong>），它使用<strong style="color: blue;">有向無環圖</strong>（<strong style="color: red;">Directed Acyclic Graph</strong>, <strong style="color: purple;">DAG</strong>）來表示一組<strong style="color: blue;">隨機變數</strong>及其之間的<strong style="background-color: #ffff0030;">條件依賴關係</strong>。圖中的每個節點代表一個<strong style="color: blue;">隨機變數</strong>，從節點 A 指向節點 B 的有向邊表示<strong style="color: blue;">變數</strong> B 直接依賴於<strong style="color: blue;">變數</strong> A（A 是 B 的一個「父節點」）。<strong style="color: blue;">貝氏網路</strong>的結構隱含了一系列<strong style="color: blue;">條件獨立性</strong>假設：每個<strong style="color: blue;">變數</strong>在給定其父節點的條件下，與其所有非後代節點（<strong style="color: red;">non-descendants</strong>）是<strong style="color: blue;">條件獨立</strong>的。結合每個節點對應的<strong style="color: blue;">條件機率表</strong>（<strong style="color: red;">Conditional Probability Table</strong>, <strong style="color: purple;">CPT</strong>），<strong style="color: blue;">貝氏網路</strong>可以緊湊地表示<strong style="color: blue;">變數</strong>集合的<strong style="color: blue;">聯合機率分佈</strong>，並用於進行<strong style="color: blue;">機率推斷</strong>（如計算<strong style="color: blue;">邊際機率</strong>、<strong style="color: blue;">條件機率</strong>）。雖然有向邊常表示影響關係，但不一定嚴格代表物理上的<strong style="color: blue;">因果關係</strong>。
                    </div>
                 </div>
             </div>

            <!-- Question 50 -->
            <div class="question-card" data-direction="7" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#50</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content">當比較兩個<strong style="color: blue;">機器學習模型</strong>的性能時，僅僅比較它們在<strong style="background-color: #ffff0030;">單一測試集</strong>上的<strong style="color: blue;">準確率</strong>可能不夠可靠，因為<strong style="color: blue;">測試集</strong>的劃分可能存在隨機性。<strong style="color: blue;">統計假設檢定</strong>（如<strong style="color: blue;">配對 t 檢定</strong> <strong style="color: red;">Paired t-test</strong>）可以用來做什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">確定哪個模型的訓練時間更短。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">判斷兩個模型性能之間的<strong style="background-color: #ffff0030;">差異是否具有統計顯著性</strong>（<strong style="color: red;">Statistical Significance</strong>），而不僅僅是隨機波動造成的。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">選擇模型使用的最佳<strong style="color: blue;">特徵</strong>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">計算每個模型的參數數量。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">
                        當我們比較模型 A 和模型 B 在某個（或多個）<strong style="color: blue;">測試集</strong>上的性能指標（如<strong style="color: blue;">準確率</strong>）時，即使看到一個指標略高於另一個，這種差異也可能僅僅是由於數據劃分的隨機性或測量誤差造成的。<strong style="color: blue;">統計假設檢定</strong>提供了一種更嚴謹的方法來判斷觀察到的性能差異是否「真實」存在，還是很可能僅僅是偶然現象。例如，可以使用<strong style="color: blue;">配對 t 檢定</strong>（如果在同一個 <strong style="color: purple;">K</strong> 折交叉驗證的不同折上比較兩個模型）或 <strong style="color: red;">McNemar</strong> 檢定（比較兩個模型在同一個<strong style="color: blue;">測試集</strong>上的錯誤分類是否顯著不同）來檢驗「兩個模型性能沒有差異」的<strong style="color: blue;">虛無假設</strong>。如果檢定結果的 <strong style="color: purple;">P</strong> 值小於<strong style="color: blue;">顯著水準</strong> <strong style="color: purple;">α</strong>，我們就可以拒絕<strong style="color: blue;">虛無假設</strong>，認為兩個模型的性能差異具有<strong style="background-color: #ffff0030;">統計顯著性</strong>。
                    </div>
                 </div>
             </div>


        </div>

        <div id="noResultsMessage" style="display: none;">沒有找到符合條件的題目。</div>

        <div class="back-to-top" id="backToTop">↑</div>
    </div>

    <script>
        let explanationsVisible = true; // Explanations start visible
        let answersVisible = true; // Answers start visible
        let correctAnswers = []; // Store information about correct answers

        // Progress bar
        const progressBar = document.getElementById("progressBar");
        window.onscroll = function() {
            updateProgressBar();
            toggleBackToTopButton();
        };

        function updateProgressBar() {
            let winScroll = document.body.scrollTop || document.documentElement.scrollTop;
            let height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
             if (height > 0) {
                 let scrolled = (winScroll / height) * 100;
                 progressBar.style.width = scrolled + "%";
             } else {
                  progressBar.style.width = "0%"; // Handle case where content height is less than viewport
             }
        }

        // Back to top button
        const backToTopButton = document.getElementById("backToTop");

        function toggleBackToTopButton() {
             if (document.body.scrollTop > 100 || document.documentElement.scrollTop > 100) {
                backToTopButton.style.display = "flex";
            } else {
                backToTopButton.style.display = "none";
            }
        }

        backToTopButton.addEventListener("click", function() {
            window.scrollTo({top: 0, behavior: 'smooth'});
        });

        // Filter by direction (called from direction items)
        function filterByDirection(directionNumber) {
            document.getElementById('directionFilter').value = directionNumber === 'all' ? 'all' : String(directionNumber);
            filterQuestions();
        }

        // Event listeners for filters and search
        document.getElementById("directionFilter").addEventListener("change", filterQuestions);
        document.getElementById("starFilter").addEventListener("change", filterQuestions); // Listener for star filter
        document.getElementById("searchButton").addEventListener("click", searchQuestions);
        document.getElementById("searchInput").addEventListener("keyup", function(event) {
            // Trigger search on Enter key press
             if (event.key === "Enter") {
                 searchQuestions();
             }
             // Optional: Trigger filtering immediately as user types
             // filterQuestions(); // Uncomment for live search filtering
             // Or search on empty input to reset filters
             if (document.getElementById("searchInput").value.trim() === '') {
                searchQuestions(); // Will call filterQuestions inside if empty
             }
        });
         // let searchTimeout; // For delayed search on keyup


        // Combined filter and visibility function
        function applyFiltersAndSearch() {
            let direction = document.getElementById("directionFilter").value;
            let stars = document.getElementById("starFilter").value;
            let searchText = document.getElementById("searchInput").value.toLowerCase().trim();
            let questions = document.querySelectorAll(".question-card");
            let anyVisible = false;
            const noResultsMessage = document.getElementById('noResultsMessage');

            questions.forEach(function(question) {
                const matchesDirection = (direction === "all" || question.dataset.direction === direction);
                const matchesStars = (stars === "all" || question.dataset.stars === stars);
                const questionText = question.textContent.toLowerCase();
                const matchesSearch = (searchText === "" || questionText.includes(searchText));

                // Show question if it matches all active filters (direction, stars, search)
                if (matchesDirection && matchesStars && matchesSearch) {
                    question.style.display = "block";
                    anyVisible = true;
                } else {
                    question.style.display = "none";
                }
            });

             // Show/hide the 'no results' message
             if (noResultsMessage) {
                 noResultsMessage.style.display = anyVisible ? 'none' : 'block';
                 // Adjust message based on whether it was filtering or searching
                  if (!anyVisible) {
                      if (searchText !== "") {
                          noResultsMessage.textContent = '沒有找到符合搜尋條件的題目。';
                      } else if (direction !== 'all' || stars !== 'all') {
                          noResultsMessage.textContent = '沒有找到符合篩選條件的題目。';
                      } else {
                           noResultsMessage.textContent = '題庫為空或發生錯誤。'; // Fallback
                      }
                  }
             }
             // Ensure progress bar updates after filtering changes layout
            updateProgressBar();
        }


        // Trigger combined function for filters and search
        function filterQuestions() {
            applyFiltersAndSearch();
        }

        function searchQuestions() {
            applyFiltersAndSearch();
        }


        // Toggle explanations visibility
        document.getElementById("toggleExplanations").addEventListener("click", function() {
            let explanations = document.querySelectorAll(".explanation-container");
            explanationsVisible = !explanationsVisible;
            let button = document.getElementById("toggleExplanations");

            explanations.forEach(function(explanation) {
                explanation.style.display = explanationsVisible ? "block" : "none";
            });

            button.textContent = explanationsVisible ? "隱藏全部解析" : "顯示全部解析";
            // Update progress bar in case toggling changes page height significantly
            updateProgressBar();
        });

        // Click options (no interactive grading logic needed as per example)


        // Initialize correct answers data
        function initializeCorrectAnswers() {
            let correctOptions = document.querySelectorAll(".option-item.correct");
            correctAnswers = [];
            
            correctOptions.forEach(function(option) {
                let strongElements = option.querySelectorAll("strong[style*='background-color']");
                let strongData = [];
                
                strongElements.forEach(function(strong) {
                    strongData.push({
                        element: strong,
                        originalStyle: strong.getAttribute('style'),
                        text: strong.textContent
                    });
                });
                
                correctAnswers.push({
                    element: option,
                    strongElements: strongData
                });
            });
        }

        // Toggle answers visibility
        document.getElementById("toggleAnswers").addEventListener("click", function() {
            answersVisible = !answersVisible;
            let button = document.getElementById("toggleAnswers");
            
            correctAnswers.forEach(function(correctAnswer) {
                if (answersVisible) {
                    // Show answers: restore correct class and strong styling
                    correctAnswer.element.classList.add("correct");
                    correctAnswer.strongElements.forEach(function(strongData) {
                        strongData.element.style.backgroundColor = "#ffff0030";
                        strongData.element.style.fontWeight = "bold";
                    });
                } else {
                    // Hide answers: remove correct class and strong styling
                    correctAnswer.element.classList.remove("correct");
                    correctAnswer.strongElements.forEach(function(strongData) {
                        strongData.element.style.backgroundColor = "";
                        strongData.element.style.fontWeight = "normal";
                    });
                }
            });
            
            button.textContent = answersVisible ? "隱藏全部解答" : "顯示全部解答";
        });        let options = document.querySelectorAll(".option-item");
        options.forEach(function(option) {
            option.addEventListener("click", function() {
                // Example doesn't highlight selection persistently, so no action needed here.
                // If needed, add logic to add/remove a 'selected' class.
            });
        });

         // Initial setup
         
         initializeCorrectAnswers(); // Initialize correct answers data
         toggleBackToTopButton(); // Check initial scroll position
         updateProgressBar(); // Set initial progress bar state
         filterQuestions(); // Apply filters (and potentially empty search) on initial load
         // Set initial state for toggle button text
         document.getElementById("toggleExplanations").textContent = explanationsVisible ? "隱藏全部解析" : "顯示全部解析";
          // Ensure explanations start visible as per initial state
          let initialExplanations = document.querySelectorAll(".explanation-container");
          initialExplanations.forEach(exp => exp.style.display = "block");

    </script>
</body>
</html>