<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <title>檔案6：L11301 機器學習基本原理（100題）</title>
    <style>
        /* RWD設定，讓整體版面在不同裝置都有良好顯示 */
        * {
            box-sizing: border-box;
        }
        body {
            margin: 0;
            padding: 0;
            font-family: "Microsoft JhengHei", sans-serif;
            background: #f5f5f5;
            color: #333;
        }
        .container {

            margin: 0 auto;
            padding: 20px;
            background: #ffffff;
        }
        h1, h2 {
            text-align: center;
            margin-bottom: 10px;
        }
        h1 {
            margin-top: 20px;
            font-size: 1.8rem;
            color: #444;
        }
        .question-block {
            border: 3px solid #888;
            border-radius: 6px;
            margin: 25px 0;
            padding: 15px;
            background: #fdfdfd;
        }
        .question-header {
            font-weight: bold;
            font-size: 1.1rem;
            margin-bottom: 10px;
            color: #0b3d86; /* 藍色字體凸顯 */
        }
        .question {
            margin-bottom: 10px;
            line-height: 1.6;
        }
        .options {
            margin: 8px 0;
            line-height: 1.8;
        }
        .reference {
            font-size: 0.9rem;
            color: #666;
            margin-bottom: 10px;
        }
        .answer {
            margin-top: 10px;
            font-size: 1rem;
        }
        .correct {
            color: red; /* 正確答案用紅色標示 */
            font-weight: bold;
        }
        .explanation {
            margin-top: 5px;
            color: blue; /* 解析用藍色 */
        }
        /* 以簡易方式示範:hover效果，可靜態修改外觀 */
        .question-block:hover {
            background: #eef;
            transition: 0.3s;
        }
        /* 簡易JS按鈕相關，可自行改寫 */
        .toggle-btn {
            display: inline-block;
            margin-top: 10px;
            padding: 6px 10px;
            background-color: #d1ecf1;
            color: #0c5460;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
        }
        .toggle-content {
            display: none; 
            margin-top: 8px;
            padding: 10px;
            background: #fff;
            border: 1px solid #ccc;
            border-radius: 4px;
        }
        .responsive-img {
            width: 100%;
            max-width: 800px; /* 可自訂最大寬度 */
            height: auto;
        }
        @media (max-width: 768px) {
            .question-header {
                font-size: 1rem;
            }
            .question {
                font-size: 0.95rem;
            }
            .container {
                width: 95%;
            }
        }
    </style>
    <script>
        /* 簡易JS：顯示或隱藏答案與解析 */
        function toggleContent(id) {
            var content = document.getElementById(id);
            if(content.style.display === "none") {
                content.style.display = "block";
            } else {
                content.style.display = "none";
            }
        }
        let explanationsVisible = false;
        let answersVisible = true;
        document.getElementById("toggleExplanations").addEventListener("click", function() {
            let explanations = document.querySelectorAll(".explanation-container");
            explanationsVisible = !explanationsVisible;
            let button = document.getElementById("toggleExplanations");
            explanations.forEach(function(explanation) {
                const questionCard = explanation.closest('.question-card');
                if (questionCard && questionCard.style.display !== 'none') {
                    explanation.style.display = explanationsVisible ? "block" : "none";
                }
            });
            button.textContent = explanationsVisible ? "隱藏全部解析" : "顯示全部解析";
        });
        document.getElementById("toggleAnswers").addEventListener("click", function() {
            answersVisible = !answersVisible;
            let button = document.getElementById("toggleAnswers");
            let allOptions = document.querySelectorAll('.option-item[data-option]');
            if (!answersVisible) {
                allOptions.forEach(function(opt){
                    opt.classList.remove('correct');
                });
                button.textContent = "顯示全部答案";
            } else {
                allOptions.forEach(function(opt){
                    if (opt.dataset.originalCorrect === 'true') {
                        opt.classList.add('correct');
                    }
                });
                button.textContent = "隱藏全部答案";
            }
        });
        document.addEventListener('DOMContentLoaded', (event) => {
            // ... existing code ...
            let allOptions = document.querySelectorAll('.option-item[data-option]');
            allOptions.forEach(function(opt) {
                if (opt.classList.contains('correct')) {
                    opt.dataset.originalCorrect = 'true';
                } else {
                    opt.dataset.originalCorrect = 'false';
                }
            });
        });
    </script>
</head>
<body>
    <div class="container">
        <h1>檔案6：L11301 機器學習基本原理（100題）</h1>
        <h2>共100題（難度比照初級樣題）</h2>

        <!-- 題目 1 -->
        <div class="question-block">
            <div class="question-header">
                1. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）
            </div>
            <div class="question">
                機器學習 (Machine Learning) 最核心的意義是什麼？
            </div>
            <div class="options">
                A. 全部以 if-else 規則寫死<br>
                B. 用大量硬體取代演算法<br>
                <span class="correct">C. 透過資料和演算法，學習經驗規律並在未見資料上做預測或決策</span><br>
                D. 只是一種行銷名詞，無實際應用
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：機器學習能根據資料學到模型或規則，在未知情境下做預測或分類等任務。
                </div>
                <img src="image/Machine-Learning.webp" alt="Machine Learning" class="responsive-img">
            </div>
        </div>

        <!-- 題目 2 -->
        <div class="question-block">
            <div class="question-header">
                2. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第32頁）
            </div>
            <div class="question">
                監督式學習可再分為「分類 (Classification)」與哪一種類型？
            </div>
            <div class="options">
                A. 分群 (Clustering)<br>
                B. 降維 (Dimensionality Reduction)<br>
                <span class="correct">C. 迴歸 (Regression)</span><br>
                D. 獎懲式學習 (Reinforcement)
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：監督式學習分為分類(目標為離散)與迴歸(目標為連續數值)，是最常見的兩大類。
                </div>
                <img src="image/regression-vs-classification.webp" alt="Regression vs Classification" class="responsive-img">
            </div>
        </div>

        <!-- 題目 3 -->
        <div class="question-block">
            <div class="question-header">
                3. 出題頻率/重要性：★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                下列哪個任務最有可能使用「非監督式學習」？
            </div>
            <div class="options">
                <span class="correct">A. 分群客戶群，找出相似行為的客群</span><br>
                B. 預測未來銷量<br>
                C. 辨識郵件是否垃圾信<br>
                D. 預測股票價格
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：非監督式學習沒有標籤，如分群。其餘皆屬監督式(目標已知)或時間序列預測。
                </div>
            </div>
        </div>

        <!-- 題目 4 -->
        <div class="question-block">
            <div class="question-header">
                4. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第12頁）
            </div>
            <div class="question">
                「強化式學習 (Reinforcement Learning)」與監督式學習最大差異是？
            </div>
            <div class="options">
                A. 強化式學習只用靜態資料<br>
                <span class="correct">B. 强化式學習透過試誤與即時獎勵或懲罰來學習行為策略</span><br>
                C. 強化式學習與監督式一樣都需要標籤<br>
                D. 強化式學習無需任何資料
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：強化式學習在互動環境中累積獎勵，非一次性給出正確標籤。
                </div>
                <img src="image/Reinforcement Learning.jpg" class="responsive-img">
            </div>
        </div>

        <!-- 題目 5 -->
        <div class="question-block">
            <div class="question-header">
                5. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）
            </div>
            <div class="question">
                機器學習流程的關鍵步驟依序為？
            </div>
            <div class="options">
                <span class="correct">A. 資料蒐集 → 特徵處理 → 建模訓練 → 評估 → 部署</span><br>
                B. 只用現成 API<br>
                C. 先部署再資料蒐集<br>
                D. 直接修改程式即可
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：典型機器學習流程先有資料，再做清理/特徵，再來建立模型、評估效果，最後部署應用。
                </div>
            </div>
        </div>

        <!-- 題目 6 -->
        <div class="question-block">
            <div class="question-header">
                6. 出題頻率/重要性：★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第40頁）
            </div>
            <div class="question">
                當模型在訓練資料表現良好，卻在測試資料表現很差，通常稱為？
            </div>
            <div class="options">
                <span class="correct">A. 過擬合 (Overfitting)</span><br>
                B. 欠擬合 (Underfitting)<br>
                C. 偏差過大<br>
                D. 權重初始化錯誤
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：過擬合代表模型過度貼合訓練集，無法泛化。
                </div>
                <img src="image/Overfitting.svg" class="responsive-img">
            </div>
        </div>

        <!-- 題目 7 -->
        <div class="question-block">
            <div class="question-header">
                7. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                欠擬合 (Underfitting) 常意味著？
            </div>
            <div class="options">
                A. 模型太複雜<br>
                B. 訓練集誤差極低<br>
                <span class="correct">C. 模型沒學到充分特徵，訓練與測試效果都不佳</span><br>
                D. 與資料量無關
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：欠擬合是模型表現不佳，可能特徵不足或模型表達能力太弱。
                </div>
                <img src="image/overfitting underfitting.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 8 -->
        <div class="question-block">
            <div class="question-header">
                8. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第25頁）
            </div>
            <div class="question">
                下列何者屬於「決策樹 (Decision Tree)」的優點？
            </div>
            <div class="options">
                <span class="correct">A. 易於理解與解釋，能以樹狀結構視覺化</span><br>
                B. 一定比所有模型都準<br>
                C. 無法分類離散值<br>
                D. 僅能做影像辨識
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：決策樹的可解釋性高，規則像 if-else，但易過擬合，常搭配集成方法（如隨機森林）。
                </div>
                <img src="image/Decision-Tree.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 9 -->
        <div class="question-block">
            <div class="question-header">
                9. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                「隨機森林 (Random Forest)」相較於單一決策樹，有何優勢？
            </div>
            <div class="options">
                <span class="correct">A. 透過多棵樹投票，降低過擬合、提高穩定性與預測準確度</span><br>
                B. 單一樹一定比森林好<br>
                C. 無差別<br>
                D. 隨機森林只適用迴歸
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：隨機森林在每棵樹訓練使用部分資料與特徵，最終投票或平均，可減少樹的高度過擬合。
                </div>
                <img src="image/Random Forest.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 10 -->
        <div class="question-block">
            <div class="question-header">
                10. 出題頻率/重要性：★
            </div>
            <div class="reference">
                由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）
            </div>
            <div class="question">
                常見的「線性迴歸 (Linear Regression)」假設為何？
            </div>
            <div class="options">
                A. 輸出必為 0 或 1<br>
                <span class="correct">B. 目標和特徵呈線性關係，可用 w·x + b 來描述</span><br>
                C. 僅能做分類<br>
                D. 不需任何假設
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：線性迴歸基本模型為 y = w<sub>1</sub>x<sub>1</sub> + … + w<sub>n</sub>x<sub>n</sub> + b，假設輸出可視作線性組合。
                </div>
                <img src="image/Linear Regression.jpg" class="responsive-img">"
            </div>
        </div>

        <!-- 題目 11 -->
        <div class="question-block">
            <div class="question-header">
                11. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                下列哪個度量較常用來評估迴歸模型的誤差？
            </div>
            <div class="options">
                <span class="correct">A. 均方誤差 (Mean Squared Error, MSE)</span><br>
                B. 準確率 (Accuracy)<br>
                C. AUC<br>
                D. F1-score
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：MSE、MAE、RMSE 是最常見迴歸模型評估方式，Accuracy、AUC、F1-score 則多用於分類。
                </div>
                <img src="image/MSE.jpeg" class="responsive-img">
            </div>
        </div>

        <!-- 題目 12 -->
        <div class="question-block">
            <div class="question-header">
                12. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第35頁）
            </div>
            <div class="question">
                為何要分割訓練集與測試集？
            </div>
            <div class="options">
                A. 只為資料儲存方便<br>
                B. 訓練集只給資深工程師<br>
                <span class="correct">C. 用測試集評估泛化能力，避免模型只記住訓練數據</span><br>
                D. 能增加模型參數
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：測試集是用於最終檢驗模型對新資料的表現，防止過擬合狀態下的假性高分。
                </div>
                <img src="image/train validation and test set.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 13 -->
        <div class="question-block">
            <div class="question-header">
                13. 出題頻率/重要性：★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                何謂「學習率 (Learning Rate)」在迴歸或神經網路訓練中的角色？
            </div>
            <div class="options">
                <span class="correct">A. 控制每次權重更新的步伐大小，太大易震盪，太小收斂慢</span><br>
                B. 與訓練無關<br>
                C. 僅用於強化式學習<br>
                D. 一定愈大愈好
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：學習率決定梯度下降一步走多遠，需適度調整才能穩定收斂。
                </div>
                <img src="image/Learning Rate2.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 14 -->
        <div class="question-block">
            <div class="question-header">
                14. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第45頁）
            </div>
            <div class="question">
                「批量梯度下降 (Batch Gradient Descent)」與「隨機梯度下降 (SGD)」差異？
            </div>
            <div class="options">
                <span class="correct">A. 前者一次用全部訓練資料計算梯度，後者每次用單一或少量樣本</span><br>
                B. SGD只用於測試集<br>
                C. 批量梯度下降比較快<br>
                D. 兩者無差別
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：批量梯度下降計算更精確但可能較慢，SGD每次更新速度快但帶隨機性。
                </div>
                <img src="image/Mini-Batch Gradient Descent.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 15 -->
        <div class="question-block">
            <div class="question-header">
                15. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）
            </div>
            <div class="question">
                下列哪些方法常用來避免模型過度擬合？
            </div>
            <div class="options">
                A. 不用測試集<br>
                <span class="correct">B. 正則化 (如 L1、L2)、資料增強 (Data Augmentation)、提前停止 (Early Stopping)</span><br>
                C. 無需預防<br>
                D. 分群演算法
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：正則化可壓縮權重避免過大，Data Augmentation 提高資料多樣性，Early Stopping 根據驗證集判斷訓練是否過度。
                </div>
            </div>
        </div>

        <!-- 題目 16 -->
        <div class="question-block">
            <div class="question-header">
                16. 出題頻率/重要性：★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                在資料集中若不同類別分佈嚴重不平衡，預測模型可能？
            </div>
            <div class="options">
                A. 更容易<br>
                B. 不會有任何問題<br>
                <span class="correct">C. 偏向多數類別，忽略少數類別，需採取平衡策略</span><br>
                D. 與分佈無關
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：嚴重不平衡時，模型可能只猜最多類別；可用 Oversampling/Undersampling/SMOTE 等策略平衡。
                </div>
            </div>
        </div>

        <!-- 題目 17 -->
        <div class="question-block">
            <div class="question-header">
                17. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第40頁）
            </div>
            <div class="question">
                何謂「偏差 (Bias)」與「變異 (Variance)」在模型誤差分解中的含意？
            </div>
            <div class="options">
                <span class="correct">A. 偏差指模型簡化所造成的系統性誤差，變異指模型對不同資料的敏感度</span><br>
                B. 兩者皆指硬體問題<br>
                C. 僅適用於深度學習<br>
                D. 無此概念
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：Bias-Variance Tradeoff 是 ML 核心議題：偏差高 → 容易欠擬合；變異高 → 易過擬合。
                </div>
                <img src="image/bias-and-variance.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 18 -->
        <div class="question-block">
            <div class="question-header">
                18. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第50頁）
            </div>
            <div class="question">
                為何我們需要「驗證集 (Validation set)」？
            </div>
            <div class="options">
                A. 與測試集相同用途<br>
                B. 用以衡量上線之後的真實效果<br>
                <span class="correct">C. 用來調參或做 Early Stopping 等決策，避免直接動用測試集</span><br>
                D. 永遠不需要
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：在三階段切分中，Validation 協助調校模型參數，Test 保持獨立最終評估，避免洩露。
                </div>
                <img src="image/train validation and test set.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 19 -->
        <div class="question-block">
            <div class="question-header">
                19. 出題頻率/重要性：★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                「混淆矩陣 (Confusion Matrix)」在分類任務中，能顯示什麼資訊？
            </div>
            <div class="options">
                A. 僅顯示準確率<br>
                <span class="correct">B. 真實標籤 vs. 預測標籤的交叉分布，含 TP, FP, TN, FN</span><br>
                C. 無法顯示 FN<br>
                D. 僅用於回歸
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：混淆矩陣是分類結果詳細對照表，可看出錯誤類型與準確預測的類別情況。
                </div>
                <img src="image/confusion-matrix.png" class="responsive-img">"
            </div>
        </div>

        <!-- 題目 20 -->
        <div class="question-block">
            <div class="question-header">
                20. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）
            </div>
            <div class="question">
                下列對於「線性迴歸」的描述，何者較為正確？
            </div>
            <div class="options">
                A. 只能處理二分類<br>
                <span class="correct">B. 用線性方程來擬合輸入特徵與輸出值的關係</span><br>
                C. 不需要任何資料<br>
                D. 完全不適用連續預測
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：線性迴歸適用於輸出為連續變數的場景，假設輸入-輸出呈線性關係。
                </div>
                <img src="image/Linear Regression.jpg" class="responsive-img">
            </div>
        </div>

        <!-- 題目 21 -->
        <div class="question-block">
            <div class="question-header">
                21. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                在機器學習中，若資料量不夠但特徵維度很多，常有何問題？
            </div>
            <div class="options">
                A. 模型更容易泛化<br>
                <span class="correct">B. 維度災難 (Curse of dimensionality)，易導致過擬合或計算複雜度高</span><br>
                C. 測試集可忽略<br>
                D. 完全不影響
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：高維度+少資料 → 難以估計參數；也因距離度量在高維下失效，致分類與回歸困難。
                </div>
                <img src="image/Curse-of-Dimensionality.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 22 -->
        <div class="question-block">
            <div class="question-header">
                22. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第55頁）
            </div>
            <div class="question">
                PCA(主成分分析)主要用途是？
            </div>
            <div class="options">
                A. 區分高低類別<br>
                B. 預測未來趨勢<br>
                <span class="correct">C. 將高維度資料投影到較低維度空間，同時保留最大差異資訊</span><br>
                D. 僅用於文字分群
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：PCA是一種降維方法，尋找能最大化資料方差的正交主成分，以壓縮維度。
                </div>
                <img src="image/PCA.jpg" class="responsive-img">
            </div>
        </div>

        <!-- 題目 23 -->
        <div class="question-block">
            <div class="question-header">
                23. 出題頻率/重要性：★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                在監督式學習中，分割資料時常見做法為多少比例？
            </div>
            <div class="options">
                <span class="correct">A. 訓練集 : 測試集 ≈ 8:2 或 7:3 (大約區間)</span><br>
                B. 一律 1:1<br>
                C. 只用測試集無需訓練<br>
                D. 無需分割
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：常見切分包含 80%/20% 或 70%/30%；依資料量大小與需求可調整。
                </div>
            </div>
        </div>

        <!-- 題目 24 -->
        <div class="question-block">
            <div class="question-header">
                24. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                常見優化方法「梯度下降 (Gradient Descent)」的核心思路是什麼？
            </div>
            <div class="options">
                <span class="correct">A. 沿著損失函式梯度方向反向移動以尋找最小化誤差的參數</span><br>
                B. 用暴力列舉所有參數組合<br>
                C. 依隨機路徑走到高點<br>
                D. 不需損失函式
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：梯度下降演算法是最常用的學習方式，透過更新參數以最小化損失。
                </div>
                <img src="image/Gradient Descent.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 25 -->
        <div class="question-block">
            <div class="question-header">
                25. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）
            </div>
            <div class="question">
                下列哪一種是「深度學習 (Deep Learning)」與傳統機器學習的主要差異？
            </div>
            <div class="options">
                <span class="correct">A. 深度學習通常採用多層神經網路，自動學習特徵，需較大量資料</span><br>
                B. 傳統 ML 需超大量資料<br>
                C. 深度學習不需要資料<br>
                D. 深度學習只能做表格分析
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：深度學習網路具多層結構，自動抽取高階特徵，表現強大但依賴大量資料與算力。
                </div>
                <img src="image/Deep_Learning_vs_Machine_Learning.jpeg" class="responsive-img">"
            </div>
        </div>

        <!-- 題目 26 -->
        <div class="question-block">
            <div class="question-header">
                26. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                對於「過擬合」問題，下列哪個敘述正確？
            </div>
            <div class="options">
                A. 過擬合的模型在所有資料上都表現極佳<br>
                <span class="correct">B. 過擬合代表模型在訓練集表現很好，測試集卻差</span><br>
                C. 過擬合一定比欠擬合好<br>
                D. 與資料量無任何關係
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：過擬合即模型只記住訓練樣本特徵，在新樣本的泛化不佳。
                </div>
                <img src="image/overfitting underfitting.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 27 -->
        <div class="question-block">
            <div class="question-header">
                27. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                為何「Learning Rate」不能設得過大？
            </div>
            <div class="options">
                <span class="correct">A. 可能導致訓練時在誤差曲面跳來跳去，無法收斂</span><br>
                B. 可以加快收斂速度<br>
                C. 與收斂無關<br>
                D. 只是令誤差更低
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：學習率太大會造成更新步伐過大，導致震盪或發散，無法到達最小值。
                </div>
                <img src="image/Learning Rate2.png" class="responsive-img">"
            </div>
        </div>

        <!-- 題目 28 -->
        <div class="question-block">
            <div class="question-header">
                28. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第50頁）</div>
            <div class="question">
                「多元線性迴歸 (Multiple Linear Regression)」相較單一迴歸，多在哪裡？
            </div>
            <div class="options">
                A. 多輸出目標<br>
                <span class="correct">B. 輸入特徵維度由1個增加到多個</span><br>
                C. 僅能處理分類<br>
                D. 不同演算法
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：多元線性迴歸係指 y = w1*x1 + w2*x2 + ... + b，特徵有多個。
                </div>
                <img src="image/Multiple Linear Regression.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 29 -->
        <div class="question-block">
            <div class="question-header">
                29. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                在分類任務中，若非常重視對「少數正類」的召回率 (Recall)，該怎麼做？
            </div>
            <div class="options">
                <span class="correct">A. 降低分類決策閾值，使模型更易判定為正類</span><br>
                B. 提高閾值<br>
                C. 不可調整閾值<br>
                D. 改成 K-Means
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：召回率要高，就要盡量把真正類都抓出來，可調低閾值，但可能犧牲精確率。
                </div>
                <img src="image/Confusion-matrix-Precision-Recall-Accuracy-and-F1-score.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 30 -->
        <div class="question-block">
            <div class="question-header">
                30. 出題頻率/重要性：★★
            </div>
            <div class="reference">由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                下列哪一個不是機器學習常見的演算法家族？
            </div>
            <div class="options">
                <span class="correct">A. 形態學演算 (Morphological Operator) 僅在影像二值處理</span><br>
                B. 決策樹與隨機森林<br>
                C. 線性迴歸與邏輯迴歸<br>
                D. K-Means 與階層式分群
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：形態學演算主要用於影像像素層面的膨脹/侵蝕，不算機器學習常見主流演算法。
                </div>                
            </div>
        </div>

        <!-- 題目 31 -->
        <div class="question-block">
            <div class="question-header">
                31. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                「集成學習 (Ensemble)」如 Bagging、Boosting 的核心理念是什麼？
            </div>
            <div class="options">
                <span class="correct">A. 結合多個弱模型，透過投票或加權形成更強模型</span><br>
                B. 使用同一個樹<br>
                C. 必須在無標籤情況下<br>
                D. 僅限 CNN
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：集成方法如隨機森林(Bagging)或梯度提升(Boosting)常可有效提升預測表現。
                </div>
                <img src="image/ensemble-learning.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 32 -->
        <div class="question-block">
            <div class="question-header">
                32. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第58頁）</div>
            <div class="question">
                Boosting (如 XGBoost、LightGBM) 與 Bagging (如 Random Forest) 的差異在？
            </div>
            <div class="options">
                <span class="correct">A. Bagging各模型獨立同分佈訓練，Boosting則序列式疊加，後續模型重點學前面誤差</span><br>
                B. 二者無任何差異<br>
                C. Bagging只能用深度學習<br>
                D. Boosting一次性訓練所有模型
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：Bagging是並行訓練後投票；Boosting是序列化，後面針對前面錯誤做加強。
                </div>
                <img src="image/Ensemble_Learning_Bagging_Boosting.avif" class="responsive-img">
            </div>
        </div>

        <!-- 題目 33 -->
        <div class="question-block">
            <div class="question-header">
                33. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                為何在高維空間下，KNN 分類可能效果較差？
            </div>
            <div class="options">
                A. KNN一定比SVM好<br>
                <span class="correct">B. 高維度下距離度量失效，導致最近鄰概念模糊</span><br>
                C. KNN不受維度影響<br>
                D. 測試資料無法帶入
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：在高維空間，所有點都「差不多遠」，KNN對距離的依賴嚴重削弱效果。
                </div>
                <br>
                <img src="image/KNN.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 34 -->
        <div class="question-block">
            <div class="question-header">
                34. 出題頻率/重要性：★★
            </div>
            <div class="reference">由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                機器學習中，為何要做「資料正規化 (Normalization)」或「標準化 (Standardization)」？
            </div>
            <div class="options">
                <span class="correct">A. 讓所有特徵單位一致，避免某些量級過大特徵支配模型</span><br>
                B. 只是讓表格好看<br>
                C. 與模型無關<br>
                D. 只限於文字分類
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：資料縮放可加速收斂、提高數值穩定，避免大值特徵嚴重影響損失函式。
                </div>
                <img src="image/Standardization and Normalization for feature scaling.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 35 -->
        <div class="question-block">
            <div class="question-header">
                35. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第63頁）</div>
            <div class="question">
                L1 正則化 (Lasso) 與 L2 正則化 (Ridge) 的主要差異？
            </div>
            <div class="options">
                <span class="correct">A. L1可產生稀疏解(使部分權重=0)，L2則會將權重均勻收斂但不會變成0</span><br>
                B. L1無法稀疏<br>
                C. L2必定產生大量權重=0<br>
                D. 無差異
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：L1(Lasso)可做特徵選擇；L2(Ridge)則抑制權重過大但不會直接變0。
                </div>
                <img src="image/Lasso ridge.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 36 -->
        <div class="question-block">
            <div class="question-header">
                36. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                在邏輯迴歸中，激活函式常用哪種？
            </div>
            <div class="options">
                A. Relu<br>
                B. Tanh<br>
                <span class="correct">C. Sigmoid 函式 (1 / (1 + e^-z))</span><br>
                D. 無需激活函式
            </div>
            <div class="answer">
                答案：C
                <div class="explanation">
                    解析：邏輯迴歸透過 sigmoid 將線性組合輸出映射到 0~1 的機率空間。
                </div>
                <img src="image/logistic Regression Sigmoid.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 37 -->
        <div class="question-block">
            <div class="question-header">
                37. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                SVM (支持向量機) 中的「核函式 (Kernel)」作用為何？
            </div>
            <div class="options">
                <span class="correct">A. 在高維或無限維空間中計算樣本相似度，讓SVM可處理非線性分類</span><br>
                B. 儲存模型參數<br>
                C. 僅能做線性分隔<br>
                D. 調整學習率
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：核函式可在不顯式映射至高維的情況下計算內積，SVM因此可處理非線性分界。
                </div>
                <img src="image/svm Kernel.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 38 -->
        <div class="question-block">
            <div class="question-header">
                38. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第72頁）</div>
            <div class="question">
                ROC 曲線指的是？
            </div>
            <div class="options">
                <span class="correct">A. 以 TPR(敏感度) 對 FPR(假陽性率) 做圖，閾值不同時所形成的曲線</span><br>
                B. 僅顯示精確度<br>
                C. 僅用於回歸<br>
                D. 與分類無關
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：ROC(Receiver Operating Characteristic) 曲線反映分類器在各閾值下的真陽性率與假陽性率。
                </div>
                <img src="image/ROC.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 39 -->
        <div class="question-block">
            <div class="question-header">
                39. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                AUC (Area Under the Curve) 通常指的就是 ROC 曲線下的面積，意義為何？
            </div>
            <div class="options">
                <span class="correct">A. 越接近1表示分類器越好，0.5附近表示接近隨機猜測</span><br>
                B. 越小越好<br>
                C. 等於準確率<br>
                D. 僅針對迴歸
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：AUC越高，代表對正負類別區分能力越強；0.5表示無區分能力。
                </div>
                <img src="image/AUC.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 40 -->
        <div class="question-block">
            <div class="question-header">
                40. 出題頻率/重要性：★★
            </div>
            <div class="reference">由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                「學習曲線 (Learning Curve)」在模型訓練中可觀察什麼？
            </div>
            <div class="options">
                <span class="correct">A. 不同訓練資料量下，訓練集與驗證集誤差的變化，判斷是否過/欠擬合</span><br>
                B. 用來調整硬體性能<br>
                C. 僅用於深度學習<br>
                D. 代表特徵工程結果
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：學習曲線可看隨資料量增多時，模型的訓練誤差與驗證誤差如何變化，以判斷是否需更多資料或更複雜模型。
                </div>
                <img src="image/overfitting underfitting.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 41 -->
        <div class="question-block">
            <div class="question-header">
                41. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                KNN 分類中的 K 值若過大，可能出現什麼情況？
            </div>
            <div class="options">
                A. 容易過擬合<br>
                <span class="correct">B. 過度平滑，導致少數類別被多數類給壓過</span><br>
                C. 不受影響<br>
                D. 一定效果最佳
            </div>
            <div class="answer">
                答案：B
                <div class="explanation">
                    解析：K太大會忽略局部區域特性，分類決策受遠方多數樣本干擾。
                </div>
                <img src="image/KNN.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 42 -->
        <div class="question-block">
            <div class="question-header">
                42. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第68頁）</div>
            <div class="question">
                「早停 (Early Stopping)」的主要目的為何？
            </div>
            <div class="options">
                <span class="correct">A. 避免在訓練集上過度迭代而造成過擬合</span><br>
                B. 增加模型複雜度<br>
                C. 只在測試階段停止<br>
                D. 與訓練時間無關
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：Early Stopping 會根據驗證集誤差是否上升來提前終止訓練，防止模型繼續記住訓練雜訊。
                </div>
                <img src="image/Early Stopping.webp" class="responsive-img">"
            </div>
        </div>

        <!-- 題目 43 -->
        <div class="question-block">
            <div class="question-header">
                43. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                「偏差 (Bias)」過大時，模型較可能是哪種狀況？
            </div>
            <div class="options">
                <span class="correct">A. 欠擬合，無法充分捕捉資料的真實規律</span><br>
                B. 過擬合<br>
                C. 訓練與測試表現都極佳<br>
                D. 模型參數過多
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：高偏差表示模型過於簡單或錯誤假設，導致欠擬合現象。
                </div>
                <img src="image/bias.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 44 -->
        <div class="question-block">
            <div class="question-header">
                44. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                為何選用「F1-score」作為分類指標，而不僅用 Accuracy？
            </div>
            <div class="options">
                A. Accuracy永遠最高<br>
                <span class="correct">B. 在類別不平衡時，F1結合Precision與Recall，更能反映模型對正類的有效偵測</span><br>
                C. F1只考慮假陰性<br>
                D. 不同指標無差
            </div>
            <div class="answer">
                答案：B
                <div class="explanation">
                    解析：F1 = 2PR/(P+R)，能同時考量精確率與召回率，特別適用不平衡資料。
                </div>
                <img src="image/Confusion-matrix-Precision-Recall-Accuracy-and-F1-score.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 45 -->
        <div class="question-block">
            <div class="question-header">
                45. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第72頁）</div>
            <div class="question">
                若在二元分類中，非常重視「不漏抓正類」，應優先提升哪個指標？
            </div>
            <div class="options">
                A. Precision<br>
                <span class="correct">B. Recall (召回率)</span><br>
                C. Accuracy<br>
                D. Specificity
            </div>
            <div class="answer">
                答案：B
                <div class="explanation">
                    解析：若要確保正類都抓到（不漏報），就是提高召回率=TP/(TP+FN)，盡量降低FN。
                </div>
                <img src="image/Confusion-matrix-Precision-Recall-Accuracy-and-F1-score.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 46 -->
        <div class="question-block">
            <div class="question-header">
                46. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                當 Accuracy 很高，但 F1-score 很低，可能表示什麼？
            </div>
            <div class="options">
                <span class="correct">A. 資料可能嚴重類別不平衡，模型只要猜多數類即可獲高Accuracy</span><br>
                B. 模型表現非常好<br>
                C. 無法發生<br>
                D. 這是深度學習特性
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：不平衡資料下，光看Accuracy易誤導，模型可能無視少數類，導致F1分數低。
                </div>
                <img src="image/Confusion-matrix-Precision-Recall-Accuracy-and-F1-score.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 47 -->
        <div class="question-block">
            <div class="question-header">
                47. 出題頻率/重要性：★★
            </div>
            <div class="reference">由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                機器學習在實務上常需持續迭代更新模型，原因是？
            </div>
            <div class="options">
                <span class="correct">A. 資料分佈可能隨時間改變 (概念飄移)，需重新學習</span><br>
                B. 一次訓練足矣<br>
                C. 模型不需維護<br>
                D. 使用者數變多無影響
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：實際環境中資料與行為模式會變化，故需定期重新蒐集與訓練模型。
                </div>
                <img src="image/Concept Drift.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 48 -->
        <div class="question-block">
            <div class="question-header">
                48. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第80頁）</div>
            <div class="question">
                Gradient Boosting 的原理為何？
            </div>
            <div class="options">
                <span class="correct">A. 逐次擬合前一模型的殘差，疊加弱模型以減少剩餘誤差</span><br>
                B. 單一樹投票<br>
                C. 不同步並行<br>
                D. 僅限線性方程
            </div>
            <div class="answer">
                答案：A
                <div class="explanation">
                    解析：Boosting將每次學習的誤差當作新標籤，不斷累加調整模型，最終形成強分類器。
                </div>
                <img src="image/Gradient Boosting Tree.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 49 -->
        <div class="question-block">
            <div class="question-header">
                49. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                在非監督式學習中，若要估計分群數 K，常用哪種方法？
            </div>
            <div class="options">
                A. 使用預先標籤<br>
                <span class="correct">B. 透過肘部法 (Elbow method) 或輪廓係數 (Silhouette) 分析</span><br>
                C. 僅隨機指定<br>
                D. 使用回歸檢驗
            </div>
            <div class="answer">
                答案：B
                <div class="explanation">
                    解析：Elbow method 觀察 SSE對K的走勢，輪廓係數衡量分群品質等，用以選擇合適K。
                </div>
            </div>
        </div>

        <!-- 題目 50 -->
        <div class="question-block">
            <div class="question-header">
                50. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第70頁）</div>
            <div class="question">
                綜觀「L11301 機器學習基本原理」，下列哪句最能代表其核心精神？
            </div>
            <div class="options">
                A. 機器學習只要隨意猜測即可<br>
                B. 只需硬體強大就能成功<br>
                <span class="correct">C. 透過適當資料與演算法，讓系統學到規律並在未知情況下做有效預測或決策</span><br>
                D. 絕對不需評估
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：機器學習本質在於「從資料中學習」並「應用於新情況」，透過演算法與模型評估持續優化。
                </div>
                <img src="image/Machine-Learning.webp" class="responsive-img">
            </div>
        </div>
        <!-- 題目 51 -->
        <div class="question-block">
            <div class="question-header">
                51. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第85頁）
            </div>
            <div class="question">
                欲評估模型在不同樣本量下的表現趨勢，我們可使用哪種曲線？
            </div>
            <div class="options">
                <span class="correct">A. Learning Curve (學習曲線)</span><br>
                B. ROC Curve<br>
                C. Precision-Recall Curve<br>
                D. 混淆矩陣
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：Learning Curve 顯示隨資料量變化時，訓練/驗證誤差的走勢，幫助判斷是否需更多資料。
                </div>
                <img src="image/learning-curve.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 52 -->
        <div class="question-block">
            <div class="question-header">
                52. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第52頁）
            </div>
            <div class="question">
                選用「梯度提升樹 (Gradient Boosted Trees)」模型時，通常可得到什麼好處？
            </div>
            <div class="options">
                A. 訓練非常快，但準確率偏低<br>
                <span class="correct">B. 擁有高表現力，能在多種資料下取得不錯預測效果</span><br>
                C. 只能用於小資料集<br>
                D. 一定會過擬合
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：像 XGBoost、LightGBM、CatBoost 等屬於梯度提升樹方法，常在各種競賽中表現良好。
                </div>
                <img src="image/Gradient Boosting Tree.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 53 -->
        <div class="question-block">
            <div class="question-header">
                53. 出題頻率/重要性：★
            </div>
            <div class="reference">
                由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）
            </div>
            <div class="question">
                為了加速迴歸或分類模型的收斂，我們常在輸入特徵上做哪件事？
            </div>
            <div class="options">
                A. 隨意打亂標籤<br>
                <span class="correct">B. 特徵縮放 (Normalization/Standardization)，使數值尺度更適中</span><br>
                C. 移除所有文字型欄位<br>
                D. 合併所有特徵成一欄
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：對特徵做縮放(如 Z-score)能讓梯度計算更穩定，避免尺度差異造成學習困難。
                </div>
                <img src="image/Standardization and Normalization for feature scaling.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 54 -->
        <div class="question-block">
            <div class="question-header">
                54. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                「多項式迴歸 (Polynomial Regression)」如何對非線性關係做擬合？
            </div>
            <div class="options">
                <span class="correct">A. 將輸入 x 擴展為 x, x^2, x^3 等多項式項再做線性擬合</span><br>
                B. 僅能2次方<br>
                C. 與線性迴歸相同無差<br>
                D. 無法處理非線性
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：多項式迴歸透過手動擴增特徵(多次方)，讓線性模型能擬合非線性關係。
                </div>
                <img src="image/Linear-Regression-vs-Polynomial-Regression.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 55 -->
        <div class="question-block">
            <div class="question-header">
                55. 出題頻率/重要性：★★★
            </div>
            <div class="reference">
                由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第95頁）
            </div>
            <div class="question">
                「Early Stopping」在 Boosting 模型中也常被使用，其原因？
            </div>
            <div class="options">
                A. 只適合深度學習<br>
                <span class="correct">B. 防止迭代次數過多而致過擬合，且可節省訓練時間</span><br>
                C. 沒有意義<br>
                D. 與樹的結構無關
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：像 XGBoost 也可透過 early_stopping_rounds 參數根據驗證集分數停止迭代。
                </div>
                <img src="image/Early Stopping.webp" class="responsive-img">"
            </div>
        </div>

        <!-- 題目 56 -->
        <div class="question-block">
            <div class="question-header">
                56. 出題頻率/重要性：★
            </div>
            <div class="reference">
                由講義出題：No（外部延伸參考）
            </div>
            <div class="question">
                在自動化ML流程中，「AutoML」可以做什麼？
            </div>
            <div class="options">
                <span class="correct">A. 自動尋找特徵工程與模型超參數，減少手動調參</span><br>
                B. 取代所有數據蒐集<br>
                C. 代替工程師寫程式<br>
                D. 僅能處理文字分類
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：AutoML 工具可嘗試多種模型與管線組合，尋找最好表現，減輕人力。
                </div>
                <img src="image/AutoML.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 57 -->
        <div class="question-block">
            <div class="question-header">
                57. 出題頻率/重要性：★★
            </div>
            <div class="reference">
                由大綱出題：Yes（參考：初級大綱.txt - L11301 機器學習基本原理）
            </div>
            <div class="question">
                「正則化 (Regularization)」的主要目的為？
            </div>
            <div class="options">
                <span class="correct">A. 限制模型權重大小或複雜度，降低過擬合風險</span><br>
                B. 測試集分割<br>
                C. 將所有特徵移除<br>
                D. 調整批量大小
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：如 L1、L2、Dropout(深度學習)等方法，目的都在減少模型複雜度、增進泛化。
                </div>
            </div>
        </div>

        <!-- 題目 58 -->
        <div class="question-block">
            <div class="question-header">
                58. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第102頁）</div>
            <div class="question">
                在樹模型中，如何判斷哪個特徵最先分裂比較好？
            </div>
            <div class="options">
                <span class="correct">A. 透過資訊增益 (Information Gain) 或基尼不純度 (Gini Impurity) 來決定</span><br>
                B. 隨機決定<br>
                C. 只看特徵名順序<br>
                D. 用線性迴歸
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：決策樹常用資訊增益（ID3/C4.5）或基尼指數（CART）選出最能區分資料的特徵。
                </div>
            </div>
        </div>

        <!-- 題目 59 -->
        <div class="question-block">
            <div class="question-header">
                59. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                在 Logistic Regression 中，Loss Function 通常為？
            </div>
            <div class="options">
                A. MSE<br>
                <span class="correct">B. Cross-Entropy (或 Log Loss)</span><br>
                C. Hinge Loss<br>
                D. 0-1 Loss
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：Logistic Regression 透過對數似然估計，可視為 Cross Entropy 損失形式。
                </div>
            </div>
        </div>

        <!-- 題目 60 -->
        <div class="question-block">
            <div class="question-header">
                60. 出題頻率/重要性：★★
            </div>
            <div class="reference">由大綱出題：Yes（初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                「Loss Function」在機器學習訓練中扮演什麼角色？
            </div>
            <div class="options">
                A. 無任何作用<br>
                <span class="correct">B. 衡量模型預測與真值之差，指引優化演算法更新參數</span><br>
                C. 指定硬體配置<br>
                D. 決定資料來源
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：Loss (損失) 用於量化預測的好壞，梯度下降等方法依此指標更新模型參數。
                </div>
                <img src="image/loss function.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 61 -->
        <div class="question-block">
            <div class="question-header">
                61. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                「One-Hot Encoding」主要用於？
            </div>
            <div class="options">
                A. 數值型特徵縮放<br>
                B. 分割訓練集<br>
                <span class="correct">C. 把類別型變量轉成0/1向量，讓模型能處理</span><br>
                D. 清除所有缺失值
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：One-Hot Encoding 是對分類特徵做離散化編碼，以便於線性或樹模型處理。
                </div>
                <img src="image/One-Hot Encoding.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 62 -->
        <div class="question-block">
            <div class="question-header">
                62. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第55頁）</div>
            <div class="question">
                當我們對資料做降維 (如 PCA) 時，可能的優勢為？
            </div>
            <div class="options">
                <span class="correct">A. 減少維度以降低過擬合風險與計算成本，且有助可視化</span><br>
                B. 失去全部資訊<br>
                C. 讓資料更難處理<br>
                D. 與維度無關
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：PCA等方法壓縮維度，去除冗餘特徵，能提取關鍵特徵並減少運算量。
                </div>
                <img src="image/PCA.jpg" class="responsive-img">
            </div>
        </div>

        <!-- 題目 63 -->
        <div class="question-block">
            <div class="question-header">
                63. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第110頁）</div>
            <div class="question">
                隨機森林有一項「Out-of-Bag (OOB)」的概念，其用途為？
            </div>
            <div class="options">
                <span class="correct">A. 使用未被該樹取樣到的資料測試樹的效能，近似替代測試集</span><br>
                B. 僅表示模型大小<br>
                C. 無任何作用<br>
                D. 只用於監督式學習
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：每棵樹訓練時是有放回抽樣，故有部分樣本沒被抽中，可用來做該樹的驗證，稱OOB測試。
                </div>
                <img src="image/Out-of-Bag.jpg" class="responsive-img">
            </div>
        </div>

        <!-- 題目 64 -->
        <div class="question-block">
            <div class="question-header">
                64. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                在SVM的分類決策裡，「支持向量 (Support Vectors)」指的是？
            </div>
            <div class="options">
                A. 所有樣本<br>
                <span class="correct">B. 位於邊界附近、對決策超平面起關鍵作用的少數樣本</span><br>
                C. 僅誤分的樣本<br>
                D. 與分類無關
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：SVM只需靠部分臨界樣本(支持向量)定義決策邊界，其餘距邊界遠的樣本不影響結果。
                </div>
                <img src = "image/SVM.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 65 -->
        <div class="question-block">
            <div class="question-header">
                65. 出題頻率/重要性：★★
            </div>
            <div class="reference">由大綱出題：Yes（初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                我們通常用「學習率衰減 (Learning Rate Decay)」來做什麼？
            </div>
            <div class="options">
                <span class="correct">A. 訓練初期步伐大，隨著 epoch 增加逐漸縮小步伐，助於穩定收斂</span><br>
                B. 讓步伐越來越大<br>
                C. 不影響最終結果<br>
                D. 只在測試階段調整
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：初期可快速下降，後期需更小步伐搜尋極小值，防止震盪。
                </div>
                <img src="image/Learning Rate2.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 66 -->
        <div class="question-block">
            <div class="question-header">
                66. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第114頁）</div>
            <div class="question">
                XGBoost 之所以常被用於競賽的原因？
            </div>
            <div class="options">
                <span class="correct">A. 效率佳、可處理缺失值、擁有多項正則化與剪枝策略，往往有高準確度</span><br>
                B. 僅能做圖像分割<br>
                C. 無法平行計算<br>
                D. 只能小資料集
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：XGBoost 是強化版梯度提升樹，支援並行、正則化、缺失值處理等特性，實務成效顯著。
                </div>
                <img src="image/XGBoost.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 67 -->
        <div class="question-block">
            <div class="question-header">
                67. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                機器學習中常用「批次大小 (Batch Size)」為何？
            </div>
            <div class="options">
                <span class="correct">A. 在一次參數更新中用多少筆訓練資料作為樣本</span><br>
                B. 測試資料筆數<br>
                C. K-Fold折數<br>
                D. 與訓練無關
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：在mini-batch梯度下降中，一次更新會基於該批次資料的平均梯度。
                </div>
                <img src="image/Batch Size.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 68 -->
        <div class="question-block">
            <div class="question-header">
                68. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                為何在做 K-Fold Cross Validation 時，某些情況下會用 Stratified K-Fold？
            </div>
            <div class="options">
                <span class="correct">A. 為保證各折中類別分佈與整體相似，避免不平衡被抽偏</span><br>
                B. 讓資料隨機消失<br>
                C. 只用於回歸<br>
                D. 與類別分佈無關
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：Stratified會分層抽樣，維持類別比例一致，使訓練/驗證集更具代表性。
                </div>
                <img src="image/Stratified K-Fold.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 69 -->
        <div class="question-block">
            <div class="question-header">
                69. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由大綱出題：Yes（初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                若模型在訓練集與測試集誤差都很高，表示什麼狀況？
            </div>
            <div class="options">
                <span class="correct">A. 欠擬合 (Underfitting)，模型無法學到足夠規律</span><br>
                B. 過擬合<br>
                C. 泛化能力很好<br>
                D. 與模型無關
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：同時在訓練/測試都表現差 → 欠擬合 → 模型太簡單或特徵不足。
                </div>
                <img src="image/overfitting underfitting.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 70 -->
        <div class="question-block">
            <div class="question-header">
                70. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第65頁）</div>
            <div class="question">
                「資料增強 (Data Augmentation)」在某些情境下如何幫助減少過擬合？
            </div>
            <div class="options">
                <span class="correct">A. 通過翻轉/旋轉/添加雜訊等擴增資料樣本，增加模型對多樣情況的穩健性</span><br>
                B. 刪除所有樣本<br>
                C. 只用既有資料不變<br>
                D. 產生隨機標籤
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：在影像/文字等場合，資料增強可有效增加樣本多樣性，降低記住訓練集而無法泛化的風險。
                </div>
                <img src="image/Data Augmentation.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 71 -->
        <div class="question-block">
            <div class="question-header">
                71. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                在多分類問題(>2類)，常用的評估方式？
            </div>
            <div class="options">
                <span class="correct">A. Macro/Micro Averaged F1-score、Confusion Matrix等綜合指標</span><br>
                B. 僅Accuracy<br>
                C. 只能二元分類指標<br>
                D. 直接用MSE
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：多分類中 Accuracy、平均F1等常使用；也可看混淆矩陣觀察各類型誤判情況。
                </div>
                <img src="image/Confusion-matrix-Precision-Recall-Accuracy-and-F1-score.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 72 -->
        <div class="question-block">
            <div class="question-header">
                72. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第120頁）</div>
            <div class="question">
                在大型資料集下，為什麼 Mini-Batch Gradient Descent 通常優於全量 Batch Gradient Descent？
            </div>
            <div class="options">
                <span class="correct">A. 可以更快收斂，節省記憶體，也不易陷入局部極小</span><br>
                B. 需要匯入全部資料記憶體<br>
                C. Mini-Batch不能做驗證<br>
                D. 兩者完全相同
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：Mini-Batch 兼具隨機性與效率，可在不讀取整批資料的情況下更新參數。
                </div>
                <img src="image/Mini-Batch Gradient Descent.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 73 -->
        <div class="question-block">
            <div class="question-header">
                73. 出題頻率/重要性：★
            </div>
            <div class="reference">由大綱出題：Yes（初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                常見應用於「維度極高」資料，但標籤數據極少時，哪種學習能發揮作用？
            </div>
            <div class="options">
                A. 監督式學習<br>
                <span class="correct">B. 半監督式學習 (Semi-supervised Learning)</span><br>
                C. 完全無法學<br>
                D. 強化學習
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：半監督可用少量標籤+大量無標籤資料，較適合標註成本高但資料豐富情況。
                </div>
                <img src="image/Semi-supervised Learning.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 74 -->
        <div class="question-block">
            <div class="question-header">
                74. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                「Zero-shot Learning」在機器學習中是指？
            </div>
            <div class="options">
                A. 需很多標籤<br>
                <span class="correct">B. 在未見過該類別的樣本情況下，也能進行推論或分類</span><br>
                C. 僅用於KNN<br>
                D. 不存在此概念
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：Zero-shot指事先無該類別樣本，但模型可依先前語意或特徵知識辨識新的類別。
                </div>
                <img src="image/Zero-shot Learning.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 75 -->
        <div class="question-block">
            <div class="question-header">
                75. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第72頁）</div>
            <div class="question">
                在實務應用中，為何常用集成方法(如RandomForest、XGBoost) 而非單一樹或單一迴歸？
            </div>
            <div class="options">
                <span class="correct">A. 集成方法可結合多模型優勢，通常有更高準確率與穩定度</span><br>
                B. 單一模型準確度總是最佳<br>
                C. 集成會增加過擬合<br>
                D. 集成僅能做圖像分割
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：多模型投票/加權能降低方差與偏差，往往在Kaggle競賽等實踐中效果出色。
                </div>
                <img src="image/ensemble-learning.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 76 -->
        <div class="question-block">
            <div class="question-header">
                76. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                「偏差-變異分解 (Bias-Variance Decomposition)」可解釋誤差由哪些部分構成？
            </div>
            <div class="options">
                <span class="correct">A. 偏差 + 變異 + 不可約誤差 (irreducible error)</span><br>
                B. 訓練集 + 測試集<br>
                C. 線性 + 非線性<br>
                D. 只分為隨機誤差
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：模型預測誤差可分為: 偏差 (模型簡化誤差) + 變異(對不同訓練集敏感度) + 固有雜訊。
                </div>
                <img src="image/Bias-Variance Trade Off.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 77 -->
        <div class="question-block">
            <div class="question-header">
                77. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第130頁）</div>
            <div class="question">
                「核 (Kernel) SVM」中，RBF核 (Gaussian Kernel) 的作用為何？
            </div>
            <div class="options">
                <span class="correct">A. 在無限維空間內映射樣本，能處理非線性分割問題</span><br>
                B. 只能做線性<br>
                C. 只適合影像辨識<br>
                D. 與核函式無關
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：RBF核能將原始空間映射到高維(甚至無限)，在該空間中以超平面做線性分割。
                </div>
                <img src="image/svm Kernel.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 78 -->
        <div class="question-block">
            <div class="question-header">
                78. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第75頁）</div>
            <div class="question">
                「貝氏分類器 (Naive Bayes)」中，為何稱作"Naive"？
            </div>
            <div class="options">
                <span class="correct">A. 因假設特徵之間條件獨立，相對簡單(naive)但常有效</span><br>
                B. 需複雜條件相依建模<br>
                C. 只適合線性問題<br>
                D. 不可用於分類
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：Naive Bayes 假設所有特徵在給定類別情況下互相獨立，儘管實際往往違背，但在多場景也能表現不錯。
                </div>
                <img src="image/Naive Bayes.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 79 -->
        <div class="question-block">
            <div class="question-header">
                79. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                對於時間序列資料，機器學習需要注意什麼？
            </div>
            <div class="options">
                A. 可隨意打亂資料順序<br>
                <span class="correct">B. 保持時序關係，避免把未來資料洩漏到訓練集</span><br>
                C. 與時序無關<br>
                D. 完全用隨機森林即可
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：在時間序列中，後期資料往往代表未來，若混進訓練樣本會導致資料洩露。
                </div>
            </div>
        </div>

        <!-- 題目 80 -->
        <div class="question-block">
            <div class="question-header">
                80. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                若要將文字敘述轉為特徵向量，常用到哪種方法？
            </div>
            <div class="options">
                A. 直接丟入線性回歸<br>
                B. 羅馬拼音<br>
                <span class="correct">C. Bag-of-Words、TF-IDF、或Word Embedding等方式</span><br>
                D. XOR編碼
            </div>
            <div class="answer">
                答案：<span class="correct">C</span>
                <div class="explanation">
                    解析：文字處理需先轉為可數值化的特徵，如 BOW/TF-IDF/embedding 等表示詞語在向量空間的意義。
                </div>
                <img src="image/embedding.webp" class="responsive-img">
            </div>
        </div>

        <!-- 題目 81 -->
        <div class="question-block">
            <div class="question-header">
                81. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第140頁）</div>
            <div class="question">
                「過採樣 (Oversampling)」與「下採樣 (Undersampling)」在何種情況下使用？
            </div>
            <div class="options">
                <span class="correct">A. 類別不平衡時，分別透過增加少數類樣本或減少多數類來平衡</span><br>
                B. 與不平衡無關<br>
                C. 只適用回歸<br>
                D. 不需任何策略
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：在分類中若正負類極度不平衡，可通過 Oversampling(如 SMOTE)或 Undersampling 調整比例。
                </div>
                <img src="image/oversampling undersampling.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 82 -->
        <div class="question-block">
            <div class="question-header">
                82. 出題頻率/重要性：★
            </div>
            <div class="reference">由大綱出題：Yes（初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                「自動特徵選擇 (Feature Selection)」的目的為？
            </div>
            <div class="options">
                <span class="correct">A. 去除冗餘或無關特徵，降低維度並可能提升模型準確度與效率</span><br>
                B. 額外增加特徵<br>
                C. 讓模型變得更複雜<br>
                D. 僅改變標籤
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：特徵選擇能減少噪音與維度，還能加快訓練速度並降低過擬合。
                </div>
                <img src="image/Feature Selection.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 83 -->
        <div class="question-block">
            <div class="question-header">
                83. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第78頁）</div>
            <div class="question">
                「混淆矩陣 (Confusion Matrix)」中，FN (False Negative) 代表？
            </div>
            <div class="options">
                <span class="correct">A. 真實為正類卻被預測為負類</span><br>
                B. 預測為正類但真實為負類<br>
                C. 皆為正確預測<br>
                D. 預測與真值相同
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：FN=真值Positive，但模型判斷Negative → 屬漏報的情況。
                </div>
                <img src="image/confusion-matrix.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 84 -->
        <div class="question-block">
            <div class="question-header">
                84. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第150頁）</div>
            <div class="question">
                「Learning Rate Scheduler」可在訓練過程中怎麼運作？
            </div>
            <div class="options">
                <span class="correct">A. 動態調整學習率，如Step Decay、Exponential Decay，保證更穩定收斂</span><br>
                B. 僅限制最大epoch<br>
                C. 調整驗證集大小<br>
                D. 無法自動調整
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：Scheduler能隨epoch增長自動遞減學習率，或在表現未提升時降低學習率等。
                </div>
                <img src="image/Learning Rate Scheduler.png" class="responsive-img">"
            </div>
        </div>

        <!-- 題目 85 -->
        <div class="question-block">
            <div class="question-header">
                85. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                「Ensemble Stacking」與 Bagging/Boosting的差異在於？
            </div>
            <div class="options">
                <span class="correct">A. Stacking以多個不同類型模型輸出再做次級學習，Bagging/Boosting主要同類模型投票</span><br>
                B. Stacking只用決策樹<br>
                C. 沒有任何差別<br>
                D. Bagging一定優於Stacking
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：Stacking有「次級學習器」(meta learner)去整合多種模型預測結果；Bagging/Boosting通常同類弱分類器。
                </div>
                <img src="image/stacking.png" class="responsive-img">
                <img src="image/Ensemble_Learning_Bagging_Boosting.avif" class="responsive-img">
            </div>
        </div>

        <!-- 題目 86 -->
        <div class="question-block">
            <div class="question-header">
                86. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                機器學習中，出現「資料洩漏 (Data Leakage)」時會導致？
            </div>
            <div class="options">
                <span class="correct">A. 評估結果過於樂觀，實際部署效果差</span><br>
                B. 模型更具泛化<br>
                C. 大幅縮短訓練時間<br>
                D. 沒有影響
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：若測試資料在訓練時被用到，模型評估失去公正性，會高估真實表現。
                </div>
            </div>
        </div>

        <!-- 題目 87 -->
        <div class="question-block">
            <div class="question-header">
                87. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第160頁）</div>
            <div class="question">
                若想同時考慮特徵交互作用，可用哪種方法？
            </div>
            <div class="options">
                <span class="correct">A. Polynomial Features 產生 x1*x2 交叉項，或使用樹模型自動捕捉交互</span><br>
                B. 只用線性方程<br>
                C. 不可考慮交互<br>
                D. One-Hot會自動產生交互
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：可以人工創建交叉特徵(如多項式)或透過樹模型分裂路徑，捕捉特徵之間的交互影響。
                </div>
            </div>
        </div>

        <!-- 題目 88 -->
        <div class="question-block">
            <div class="question-header">
                88. 出題頻率/重要性：★
            </div>
            <div class="reference">由大綱出題：Yes（初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                初學者常犯錯之一：直接看訓練集 Accuracy 來評價模型。可能問題是？
            </div>
            <div class="options">
                <span class="correct">A. 容易過擬合，訓練集高分不代表測試集或真實場景高分</span><br>
                B. 表示模型完美<br>
                C. 測試集一致<br>
                D. 無任何問題
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：只看訓練表現會忽視泛化能力，必須檢查測試/驗證集表現才能避免過擬合。
                </div>
            </div>
        </div>

        <!-- 題目 89 -->
        <div class="question-block">
            <div class="question-header">
                89. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                在影像辨識等領域，通常需要大量標記資料，原因是？
            </div>
            <div class="options">
                A. 機器學習不用標記<br>
                <span class="correct">B. 深度模型參數極多，需要龐大數據支撐，否則易過擬合</span><br>
                C. 純文字描述即可<br>
                D. 只需 10 筆資料足矣
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：如CNN等深度模型參數量大，需龐大訓練樣本提供足夠學習，否則過擬合。
                </div>
            </div>
        </div>

        <!-- 題目 90 -->
        <div class="question-block">
            <div class="question-header">
                90. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第170頁）</div>
            <div class="question">
                「特徵重要性 (Feature Importance)」在樹模型中如何估算？
            </div>
            <div class="options">
                <span class="correct">A. 透過節點分裂所帶來的純度提升 (如資訊增益) 做加總</span><br>
                B. 由樹高決定<br>
                C. 只由隨機產生<br>
                D. 與樹結構無關
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：像Random Forest或XGBoost可根據特徵使不純度或Loss下降量計算重要度。
                </div>
            </div>
        </div>

        <!-- 題目 91 -->
        <div class="question-block">
            <div class="question-header">
                91. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                當資料中有大量缺失值且分佈不均，常見做法？
            </div>
            <div class="options">
                <span class="correct">A. 先探索缺失原因，再選擇刪除或以統計/模型方式插補</span><br>
                B. 全部補 0<br>
                C. 全部丟棄<br>
                D. 無需理會
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：缺失值處理視比例、分佈與機制而定，可能用均值、中位數、模型預測等方式合理補齊。
                </div>
            </div>
        </div>

        <!-- 題目 92 -->
        <div class="question-block">
            <div class="question-header">
                92. 出題頻率/重要性：★★
            </div>
            <div class="reference">由大綱出題：Yes（初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                在模型部署後，為何需要持續監控模型效能？
            </div>
            <div class="options">
                <span class="correct">A. 隨著資料或環境變化，模型可能失效，需要重新訓練或調整</span><br>
                B. 一次訓練可永久使用<br>
                C. 使用者無法影響模型<br>
                D. 監控無法幫助
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：真實世界資料分佈可能漸變(概念漂移)，需監控並適時更新模型。
                </div>
                <img src="image/Concept Drift.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 93 -->
        <div class="question-block">
            <div class="question-header">
                93. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第180頁）</div>
            <div class="question">
                「半監督式學習 (Semi-supervised Learning)」在實務應用中常見於哪種情境？
            </div>
            <div class="options">
                <span class="correct">A. 有少量標籤資料+大量無標籤資料，如文本、影像標記成本高</span><br>
                B. 僅用全監督資料<br>
                C. 只用深度學習<br>
                D. 不適用於實務
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：半監督透過無標籤樣本學得分佈結構，再配合少量標籤資料指示，可顯著提升效果。
                </div>
                <img src="image/Semi-supervised Learning.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 94 -->
        <div class="question-block">
            <div class="question-header">
                94. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                要檢驗模型是否「過度依賴個別特徵」或「穩健」，可嘗試什麼測試？
            </div>
            <div class="options">
                A. 直接忽略<br>
                <span class="correct">B. 敏感度分析 / 特徵擾動測試，看準確度下降幅度</span><br>
                C. 只用全部特徵<br>
                D. 與模型無關
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：若移除或干擾某特徵導致精度顯著下降，代表該特徵對模型決策影響很大。
                </div>
            </div>
        </div>

        <!-- 題目 95 -->
        <div class="question-block">
            <div class="question-header">
                95. 出題頻率/重要性：★★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                「One-vs-Rest (OvR)」策略在多類別分類中是如何運作？
            </div>
            <div class="options">
                <span class="correct">A. 針對每個類別都訓練一個二元分類器，把該類 vs. 其他所有類</span><br>
                B. 一次全部類別同時訓練<br>
                C. 僅適用兩類<br>
                D. 僅用距離度量
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：多分類可透過OvR(或OvO)拆成多個二分類器，再綜合判斷哪類概率最高。
                </div>
                <img src="image/OvO OvR.jpg" class="responsive-img">
            </div>
        </div>

        <!-- 題目 96 -->
        <div class="question-block">
            <div class="question-header">
                96. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第80頁）</div>
            <div class="question">
                機器學習中，為何要做「超參數 (Hyperparameters)」調整？
            </div>
            <div class="options">
                <span class="correct">A. 這些參數無法在訓練過程自動學得，需要人工或自動搜尋最佳化</span><br>
                B. 超參數與模型效能無關<br>
                C. 僅用默認即可<br>
                D. 與正則化相同
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：如學習率、正則強度、樹深、K值等屬超參數，不會自動更新，須網格/隨機/貝氏最佳化等。
                </div>                
                <img src="image/Hyperparameters.png" class="responsive-img">
            </div>
        </div>

        <!-- 題目 97 -->
        <div class="question-block">
            <div class="question-header">
                97. 出題頻率/重要性：★
            </div>
            <div class="reference">由講義出題：No（外部延伸參考）</div>
            <div class="question">
                在回歸問題中，若 outlier(極端值)很多，可能優先考慮哪種誤差度量？
            </div>
            <div class="options">
                <span class="correct">A. MAE (Mean Absolute Error)</span><br>
                B. MSE<br>
                C. Huber Loss<br>
                D. ACC
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：MAE對outlier較不敏感，MSE則會擴大outlier影響。另Huber也是折衷選項。
                    <img src="image/MAE.jpeg">
                </div>
            </div>
        </div>

        <!-- 題目 98 -->
        <div class="question-block">
            <div class="question-header">
                98. 出題頻率/重要性：★★
            </div>
            <div class="reference">由大綱出題：Yes（初級大綱.txt - L11301 機器學習基本原理）</div>
            <div class="question">
                「資料前處理」對機器學習模型的重要性為何？
            </div>
            <div class="options">
                <span class="correct">A. 直接影響模型能否有效學習，若原始資料有噪音或缺失，需先清理</span><br>
                B. 只需使用所有欄位<br>
                C. 不會影響結果<br>
                D. 與模型無關
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：資料品質與前處理決定模型上限，垃圾進、垃圾出（GIGO）就是其反面案例。
                </div>
            </div>
        </div>

        <!-- 題目 99 -->
        <div class="question-block">
            <div class="question-header">
                99. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：04_機器學習技術理論與案例_講義.pdf 第190頁）</div>
            <div class="question">
                「偏差校正 (Bias Correction)」在某些模型結果中為何需要？
            </div>
            <div class="options">
                <span class="correct">A. 若資料有系統性偏差，需在結果中進行修正，以貼近真實分布</span><br>
                B. 僅在測試集做對齊<br>
                C. 讓預測更偏向多數類<br>
                D. 與評估無關
            </div>
            <div class="answer">
                答案：<span class="correct">A</span>
                <div class="explanation">
                    解析：如採樣不均或模型系統性誤差，可通過偏差校正(後處理)使分布與真實狀況更一致。
                </div>
            </div>
        </div>

        <!-- 題目 100 -->
        <div class="question-block">
            <div class="question-header">
                100. 出題頻率/重要性：★★★
            </div>
            <div class="reference">由講義出題：Yes（參考：01_AI基礎理論_講義.pdf 第90頁）</div>
            <div class="question">
                綜觀「L11301 機器學習基本原理」後半段要點，下列何者最佳總結？
            </div>
            <div class="options">
                A. 機器學習不需資料清理，也不用關心泛化<br>
                <span class="correct">B. 須兼顧演算法特性、超參數調整、正則化與資料品質，並持續監控以達最佳效果</span><br>
                C. 只要深度學習就萬能<br>
                D. 評估不重要
            </div>
            <div class="answer">
                答案：<span class="correct">B</span>
                <div class="explanation">
                    解析：成功機器學習需多層面配合：特徵、演算法、調參、正則與評估迭代，持續維護才能在實務中表現良好。
                </div>
            </div>
        <h2 style="text-align:center; margin-top:30px;">--- 以上為檔案6：L11301 機器學習基本原理 100題 ---</h2>
    </div>
</body>
</html>