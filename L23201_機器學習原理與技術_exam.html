<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <title>iPAS AI應用規劃師 經典題庫 - L23201 機器學習原理與技術</title>
    <style>
        /* RWD設定，讓整體版面在不同裝置都有良好顯示 */
        * {
            box-sizing: border-box;
        }
        body {
            margin: 0;
            padding: 0;
            font-family: "Microsoft JhengHei", sans-serif;
            background: #f5f5f5;
            /* Changed default text color to pure black */
            color: #000;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #ffffff;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        h1, h2 {
            text-align: center;
            margin-bottom: 10px;
        }
        h1 {
            margin-top: 20px;
            font-size: 1.8rem;
            color: #2c3e50; /* Header color kept for contrast */
        }
        .header-container {
            background: linear-gradient(135deg, #3498db, #2c3e50);
            color: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 5px;
            text-align: center;
        }
        .header-container h1 {
            margin: 0;
            color: white;
            font-size: 2rem;
        }
        /* 出題方向區塊樣式 */
        .directions-container {
            background-color: #fffbeb;
            padding: 15px;
            margin-bottom: 20px;
            border-left: 5px solid #f1c40f;
            border-radius: 5px;
        }
        .directions-title {
            font-size: 1.2rem;
            font-weight: bold;
            margin-bottom: 10px;
            color: #2c3e50; /* Header color kept for contrast */
        }
        .directions-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
            gap: 10px;
        }
        .direction-item {
            display: flex;
            align-items: center;
            padding: 10px;
            background-color: white;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        .direction-item:hover {
            background-color: #f1c40f;
            color: white;
        }
        .direction-number {
            width: 25px;
            height: 25px;
            background-color: #f1c40f;
            color: white;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            margin-right: 10px;
            font-weight: bold;
        }
        .direction-item:hover .direction-number {
            background-color: white;
            color: #f1c40f;
        }
        /* 問題卡片樣式 */
        .questions-container {
            display: grid;
            grid-template-columns: 1fr;
            gap: 20px;
        }
        .responsive-img {
            width: 100%;
            max-width: 800px; /* 可自訂最大寬度 */
            height: auto;
        }
        .question-card {
            background-color: white;
            border-radius: 5px;
            padding: 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            transition: transform 0.3s;
        }
        .question-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        .question-header {
            display: flex;
            justify-content: space-between;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 1px solid #eee;
        }
        .question-id {
            font-weight: bold;
            color: #3498db; /* Kept for visual distinction */
        }
        .question-frequency {
            color: #e74c3c; /* Kept for visual distinction */
            font-weight: bold;
        }
        .question-content {
            font-size: 1.1rem;
            margin-bottom: 15px;
            line-height: 1.5;
        }
        .options-container {
            display: grid;
            grid-template-columns: 1fr;
            gap: 10px;
            margin-bottom: 20px;
        }
        .option-item {
            display: flex;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        .option-item:hover {
            background-color: #e9ecef;
        }
        .option-item.correct {
            background-color: #d4edda;
            border-left: 5px solid #28a745;
        }
        .option-item.correct:hover {
            background-color: #c3e6cb;
        }
        .option-label {
            width: 25px;
            height: 25px;
            background-color: #3498db; /* Kept for visual distinction */
            color: white;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            margin-right: 10px;
            font-weight: bold;
        }
        .option-item.correct .option-label {
            background-color: #28a745; /* Kept for visual distinction */
        }
        .explanation-container {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin-top: 10px;
            display: block; /* Initially shown */
        }
        .explanation-header {
            font-weight: bold;
            margin-bottom: 10px;
            color: #2c3e50; /* Header color kept for contrast */
        }
        .explanation-content {
            line-height: 1.6;
        }
        /* 控制區塊樣式 */
        .controls {
            display: flex;
            justify-content: space-between;
            margin-bottom: 20px;
            flex-wrap: wrap;
            gap: 10px; /* Add gap for better spacing */
        }
        .filter-container, .search-container, .star-filter-container { /* Added star filter container */
            margin-bottom: 10px;
            display: flex; /* Align items nicely */
            align-items: center; /* Vertically align */
        }
        .filter-label, .search-label, .star-filter-label { /* Added star filter label */
            font-weight: bold;
            margin-right: 10px;
            white-space: nowrap; /* Prevent label wrapping */
        }
        select, input[type="text"] {
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 5px;
            font-family: inherit;
            flex-grow: 1; /* Allow input/select to grow */
            min-width: 150px; /* Ensure minimum width */
        }
         input[type="text"] {
            flex-grow: 2; /* Allow search input to be wider */
         }
        button {
            padding: 8px 15px;
            background-color: #3498db; /* Kept for visual distinction */
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-family: inherit;
            transition: background-color 0.3s;
            margin-left: 5px; /* Add margin for buttons */
        }
        button:hover {
            background-color: #2980b9; /* Kept for visual distinction */
        }
        /* RWD調整 */
        @media (max-width: 992px) { /* Adjust breakpoint */
             .controls {
                flex-direction: column;
                align-items: stretch; /* Make items full width */
            }
            .filter-container, .search-container, .star-filter-container {
                width: 100%;
            }
             select, input[type="text"] {
                 width: auto; /* Reset width */
                 flex-grow: 1; /* Allow growth */
             }
        }
        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            .directions-grid {
                grid-template-columns: 1fr;
            }
        }
        /* 顯示/隱藏解析的按鈕 */
        .toggle-explanations {
            margin-bottom: 10px; /* Adjusted margin */
            display: flex; /* Align button */
            align-items: center; /* Vertically align */
        }
        /* 返回頂部按鈕 */
        .back-to-top {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background-color: #3498db; /* Kept for visual distinction */
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: none; /* Hidden by default */
            justify-content: center;
            align-items: center;
            cursor: pointer;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            transition: background-color 0.3s, opacity 0.3s;
            z-index: 1000;
            opacity: 0.7;
        }
        .back-to-top:hover {
            background-color: #2980b9; /* Kept for visual distinction */
            opacity: 1;
        }
        /* 進度指示器 */
        .progress-container {
            width: 100%;
            height: 5px;
            background-color: #f1f1f1;
            position: fixed;
            top: 0;
            left: 0;
            z-index: 1001;
        }
        .progress-bar {
            height: 5px;
            background-color: #3498db; /* Kept for visual distinction */
            width: 0%;
        }
         /* Message for no results */
         #noResultsMessage {
             display: none; /* Hidden by default */
             text-align: center;
             padding: 20px;
             color: #777;
             font-size: 1.1rem;
             margin-top: 20px;
             background-color: #f9f9f9;
             border-radius: 5px;
         }

        /* Added styles for terminology and highlighting */
        .term-zh {
            color: blue;
            font-weight: bold;
        }
        .term-en-abbr {
            color: purple;
            font-weight: bold;
        }
        .term-en-full {
            color: red;
            font-weight: bold;
        }
        .highlight-keyword {
            background-color: #ffff0030; /* Light yellow background */
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="progress-container">
        <div class="progress-bar" id="progressBar"></div>
    </div>

    <div class="container">
        <div class="header-container">
            <h1>iPAS AI應用規劃師 經典題庫</h1>
            <div>L23201 機器學習原理與技術</div>
        </div>

        <!-- Controls and Directions sections remain unchanged -->
        <div class="controls">
            <div class="filter-container">
                <label for="directionFilter" class="filter-label">篩選出題方向：</label>
                <select id="directionFilter">
                    <option value="all">全部方向</option>
                    <option value="1">機器學習概論與類型</option>
                    <option value="2">監督式學習：回歸</option>
                    <option value="3">監督式學習：分類</option>
                    <option value="4">非監督式學習：分群</option>
                    <option value="5">非監督式學習：降維</option>
                    <option value="6">模型評估、選擇與調校</option>
                    <option value="7">特徵工程與資料預處理</option>
                    <option value="8">系集學習與進階概念</option>
                </select>
            </div>

            <div class="star-filter-container">
                <label for="starFilter" class="star-filter-label">篩選重要性：</label>
                <select id="starFilter">
                    <option value="all">全部重要性</option>
                    <option value="5">★★★★★</option>
                    <option value="4">★★★★</option>
                    <option value="3">★★★</option>
                    <option value="2">★★</option>
                    <option value="1">★</option>
                </select>
            </div>

            <div class="search-container">
                <label for="searchInput" class="search-label">搜尋：</label>
                <input type="text" id="searchInput" placeholder="輸入關鍵字...">
                <button id="searchButton">搜尋</button>
            </div>

                         <div class="toggle-explanations">
                 <button id="toggleExplanations">顯示/隱藏全部解析</button>
                 <button id="toggleAnswers">隱藏全部解答</button>
             </div>
        </div>

        <div class="directions-container">
            <div class="directions-title">出題方向</div>
            <div class="directions-grid" id="directionsGrid">
                 <div class="direction-item" onclick="filterByDirection(1)">
                    <div class="direction-number">1</div>
                    <div class="direction-text">機器學習概論與類型</div>
                </div>
                <div class="direction-item" onclick="filterByDirection(2)">
                    <div class="direction-number">2</div>
                    <div class="direction-text">監督式學習：回歸</div>
                </div>
                <div class="direction-item" onclick="filterByDirection(3)">
                    <div class="direction-number">3</div>
                    <div class="direction-text">監督式學習：分類</div>
                </div>
                <div class="direction-item" onclick="filterByDirection(4)">
                    <div class="direction-number">4</div>
                    <div class="direction-text">非監督式學習：分群</div>
                </div>
                 <div class="direction-item" onclick="filterByDirection(5)">
                    <div class="direction-number">5</div>
                    <div class="direction-text">非監督式學習：降維</div>
                </div>
                <div class="direction-item" onclick="filterByDirection(6)">
                    <div class="direction-number">6</div>
                    <div class="direction-text">模型評估、選擇與調校</div>
                </div>
                <div class="direction-item" onclick="filterByDirection(7)">
                    <div class="direction-number">7</div>
                    <div class="direction-text">特徵工程與資料預處理</div>
                </div>
                <div class="direction-item" onclick="filterByDirection(8)">
                    <div class="direction-number">8</div>
                    <div class="direction-text">系集學習與進階概念</div>
                </div>
            </div>
        </div>

        <div class="questions-container" id="questionsContainer">

            <!-- Question 1 -->
            <div class="question-card" data-direction="1" data-stars="5">
                <div class="question-header">
                    <div class="question-id">#1</div>
                    <div class="question-frequency">★★★★★</div>
                </div>
                <div class="question-content">下列哪項最能描述<span class="term-zh">監督式學習</span>（<span class="term-en-full">Supervised Learning</span>）的特點？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">模型從<span class="highlight-keyword">未標註</span>的數據中自行尋找模式或結構。</div>
                    </div>
                    <div class="option-item correct" data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text">模型從帶有<span class="highlight-keyword">標籤</span> (<span class="term-en-full">Labels</span>) 或<span class="highlight-keyword">目標輸出</span> (<span class="term-en-full">Target Outputs</span>) 的輸入數據中學習<span class="highlight-keyword">映射關係</span>。</div>
                    </div>
                     <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text">模型通過與環境互動，根據獲得的獎勵或懲罰來學習最佳行為策略。</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">模型的主要目標是降低數據的維度。</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content"><span class="term-zh">監督式學習</span>是<span class="term-zh">機器學習</span>最主要的類型之一。其核心特徵是訓練數據包含成對的<span class="highlight-keyword">輸入</span>（<span class="term-zh">特徵</span>）和對應的<span class="highlight-keyword">正確輸出</span>（<span class="term-zh">標籤</span>或<span class="term-zh">目標值</span>）。模型的目標是學習一個從輸入到輸出的<span class="highlight-keyword">映射函數</span> f，使得對於新的、未見過的輸入 x，模型能夠預測出接近真實輸出的 y。根據輸出的類型，<span class="term-zh">監督式學習</span>可以分為：
                    <ul><li><span class="highlight-keyword"><span class="term-zh">分類</span></span> (<span class="term-en-full">Classification</span>)：輸出是<span class="highlight-keyword">離散的類別標籤</span>（如「貓」、「狗」；「垃圾郵件」、「非垃圾郵件」）。</li><li><span class="highlight-keyword"><span class="term-zh">迴歸</span></span> (<span class="term-en-full">Regression</span>)：輸出是<span class="highlight-keyword">連續的數值</span>（如房價、溫度、銷售額）。</li></ul>
                    選項 A 描述的是<span class="term-zh">非監督式學習</span>。選項 C 描述的是<span class="term-zh">強化學習</span>。選項 D 描述的是<span class="term-zh">降維</span>（屬於<span class="term-zh">非監督式學習</span>的一種）。</div>
                    <img src="image/Supervised_and_unsupervised_learning.png" class="responsive-img">
                </div>
            </div>

            <!-- Question 2 -->
            <div class="question-card" data-direction="2" data-stars="4">
                <div class="question-header">
                    <div class="question-id">#2</div>
                    <div class="question-frequency">★★★★</div>
                </div>
                <div class="question-content">預測房屋的價格（一個<span class="highlight-keyword">連續數值</span>），根據房屋的大小、位置、屋齡等特徵，這屬於哪種類型的<span class="term-zh">機器學習</span>問題？</div>
                <div class="options-container">
                    <div class="option-item correct" data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text"><span class="highlight-keyword">迴歸</span> (<span class="term-en-full">Regression</span>)</div>
                    </div>
                    <div class="option-item " data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><span class="term-zh">分類</span> (<span class="term-en-full">Classification</span>)</div>
                    </div>
                     <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text"><span class="term-zh">分群</span> (<span class="term-en-full">Clustering</span>)</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text"><span class="term-zh">降維</span> (<span class="term-en-full">Dimensionality Reduction</span>)</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content"><span class="term-zh">迴歸</span>問題的目標是預測一個<span class="highlight-keyword">連續的數值輸出</span>。在這個例子中，房屋價格是一個<span class="term-zh">連續變數</span>，我們希望根據輸入的特徵（大小、位置、屋齡等）來預測這個數值。因此，這是一個典型的<span class="term-zh">迴歸</span>問題。<span class="term-zh">分類</span>問題的目標是預測<span class="term-zh">離散的類別標籤</span>（例如，預測房屋是「豪華」還是「普通」）。<span class="term-zh">分群</span>和<span class="term-zh">降維</span>屬於<span class="term-zh">非監督式學習</span>，不需要<span class="term-zh">標籤</span>。</div>
                    <img src="image/regression-vs-classification.webp" class="responsive-img">
                </div>
            </div>

            <!-- Question 3 -->
            <div class="question-card" data-direction="3" data-stars="4">
                <div class="question-header">
                    <div class="question-id">#3</div>
                    <div class="question-frequency">★★★★</div>
                </div>
                <div class="question-content">判斷一封電子郵件是否為垃圾郵件（<span class="highlight-keyword">是/否</span>），這屬於哪種類型的<span class="term-zh">機器學習</span>問題？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text"><span class="term-zh">迴歸</span> (<span class="term-en-full">Regression</span>)</div>
                    </div>
                    <div class="option-item correct" data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><span class="highlight-keyword">分類</span> (<span class="term-en-full">Classification</span>)</div>
                    </div>
                     <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text"><span class="term-zh">分群</span> (<span class="term-en-full">Clustering</span>)</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text"><span class="term-zh">關聯規則學習</span> (<span class="term-en-full">Association Rule Learning</span>)</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content"><span class="term-zh">分類</span>問題的目標是將輸入數據分配到預定義的<span class="highlight-keyword">離散類別</span>中。在這個例子中，我們需要將每封電子郵件歸類為<span class="highlight-keyword">兩個類別</span>之一：「垃圾郵件」或「非垃圾郵件」。由於輸出是<span class="term-zh">離散的類別標籤</span>，這是一個典型的<span class="highlight-keyword">二元分類</span> (<span class="term-en-full">Binary Classification</span>) 問題。</div>
                    <img src="image/regression-vs-classification.webp" class="responsive-img">
                </div>
            </div>

            <!-- Question 4 -->
            <div class="question-card" data-direction="4" data-stars="4">
                <div class="question-header">
                    <div class="question-id">#4</div>
                    <div class="question-frequency">★★★★</div>
                </div>
                <div class="question-content"><span class="term-en-abbr">K-means</span> 演算法是一種常用的<span class="term-zh">機器學習</span>技術，主要用於解決哪類問題？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text"><span class="term-zh">監督式迴歸</span></div>
                    </div>
                     <div class="option-item " data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><span class="term-zh">監督式分類</span></div>
                    </div>
                     <div class="option-item correct" data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text"><span class="highlight-keyword">非監督式分群</span> (<span class="term-en-full">Clustering</span>)</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text"><span class="term-zh">強化學習</span></div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content"><span class="term-en-abbr">K-means</span> 是一種<span class="highlight-keyword">非監督式學習</span>算法，其目標是將<span class="highlight-keyword">未標註</span>的數據點劃分成 K 個不同的<span class="highlight-keyword">群集</span> (<span class="term-en-full">Clusters</span>)。它通過<span class="highlight-keyword">迭代</span>地將每個數據點分配給最近的群集中心（<span class="term-zh">質心</span> <span class="term-en-full">Centroid</span>），然後重新計算每個群集的中心，直到群集分配不再變化或達到最大迭代次數。由於它不需要預先標註的數據，而是試圖從數據本身中發現潛在的群組結構，因此屬於<span class="highlight-keyword">非監督式分群</span>。</div>
                    <img src="image/K-Means.avif" class="responsive-img">
                </div>
            </div>

            <!-- Question 5 -->
            <div class="question-card" data-direction="5" data-stars="5">
                 <div class="question-header">
                     <div class="question-id">#5</div>
                     <div class="question-frequency">★★★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">主成分分析</span> (<span class="term-en-full">Principal Component Analysis</span>, <span class="term-en-abbr">PCA</span>) 主要用於<span class="term-zh">機器學習</span>中的哪個目的？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">預測離散類別標籤。</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text">預測連續數值。</div></div>
                     <div class="option-item correct" data-option="C"><div class="option-label">C</div><div class="option-text"><span class="highlight-keyword">降低數據的維度</span> (<span class="term-en-full">Dimensionality Reduction</span>)，同時<span class="highlight-keyword">保留大部分變異信息</span>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">將數據分成不同的群組。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-en-abbr">PCA</span> 是一種<span class="highlight-keyword">非監督式學習</span>技術，主要用於<span class="highlight-keyword">降維</span>。它通過找到一組新的<span class="highlight-keyword">正交座標軸</span>（<span class="highlight-keyword">主成分</span>），這些座標軸能夠捕捉數據中<span class="highlight-keyword">最大變異</span>的方向。通過只保留前幾個最重要的主成分，可以將高維數據投影到一個低維空間，同時損失盡可能少的信息（<span class="term-zh">變異</span>）。<span class="term-en-abbr">PCA</span> 常被用作數據預處理步驟，以減少特徵數量、去除冗餘、壓縮數據、方便視覺化或提高後續模型的性能。預測標籤是分類（A），預測數值是迴歸（B），分群是聚類（D）。</div>
                     <img src="image/PCA.jpg" class="responsive-img">
                 </div>
            </div>

            <!-- Question 6 -->
            <div class="question-card" data-direction="6" data-stars="5">
                 <div class="question-header">
                     <div class="question-id">#6</div>
                     <div class="question-frequency">★★★★★</div>
                 </div>
                 <div class="question-content">在<span class="term-zh">機器學習</span>中，將數據集劃分為<span class="term-zh">訓練集</span> (<span class="term-en-full">Training Set</span>)、<span class="term-zh">驗證集</span> (<span class="term-en-full">Validation Set</span>) 和<span class="term-zh">測試集</span> (<span class="term-en-full">Test Set</span>) 的主要目的是什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">僅為了加快訓練速度。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">訓練集</span>用於訓練模型參數；<span class="highlight-keyword">驗證集</span>用於調整模型<span class="term-zh">超參數</span>和進行<span class="term-zh">模型選擇</span>；<span class="highlight-keyword">測試集</span>用於最終評估模型的<span class="term-zh">泛化能力</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">訓練集</span>用於評估，<span class="term-zh">驗證集</span>和<span class="term-zh">測試集</span>用於訓練。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">所有集合都用於訓練模型以達到最高<span class="term-zh">準確率</span>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">為了客觀地評估模型性能並避免<span class="term-zh">過擬合</span>，通常需要將數據集進行劃分：
                     <ul>
                         <li><span class="highlight-keyword">訓練集 (<span class="term-en-full">Training Set</span>)</span>：用於訓練模型，即調整模型的內部參數（如<span class="term-zh">權重</span>、<span class="term-zh">偏置</span>）。</li>
                         <li><span class="highlight-keyword">驗證集 (<span class="term-en-full">Validation Set</span>)</span>：用於在模型訓練過程中或訓練後，評估不同模型架構或不同<span class="term-zh">超參數</span>（如<span class="term-zh">學習率</span>、<span class="term-zh">正規化</span>強度、隱藏層單元數）組合的性能，以便<span class="highlight-keyword">選擇最佳的模型配置</span>。它模擬了未見數據，幫助檢測<span class="term-zh">過擬合</span>。</li>
                         <li><span class="highlight-keyword">測試集 (<span class="term-en-full">Test Set</span>)</span>：在<span class="term-zh">模型選擇</span>和<span class="term-zh">超參數調整</span>完成後，使用<span class="term-zh">測試集</span>對最終選定的模型進行<span class="highlight-keyword">一次性</span>的評估，得到模型在<span class="highlight-keyword">完全未見過的數據</span>上的<span class="highlight-keyword">泛化性能</span>的最終估計。<span class="term-zh">測試集不應參與任何訓練或調優過程</span>，以保證評估的公正性。</li>
                     </ul>
                     這種劃分是防止模型在開發過程中「偷看」測試數據而導致評估結果過於樂觀的關鍵步驟。</div>
                 </div>
            </div>

             <!-- Question 7 -->
            <div class="question-card" data-direction="7" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#7</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">獨熱編碼</span> (<span class="term-en-full">One-Hot Encoding</span>) 是一種常用的數據預處理技術，主要用於處理哪種類型的特徵？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">連續數值特徵 (<span class="term-en-full">Continuous Numerical Features</span>)</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">名目類別特徵</span> (<span class="term-en-full">Nominal Categorical Features</span>)</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">有序類別特徵 (<span class="term-en-full">Ordinal Categorical Features</span>)</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">日期時間特徵 (<span class="term-en-full">Datetime Features</span>)</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">許多<span class="term-zh">機器學習</span>算法（尤其是基於距離或線性模型的算法）無法直接處理<span class="term-zh">類別型特徵</span>。<span class="highlight-keyword">獨熱編碼</span>是一種將<span class="highlight-keyword">名目類別特徵</span>（即類別之間<span class="highlight-keyword">沒有內在順序關係</span>，如「顏色：紅、綠、藍」或「城市：台北、台中、高雄」）轉換為數值形式的方法。對於一個具有 k 個可能類別的特徵，<span class="term-zh">獨熱編碼</span>會創建 k 個新的<span class="highlight-keyword">二元（0或1）特徵</span>。對於每個樣本，只有對應其原始類別的新特徵值為 1，其餘 k-1 個新特徵值都為 0。例如，「顏色」特徵，「紅」可能被編碼為 [1, 0, 0]，「綠」為 [0, 1, 0]，「藍」為 [0, 0, 1]。這種表示方式避免了算法錯誤地假設類別之間存在數值大小或順序關係。對於<span class="term-zh">有序類別特徵</span>（如「滿意度：低、中、高」），有時會使用<span class="term-zh">標籤編碼</span> (<span class="term-en-full">Label Encoding</span>) 或其他方法。</div>
                     <br>
                     <img src="image/One-Hot Encoding.png" class="responsive-img">
                 </div>
            </div>

             <!-- Question 8 -->
            <div class="question-card" data-direction="8" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#8</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">隨機森林</span> (<span class="term-en-full">Random Forest</span>) 是一種<span class="term-zh">系集學習</span> (<span class="term-en-full">Ensemble Learning</span>) 方法，它通過結合多個什麼<span class="term-zh">基學習器</span> (<span class="term-en-full">Base Learner</span>) 來進行預測？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">線性迴歸</span>模型</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">決策樹</span> (<span class="term-en-full">Decision Trees</span>)</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">支持向量機</span> (<span class="term-en-abbr">SVM</span>)</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">K-近鄰</span> (<span class="term-en-abbr">KNN</span>) 模型</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">隨機森林</span>是基於 <span class="highlight-keyword">Bagging</span> (<span class="term-en-full">Bootstrap Aggregating</span>) 思想的<span class="term-zh">系集學習</span>算法，其<span class="highlight-keyword">基學習器是決策樹</span>。它構建多個<span class="term-zh">決策樹</span>，每棵樹的訓練過程引入了兩種<span class="highlight-keyword">隨機性</span>：
                     <ol>
                         <li><span class="highlight-keyword">樣本隨機性</span>：每棵樹使用通過<span class="term-zh">自助法</span> (<span class="term-en-full">Bootstrap</span>) 從原始訓練集中隨機抽樣得到的樣本子集進行訓練。</li>
                         <li><span class="highlight-keyword">特徵隨機性</span>：在每個節點分裂時，不是考慮所有特徵，而是從中隨機選擇一部分特徵（例如，總特徵數的平方根）來尋找最佳分裂點。</li>
                     </ol>
                     這種隨機性使得每棵樹之間具有<span class="highlight-keyword">差異性</span> (<span class="term-en-full">Diversity</span>)。在進行預測時，<span class="term-zh">隨機森林</span>將所有樹的預測結果進行匯總：對於<span class="term-zh">分類</span>問題，通常採用<span class="highlight-keyword">投票</span> (<span class="term-en-full">Voting</span>) 方式；對於<span class="term-zh">迴歸</span>問題，通常採用<span class="highlight-keyword">平均</span> (<span class="term-en-full">Averaging</span>) 方式。通過結合多個（隨機的）<span class="term-zh">決策樹</span>，<span class="term-zh">隨機森林</span>通常能顯著提高模型的<span class="highlight-keyword">穩定性</span>和<span class="highlight-keyword">泛化能力</span>，降低單個<span class="term-zh">決策樹</span>容易<span class="term-zh">過擬合</span>的風險。</div>
                     <br>
                     <img src="image/Random Forest.webp" class="responsive-img">
                 </div>
            </div>

             <!-- Question 9 -->
            <div class="question-card" data-direction="6" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#9</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">過擬合</span> (<span class="term-en-full">Overfitting</span>) 指的是<span class="term-zh">機器學習</span>模型在哪個數據集上表現良好，但在哪個數據集上表現較差？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">在<span class="term-zh">驗證集</span>上表現好，在<span class="term-zh">訓練集</span>上表現差。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">在<span class="highlight-keyword">訓練集</span>上表現好，但在<span class="highlight-keyword">未見過的數據</span>（如<span class="term-zh">驗證集</span>或<span class="term-zh">測試集</span>）上表現差。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">在<span class="term-zh">訓練集</span>和<span class="term-zh">測試集</span>上都表現差。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">在<span class="term-zh">訓練集</span>和<span class="term-zh">測試集</span>上都表現好。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="highlight-keyword">過擬合</span>是<span class="term-zh">機器學習</span>中常見的問題。當模型<span class="highlight-keyword">過於複雜</span>或訓練數據不足時，模型可能會學習到<span class="highlight-keyword">訓練數據</span>中特有的<span class="highlight-keyword">噪聲</span>或隨機模式，而不是潛在的、具有<span class="term-zh">泛化性</span>的規律。這導致模型在<span class="highlight-keyword">訓練集</span>上能夠取得非常低的誤差（表現很好），但當遇到新的、未在訓練中出現過的數據時，其預測性能會顯著下降（表現很差）。這表明模型未能很好地<span class="highlight-keyword">泛化</span> (<span class="term-en-full">Generalize</span>) 到新數據。相對應的是<span class="term-zh">欠擬合</span> (<span class="term-en-full">Underfitting</span>)，指模型過於簡單，連訓練數據中的基本模式都未能很好地捕捉，導致在<span class="term-zh">訓練集</span>和<span class="term-zh">測試集</span>上表現都不佳。</div>
                     <img src="image/overfitting underfitting.png" class="responsive-img">
                 </div>
            </div>

            <!-- Question 10 -->
            <div class="question-card" data-direction="7" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#10</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">特徵縮放</span> (<span class="term-en-full">Feature Scaling</span>)，例如<span class="term-zh">標準化</span> (<span class="term-en-full">Standardization</span>) 或<span class="term-zh">歸一化</span> (<span class="term-en-full">Normalization</span>)，在應用於某些<span class="term-zh">機器學習</span>算法之前通常是必要的，主要原因是？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">為了增加特徵的數量。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">防止具有<span class="highlight-keyword">較大數值範圍</span>的特徵<span class="highlight-keyword">主導</span>模型的學習過程，確保所有特徵貢獻相對公平，有助於算法<span class="highlight-keyword">收斂</span>和性能提升。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">為了將所有特徵轉換為<span class="term-zh">類別型</span>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">為了減少數據集的大小。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">許多<span class="term-zh">機器學習</span>算法對輸入特徵的<span class="highlight-keyword">尺度敏感</span>，特別是：
                     <ul>
                         <li><span class="highlight-keyword">基於距離的算法</span>：如 <span class="term-zh">K-近鄰</span> (<span class="term-en-abbr">KNN</span>)、<span class="term-zh">K-means</span>、<span class="term-zh">支持向量機</span> (<span class="term-en-abbr">SVM</span>) 等，距離計算會被數值範圍大的特徵所主導。</li>
                         <li><span class="highlight-keyword">基於梯度下降的算法</span>：如<span class="term-zh">線性迴歸</span>、<span class="term-zh">邏輯迴歸</span>、<span class="term-zh">神經網路</span>等，不同尺度的特徵可能導致<span class="term-zh">損失函數</span>的等高線圖呈橢圓形，使得梯度下降收斂緩慢或困難。</li>
                     </ul>
                     <span class="term-zh">特徵縮放</span>通過將所有特徵轉換到<span class="highlight-keyword">相似的數值範圍</span>來解決這個問題。常用方法包括：
                     <ul>
                         <li><span class="highlight-keyword">標準化 (<span class="term-en-full">Standardization</span>)</span>：將特徵轉換為均值為 0，標準差為 1 的分佈 (<span class="term-en-full">Z-score</span>: (x - μ) / σ)。</li>
                         <li><span class="highlight-keyword">歸一化 (<span class="term-en-full">Normalization</span>) / 最小-最大縮放 (<span class="term-en-full">Min-Max Scaling</span>)</span>：將特徵縮放到 [0, 1] 或 [-1, 1] 的區間（例如：(x - min) / (max - min)）。</li>
                     </ul>
                     這樣可以確保所有特徵在模型學習中獲得相對平等的對待，有助於提高算法的性能和收斂速度。對於像<span class="term-zh">決策樹</span>、<span class="term-zh">隨機森林</span>這樣基於規則分裂的算法，通常對<span class="term-zh">特徵縮放不敏感</span>。</div>
                 </div>
            </div>

            <!-- Question 11 -->
             <div class="question-card" data-direction="1" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#11</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">強化學習</span> (<span class="term-en-full">Reinforcement Learning</span>, <span class="term-en-abbr">RL</span>) 與<span class="term-zh">監督式</span>和<span class="term-zh">非監督式學習</span>的主要區別在於其學習方式基於？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">帶<span class="term-zh">標籤</span>的輸入輸出對。</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text"><span class="term-zh">未標註</span>數據中的模式發現。</div></div>
                     <div class="option-item correct" data-option="C"><div class="option-label">C</div><div class="option-text"><span class="highlight-keyword">代理</span> (<span class="term-en-full">Agent</span>) 與<span class="highlight-keyword">環境</span>的<span class="highlight-keyword">互動</span>，並通過<span class="highlight-keyword">最大化累積獎勵</span> (<span class="term-en-full">Cumulative Reward</span>) 來學習<span class="highlight-keyword">策略</span> (<span class="term-en-full">Policy</span>)。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">數據降維</span>和視覺化。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">強化學習</span>關注的是<span class="highlight-keyword">智能代理</span> (<span class="term-en-full">Agent</span>) 如何在一個<span class="highlight-keyword">環境</span> (<span class="term-en-full">Environment</span>) 中學習做出一系列<span class="highlight-keyword">決策</span>（動作 <span class="term-en-full">Actions</span>），以<span class="highlight-keyword">最大化</span>其獲得的長期<span class="highlight-keyword">累積獎勵</span>。<span class="term-zh">代理</span>不是被告知「正確」的動作（像<span class="term-zh">監督學習</span>那樣），而是通過<span class="highlight-keyword">試錯</span> (<span class="term-en-full">Trial-and-Error</span>) 來學習。<span class="term-zh">代理</span>執行一個動作後，環境會轉移到一個新的<span class="highlight-keyword">狀態</span> (<span class="term-en-full">State</span>)，並給予<span class="term-zh">代理</span>一個立即的<span class="highlight-keyword">回饋信號</span>（<span class="highlight-keyword">獎勵</span> <span class="term-en-full">Reward</span> 或懲罰 <span class="term-en-full">Penalty</span>）。<span class="term-zh">代理</span>的目標是學習一個<span class="highlight-keyword">策略</span> (<span class="term-en-full">Policy</span>)，即在特定狀態下選擇哪個動作，才能使得從長遠來看獲得的總獎勵最大化。這種通過與環境互動和獎勵信號來學習的方式是<span class="term-zh">強化學習</span>的獨特之處，適用於遊戲（如 <span class="term-en-abbr">AlphaGo</span>）、機器人控制、資源調度等問題。</div>
                     <br>
                     <img src="image/Reinforcement Learning.jpg" class="responsive-img">
                 </div>
            </div>

            <!-- Question 12 -->
             <div class="question-card" data-direction="2" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#12</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">在<span class="term-zh">線性回歸</span>中，常用來評估模型<span class="term-zh">擬合優度</span> (<span class="term-en-full">Goodness of Fit</span>) 的一個指標是 <span class="term-zh">R 平方</span> (<span class="term-en-abbr">R-squared</span>) 或稱<span class="term-zh">決定係數</span> (<span class="term-en-full">Coefficient of Determination</span>)。<span class="term-en-abbr">R</span> 平方的值越接近 1 代表什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">模型的預測誤差越大。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">模型能夠解釋<span class="term-zh">應變數</span>（目標變數）總<span class="highlight-keyword">變異</span>的<span class="highlight-keyword">比例越高</span>，<span class="highlight-keyword">擬合效果越好</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">自變數</span>之間的<span class="term-zh">多重共線性</span>越嚴重。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">模型參數越多。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">R 平方</span>衡量的是<span class="term-zh">迴歸模型</span>對<span class="term-zh">應變數</span> y 的總<span class="highlight-keyword">變異</span>能夠解釋的百分比。其計算公式為 <span class="highlight-keyword">R² = 1 - (SSR / SST)</span>，其中 <span class="term-en-abbr">SSR</span> (<span class="term-en-full">Sum of Squared Residuals</span>) 是<span class="term-zh">殘差平方和</span>（模型未能解釋的變異），<span class="term-en-abbr">SST</span> (<span class="term-en-full">Total Sum of Squares</span>) 是總平方和（y 的總變異，相對於其平均值）。<span class="term-en-abbr">R</span> 平方的取值範圍通常在 0 到 1 之間（也可能為負，如果模型比簡單預測平均值還差）。<span class="highlight-keyword">R² 越接近 1</span>，表示模型解釋了 y 的大部分<span class="term-zh">變異性</span>，<span class="highlight-keyword">擬合效果越好</span>；<span class="term-en-abbr">R²</span> 越接近 0，表示模型幾乎沒有解釋 y 的<span class="term-zh">變異</span>。需要注意的是，<span class="term-en-abbr">R²</span> 會隨著模型中<span class="term-zh">自變數</span>數量的增加而增加（即使增加的變數不相關），因此在比較不同模型時，<span class="highlight-keyword">調整後的 R 平方</span> (<span class="term-en-full">Adjusted R-squared</span>) 可能是一個更合適的指標，它對模型參數數量進行了懲罰。</div>
                     <br>
                     <img src="image/R-squared.png" class="responsive-img">
                 </div>
            </div>

            <!-- Question 13 -->
             <div class="question-card" data-direction="3" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#13</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">支持向量機</span> (<span class="term-en-full">Support Vector Machine</span>, <span class="term-en-abbr">SVM</span>) 最初是為了解決哪類問題而設計的？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">時間序列預測</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">二元分類</span> (<span class="term-en-full">Binary Classification</span>)</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">異常檢測 (<span class="term-en-full">Anomaly Detection</span>)</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">主題建模 (<span class="term-en-full">Topic Modeling</span>)</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-en-abbr">SVM</span> 最早被提出是用於解決<span class="highlight-keyword">二元分類</span>問題。其核心思想是找到一個能夠將兩類數據點分開，並且使得兩類之間<span class="highlight-keyword">間隔</span> (<span class="term-en-full">Margin</span>) <span class="highlight-keyword">最大化</span>的<span class="highlight-keyword">決策邊界</span>（<span class="term-zh">超平面</span> <span class="term-en-full">Hyperplane</span>）。對於線性不可分的數據，<span class="term-en-abbr">SVM</span> 可以通過引入<span class="highlight-keyword">核技巧</span> (<span class="term-en-full">Kernel Trick</span>) 將數據映射到更高維的特徵空間，在該空間中尋找線性分隔<span class="term-zh">超平面</span>，從而實現非線性分類。雖然 <span class="term-en-abbr">SVM</span> 後來也被擴展到解決<span class="term-zh">迴歸</span>問題（<span class="term-zh">支持向量迴歸</span>, <span class="term-en-abbr">SVR</span>）和<span class="term-zh">多類分類</span>問題，但其最基礎和最經典的應用是<span class="term-zh">二元分類</span>。</div>
                     <br>
                     <img src="image/SVM.png" class="responsive-img">
                 </div>
            </div>
            
             <!-- Question 14 -->
            <div class="question-card" data-direction="4" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#14</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">階層式分群</span> (<span class="term-en-full">Hierarchical Clustering</span>) 與 <span class="term-en-abbr">K-means</span> <span class="term-zh">分群</span>的主要區別在於？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-en-abbr">K-means</span> 不需要指定群數 K，<span class="term-zh">階層式分群</span>需要。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">階層式分群</span>會產生一個<span class="highlight-keyword">巢狀的群集結構</span>（<span class="term-zh">樹狀圖</span> <span class="term-en-full">Dendrogram</span>），<span class="highlight-keyword">不需要預先指定群數 K</span>，而 <span class="term-en-abbr">K-means</span> <span class="highlight-keyword">需要預先指定群數 K</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-en-abbr">K-means</span> 只能處理類別數據，<span class="term-zh">階層式分群</span>只能處理數值數據。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">階層式分群</span>的計算速度遠快於 <span class="term-en-abbr">K-means</span>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-en-abbr">K-means</span> 是一種<span class="highlight-keyword">劃分式分群</span> (<span class="term-en-full">Partitional Clustering</span>) 方法，它將數據點直接劃分成 K 個互斥的群集，需要用戶<span class="highlight-keyword">事先指定群集的數量 K</span>。而<span class="term-zh">階層式分群</span>則不同，它會構建一個群集的<span class="highlight-keyword">層次結構</span>。有兩種主要方式：
                     <ul>
                         <li><span class="highlight-keyword">凝聚式 (<span class="term-en-full">Agglomerative</span>) / 由下而上 (<span class="term-en-full">Bottom-up</span>)</span>：開始時每個數據點自成一群，然後逐步合併最相似（距離最近）的兩個群集，直到所有點合併為一個大群或達到某個停止條件。</li>
                         <li><span class="highlight-keyword">分裂式 (<span class="term-en-full">Divisive</span>) / 由上而下 (<span class="term-en-full">Top-down</span>)</span>：開始時所有數據點在一個大群中，然後逐步將群集分裂成更小的群集，直到每個點自成一群或達到某個停止條件。</li>
                     </ul>
                     <span class="term-zh">階層式分群</span>的結果通常用<span class="highlight-keyword">樹狀圖</span> (<span class="term-en-full">Dendrogram</span>) 來視覺化，顯示了群集合併或分裂的過程。用戶可以通過在不同高度切割<span class="term-zh">樹狀圖</span>來獲得不同數量的群集，因此它<span class="highlight-keyword">不需要預先指定 K 值</span>。但其計算複雜度通常高於 <span class="term-en-abbr">K-means</span>（特別是凝聚式）。</div>
                     <br>
                     <img src="image/Hierarchical Clustering.webp" class="responsive-img">
                 </div>
            </div>

            <!-- Question 15 -->
            <div class="question-card" data-direction="5" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#15</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">t-分佈隨機鄰近嵌入</span> (<span class="term-en-full">t-Distributed Stochastic Neighbor Embedding</span>, <span class="term-en-abbr">t-SNE</span>) 是一種常用的非線性<span class="term-zh">降維</span>技術，特別擅長用於什麼目的？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">數據壓縮以節省儲存空間。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">高維數據的視覺化</span> (<span class="term-en-full">Visualization</span>)，將數據投影到二維或三維空間，以揭示數據中的<span class="highlight-keyword">局部結構和群集</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">作為<span class="term-zh">分類模型</span>的最終預測步驟。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">替換 <span class="term-en-abbr">PCA</span> 進行線性<span class="term-zh">降維</span>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-en-abbr">t-SNE</span> 是一種<span class="highlight-keyword">非線性降維</span>算法，其主要目標是將高維數據點之間的相似性關係（在高維空間中，點 i 將以某個機率選擇點 j 作為其鄰居）在低維空間（通常是 2D 或 3D）中進行建模和再現（在低維空間中，點 i 也以某個機率選擇點 j 作為鄰居，這個機率使用 <span class="highlight-keyword">t-分佈</span>來計算）。它特別擅長揭示高維數據中存在的<span class="highlight-keyword">局部結構</span>和<span class="highlight-keyword">聚類模式</span>，並將其以視覺上分離的形式展現出來。因此，<span class="term-en-abbr">t-SNE</span> 最常用於高維數據集的<span class="highlight-keyword">探索性視覺化分析</span>。但需要注意：(1) <span class="term-en-abbr">t-SNE</span> 的計算成本相對較高。(2) 它主要關注保留<span class="term-zh">局部結構</span>，可能無法很好地保留全局結構。(3) 不同的<span class="term-zh">超參數</span>（如 <span class="term-en-full">Perplexity</span>）設置會影響結果。(4) 它通常不適合用於後續的密度估計或異常檢測，主要用於視覺探索。</div>
                     <br>
                     <img src="image/t-SNE.jpg" classs="responsive-img">
                 </div>
            </div>
            
            <!-- Question 16 -->
             <div class="question-card" data-direction="6" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#16</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">超參數</span> (<span class="term-en-full">Hyperparameter</span>) 與<span class="term-zh">模型參數</span> (<span class="term-en-full">Model Parameter</span>) 的主要區別是？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">兩者沒有區別。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">模型參數</span>是模型在訓練過程中從數據中<span class="highlight-keyword">學習得到</span>的（如<span class="term-zh">線性迴歸</span>的係數、<span class="term-zh">神經網路</span>的權重），而<span class="highlight-keyword">超參數</span>是在訓練<span class="highlight-keyword">之前</span>由用戶<span class="highlight-keyword">設定</span>的（如<span class="term-zh">學習率</span>、<span class="term-zh">正規化</span>強度、<span class="term-en-abbr">K-means</span> 中的 K 值）。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">超參數</span>只能是數值型，<span class="term-zh">模型參數</span>只能是類別型。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">模型參數</span>用於評估，<span class="term-zh">超參數</span>用於訓練。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">這是<span class="term-zh">機器學習</span>中的一個基礎區分：
                     <ul>
                         <li><span class="highlight-keyword">模型參數 (<span class="term-en-full">Model Parameters</span>)</span>：這些是模型內部用來進行預測的變數，它們的值是通過學習算法在訓練數據上<span class="highlight-keyword">學習得到</span>的。例如，<span class="term-zh">線性迴歸</span>的係數 β，<span class="term-zh">神經網路</span>的<span class="term-zh">權重 W</span> 和<span class="term-zh">偏置 b</span>。模型參數的數量可以非常多。</li>
                         <li><span class="highlight-keyword">超參數 (<span class="term-en-full">Hyperparameters</span>)</span>：這些是學習算法本身的參數，它們的值需要在<span class="highlight-keyword">訓練開始之前由用戶設定</span>，而不是從數據中學習。超參數控制著學習過程的行為和模型的結構。例如，<span class="term-zh">梯度下降</span>的<span class="term-zh">學習率 η</span>，<span class="term-zh">正規化</span>的強度 λ，<span class="term-en-abbr">SVM</span> 的懲罰係數 C 和核函數參數，<span class="term-zh">決策樹</span>的最大深度，<span class="term-en-abbr">K-means</span> 的群數 K，<span class="term-zh">神經網路</span>的層數和每層單元數等。</li>
                     </ul>
                     選擇合適的<span class="term-zh">超參數</span>對模型性能至關重要，通常需要通過<span class="term-zh">交叉驗證</span>、<span class="term-zh">網格搜索</span>、<span class="term-zh">隨機搜索</span>或<span class="term-zh">貝葉斯優化</span>等方法來進行<span class="highlight-keyword">調優</span> (<span class="term-en-full">Hyperparameter Tuning</span>)。</div>
                     <br>
                     <img src="image/"
                 </div>
            </div>

             <!-- Question 17 -->
             <div class="question-card" data-direction="7" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#17</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content">處理數據中的<span class="term-zh">缺失值</span> (<span class="term-en-full">Missing Values</span>) 時，下列哪種方法<span class="highlight-keyword">最不推薦</span>直接使用，尤其是在缺失比例較高時？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">用特徵的<span class="term-zh">平均值</span> (<span class="term-en-full">Mean</span>) 或<span class="term-zh">中位數</span> (<span class="term-en-full">Median</span>) 填充。</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text">用特徵的<span class="term-zh">眾數</span> (<span class="term-en-full">Mode</span>) 填充（適用於<span class="term-zh">類別特徵</span>）。</div></div>
                     <div class="option-item correct" data-option="C"><div class="option-label">C</div><div class="option-text"><span class="highlight-keyword">直接刪除</span>包含任何<span class="term-zh">缺失值</span>的<span class="highlight-keyword">整列樣本</span> (<span class="term-en-full">Listwise Deletion</span>)。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">使用<span class="term-zh">機器學習</span>模型（如 <span class="term-en-abbr">KNN Imputer</span> 或基於<span class="term-zh">迴歸</span>）來預測並填充<span class="term-zh">缺失值</span>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">處理<span class="term-zh">缺失值</span>有多種方法：
                     <ul>
                         <li><span class="highlight-keyword">刪除法</span>：可以直接刪除包含<span class="term-zh">缺失值</span>的樣本（行）或整個特徵（列）。刪除樣本 (<span class="term-en-full">Listwise Deletion</span>) 是最簡單的方法，但如果<span class="term-zh">缺失值</span>廣泛存在（比例較高），會導致<span class="highlight-keyword">丟失大量有價值的信息</span>，減少可用樣本量，甚至可能引入<span class="term-zh">偏見</span>（如果缺失不是完全隨機的）。刪除特徵則會丟失該特徵的所有信息。</li>
                         <li><span class="highlight-keyword">填充法 (<span class="term-en-full">Imputation</span>)</span>：用一個估計值來替換<span class="term-zh">缺失值</span>。簡單的方法是用該特徵的<span class="term-zh">均值</span>、<span class="term-zh">中位數</span>（對抗<span class="term-zh">離群值</span>更魯棒）或<span class="term-zh">眾數</span>（用於<span class="term-zh">類別特徵</span>）填充。更複雜的方法包括使用其他特徵通過<span class="term-zh">迴歸模型</span>預測<span class="term-zh">缺失值</span>，或者使用 <span class="term-en-abbr">K</span>-近鄰算法找到相似樣本的值來填充 (<span class="term-en-abbr">KNN Imputer</span>)。</li>
                     </ul>
                     <span class="highlight-keyword">直接刪除樣本</span>通常是<span class="highlight-keyword">最不推薦</span>的方法，除非缺失比例非常小或者有充分理由認為這些樣本不具代表性。填充法雖然引入了估計，但通常能更好地保留數據信息。</div>
                 </div>
            </div>

             <!-- Question 18 -->
             <div class="question-card" data-direction="8" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#18</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">梯度提升決策樹</span> (<span class="term-en-full">Gradient Boosting Decision Tree</span>, <span class="term-en-abbr">GBDT</span>) 是一種強大的<span class="term-zh">系集學習</span>算法。它與<span class="term-zh">隨機森林</span>的主要區別在於其構建樹的方式是？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="highlight-keyword">並行</span> (<span class="term-en-full">Parallel</span>) 構建多棵<span class="highlight-keyword">獨立</span>的樹。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">循序</span> (<span class="term-en-full">Sequential</span>) 構建樹，每一棵新樹都試圖<span class="highlight-keyword">修正</span>前面所有樹的<span class="highlight-keyword">殘差</span> (<span class="term-en-full">Residuals</span>) 或<span class="highlight-keyword">梯度</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">只使用一棵非常深的<span class="term-zh">決策樹</span>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">使用<span class="term-zh">支持向量機</span>作為<span class="term-zh">基學習器</span>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">隨機森林</span>（基於 <span class="term-zh">Bagging</span>）是<span class="highlight-keyword">並行</span>地訓練多棵<span class="highlight-keyword">獨立</span>的<span class="term-zh">決策樹</span>，然後將它們的結果匯總。而<span class="highlight-keyword">梯度提升</span> (<span class="term-en-full">Gradient Boosting</span>) 則是一種<span class="highlight-keyword">循序漸進</span>的<span class="term-zh">系集方法</span>。它從一個簡單的初始模型（例如，預測平均值）開始，然後<span class="highlight-keyword">迭代地添加</span>新的<span class="term-zh">基學習器</span>（通常是<span class="term-zh">決策樹</span>），每一棵新樹的目標是擬合前面模型預測結果的<span class="highlight-keyword">殘差</span>（對於平方損失）或者更一般地說是<span class="term-zh">損失函數</span>的<span class="highlight-keyword">負梯度</span>。通過逐步修正錯誤，梯度提升模型能夠構建出非常強大的預測模型。由於是<span class="term-zh">循序</span>構建，<span class="term-en-abbr">GBDT</span> 通常比<span class="term-zh">隨機森林</span>更容易<span class="term-zh">過擬合</span>，需要仔細調整<span class="term-zh">超參數</span>（如樹的數量、深度、<span class="term-zh">學習率</span>）。<span class="term-en-abbr">XGBoost</span>、<span class="term-en-abbr">LightGBM</span> 和 <span class="term-en-abbr">CatBoost</span> 是 <span class="term-en-abbr">GBDT</span> 的高效實現和改進版本。</div>
                     <br>
                     <img src="image/Gradient Boosting Tree.webp" class="responsive-img">                    
                     <br>
                     <img src="image/Ensemble_Learning_Bagging_Boosting.avif" class="responsive-img">

                 </div>
            </div>

            <!-- Question 19 -->
            <div class="question-card" data-direction="1" data-stars="2">
                <div class="question-header">
                    <div class="question-id">#19</div>
                    <div class="question-frequency">★★</div>
                </div>
                <div class="question-content"><span class="term-zh">機器學習</span>中常提到的「<span class="term-zh">沒有免費的午餐定理</span>」(<span class="term-en-full">No Free Lunch Theorem</span>) 指的是什麼？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">所有<span class="term-zh">機器學習</span>模型都是免費提供的。</div>
                    </div>
                    <div class="option-item correct" data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><span class="highlight-keyword">沒有任何單一</span>的<span class="term-zh">機器學習算法</span>能在<span class="highlight-keyword">所有可能的數據集和問題</span>上都表現<span class="highlight-keyword">最佳</span>。</div>
                    </div>
                     <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text"><span class="term-zh">機器學習</span>模型不需要訓練數據。</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text"><span class="term-zh">機器學習</span>的計算成本總是為零。</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">「<span class="term-zh">沒有免費的午餐定理</span>」在優化和<span class="term-zh">機器學習</span>領域指出，如果考慮所有可能的問題（或數據生成分佈），那麼<span class="highlight-keyword">沒有任何一種特定</span>的算法能夠在<span class="highlight-keyword">平均性能上優於</span>其他所有算法。換句話說，<span class="highlight-keyword">不存在一個「萬能」</span>的、在所有情況下都表現最好的<span class="term-zh">機器學習</span>模型或算法。一個算法在某類問題上表現出色，可能在另一類問題上表現平平或很差。這強調了理解問題特性、數據分佈以及不同算法的假設、優缺點的重要性，並需要根據<span class="highlight-keyword">具體情況選擇</span>或定製合適的算法。</div>
                </div>
            </div>
            
             <!-- Question 20 -->
            <div class="question-card" data-direction="3" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#20</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">邏輯回歸</span> (<span class="term-en-full">Logistic Regression</span>) 雖然名字中帶有「回歸」，但它主要用於解決哪類問題？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">連續值預測 (<span class="term-zh">迴歸</span>)</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">類別預測</span> (<span class="term-zh">分類</span>)，特別是<span class="highlight-keyword">二元分類</span></div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">數據<span class="term-zh">分群</span> (<span class="term-zh">聚類</span>)</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">特徵<span class="term-zh">降維</span></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">儘管名稱包含「回歸」，<span class="term-zh">邏輯回歸</span>實際上是一種廣泛使用的<span class="highlight-keyword">分類</span>算法。它通過 <span class="highlight-keyword">Sigmoid 函數</span>將<span class="term-zh">線性模型</span>的輸出映射到 (0, 1) 區間，得到樣本屬於正類的<span class="highlight-keyword">機率</span>。然後可以設定一個<span class="highlight-keyword">閾值</span>（例如 0.5），將機率大於閾值的樣本預測為正類，小於閾值的預測為負類。因此，它的最終輸出是<span class="highlight-keyword">離散的類別標籤</span>，用於解決<span class="term-zh">分類</span>問題，尤其是<span class="term-zh">二元分類</span>。它也可以擴展到<span class="term-zh">多類分類</span>（例如通過 <span class="term-en-full">One-vs-Rest</span> 或 <span class="term-en-full">Softmax</span> 回歸）。</div>
                     <br>
                     <img src="image/Logistic Regression.png" class="responsive-img">
                 </div>
            </div>

             <!-- Question 21 -->
            <div class="question-card" data-direction="4" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#21</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content">在評估<span class="term-zh">分群</span> (<span class="term-en-full">Clustering</span>) 結果的品質時，如果我們<span class="highlight-keyword">沒有</span>真實的類別標籤（<span class="term-zh">非監督式</span>場景），可以使用哪類指標？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">準確率</span> (<span class="term-en-full">Accuracy</span>) 和 <span class="term-en-abbr">F1</span> 分數。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">內部指標</span> (<span class="term-en-full">Internal Indices</span>)，如<span class="highlight-keyword">輪廓係數</span> (<span class="term-en-full">Silhouette Coefficient</span>) 或 <span class="term-en-abbr">Calinski-Harabasz</span> 指數。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">均方誤差</span> (<span class="term-en-full">Mean Squared Error</span>, <span class="term-en-abbr">MSE</span>)。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-en-abbr">ROC</span> 曲線下面積 (<span class="term-en-abbr">AUC</span>)。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">由於<span class="term-zh">分群</span>是<span class="term-zh">非監督式學習</span>，通常沒有「正確答案」（真實標籤）來直接比較。因此，評估<span class="term-zh">分群</span>結果需要使用不同的指標：
                     <ul>
                         <li><span class="highlight-keyword">內部指標 (<span class="term-en-full">Internal Indices</span>)</span>：<span class="highlight-keyword">僅基於分群結果本身的數據</span>（不需要外部標籤）來評估群集的品質。它們通常衡量群集內部的<span class="highlight-keyword">緊密度</span> (<span class="term-en-full">Intra-cluster Cohesion</span>) 和群集之間的<span class="highlight-keyword">分離度</span> (<span class="term-en-full">Inter-cluster Separation</span>)。例如：
                             <ul>
                                 <li><span class="highlight-keyword">輪廓係數 (<span class="term-en-full">Silhouette Coefficient</span>)</span>：衡量每個樣本與其自身群集的緊密度以及與最近的其他群集的分離度。值域 [-1, 1]，越接近 1 越好。</li>
                                 <li><span class="highlight-keyword">Calinski-Harabasz (<span class="term-en-abbr">CH</span>) 指數</span>：計算類間散度與類內散度之比，值越大越好。</li>
                                 <li><span class="highlight-keyword">Davies-Bouldin (<span class="term-en-abbr">DB</span>) 指數</span>：計算任意兩個類別內樣本平均距離之和除以類別中心點距離，值越小越好。</li>
                             </ul>
                         </li>
                         <li><span class="highlight-keyword">外部指標 (<span class="term-en-full">External Indices</span>)</span>：如果存在真實的類別標籤（例如，作為評估基準），則可以使用外部指標來比較<span class="term-zh">分群</span>結果與真實類別的一致性。例如：<span class="term-zh">調整後蘭德指數</span> (<span class="term-en-full">Adjusted Rand Index</span>, <span class="term-en-abbr">ARI</span>)、<span class="term-zh">調整後互信息</span> (<span class="term-en-full">Adjusted Mutual Information</span>, <span class="term-en-abbr">AMI</span>)、同質性 (<span class="term-en-full">Homogeneity</span>)、完整性 (<span class="term-en-full">Completeness</span>)、<span class="term-en-abbr">V-measure</span> 等。</li>
                     </ul>
                      <span class="term-zh">準確率</span>、<span class="term-en-abbr">F1</span>、<span class="term-en-abbr">MSE</span>、<span class="term-en-abbr">AUC</span> 都是<span class="term-zh">監督式學習</span>的評估指標。</div>
                 </div>
            </div>

             <!-- Question 22 -->
             <div class="question-card" data-direction="5" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#22</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">線性判別分析</span> (<span class="term-en-full">Linear Discriminant Analysis</span>, <span class="term-en-abbr">LDA</span>) 除了用於分類，也常被用作一種什麼技術？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">數據增強</span> (<span class="term-en-full">Data Augmentation</span>)</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">有監督的降維</span> (<span class="term-en-full">Supervised Dimensionality Reduction</span>)</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">異常檢測 (<span class="term-en-full">Anomaly Detection</span>)</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">模型解釋 (<span class="term-en-full">Model Interpretation</span>)</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-en-abbr">LDA</span> 的主要目標是找到一個低維投影空間，使得投影後不同類別的數據能夠<span class="highlight-keyword">最大程度地分開</span>（最大化<span class="highlight-keyword">類間散度</span>/類內散度比）。因此，<span class="term-en-abbr">LDA</span> 不僅可以直接用於分類（例如，將樣本投影到低維空間後，根據其位置判斷類別），也常被用作一種<span class="highlight-keyword">有監督的降維</span>技術。與<span class="highlight-keyword">無監督</span>的 <span class="term-en-abbr">PCA</span> 不同，<span class="term-en-abbr">LDA</span> 在<span class="term-zh">降維</span>過程中利用了<span class="highlight-keyword">類別標籤信息</span>，旨在找到最有利於<span class="highlight-keyword">區分類別</span>的低維表示。<span class="term-zh">降維</span>後的維度最多為 C-1（其中 C 是類別數量）或原始特徵維度（取較小者）。</div>
                     <br>
                     <img src="image/LDA.png" class="responsive-img">
                 </div>
            </div>

             <!-- Question 23 -->
            <div class="question-card" data-direction="6" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#23</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content">在進行模型選擇或<span class="term-zh">超參數調優</span>時，<span class="term-zh">網格搜索</span> (<span class="term-en-full">Grid Search</span>) 和<span class="term-zh">隨機搜索</span> (<span class="term-en-full">Random Search</span>) 是常用的方法。<span class="term-zh">隨機搜索</span>相比<span class="term-zh">網格搜索</span>的主要優勢通常是什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">保證能找到全局最優的<span class="term-zh">超參數</span>組合。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">在相同的計算預算（例如，嘗試相同次數的組合）下，<span class="term-zh">隨機搜索</span>通常能<span class="highlight-keyword">更有效地探索</span><span class="term-zh">超參數</span>空間，尤其當只有少數幾個<span class="term-zh">超參數</span>對性能影響較大時。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">實現起來比<span class="term-zh">網格搜索</span>簡單得多。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">每次搜索都使用不同的模型架構。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">網格搜索</span>會窮舉所有預定義的<span class="term-zh">超參數</span>組合，如果某些<span class="term-zh">超參數</span>對模型性能影響不大，<span class="term-zh">網格搜索</span>會在這些不重要的維度上浪費大量計算資源。而<span class="term-zh">隨機搜索</span>則是在預定義的範圍內<span class="highlight-keyword">隨機抽取</span><span class="term-zh">超參數</span>組合進行嘗試。研究和實踐表明，對於許多<span class="term-zh">機器學習</span>問題，模型性能通常只對<span class="highlight-keyword">少數幾個超參數比較敏感</span>。<span class="term-zh">隨機搜索</span>更有可能在這些<span class="highlight-keyword">重要的超參數</span>維度上採樣到更多不同的值，因此在相同的嘗試次數下，往往比<span class="term-zh">網格搜索</span>更容易找到接近最優的組合。雖然兩者都不保證找到全局最優解，但<span class="term-zh">隨機搜索</span>通常在<span class="highlight-keyword">計算效率</span>上更優。</div>
                 </div>
            </div>

             <!-- Question 24 -->
             <div class="question-card" data-direction="7" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#24</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">特徵哈希</span> (<span class="term-en-full">Feature Hashing</span>) 或稱<span class="term-zh">哈希技巧</span> (<span class="term-en-full">Hashing Trick</span>) 是一種處理<span class="term-zh">高維度稀疏特徵</span>（特別是<span class="term-zh">類別特徵</span>）的方法，其主要優點是？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">能夠保留所有原始特徵信息。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">可以將任意數量的原始特徵映射到一個<span class="highlight-keyword">固定大小的低維向量</span>空間，<span class="highlight-keyword">無需維護詞彙表</span>，<span class="highlight-keyword">節省內存</span>，並方便<span class="highlight-keyword">在線學習</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">保證不會發生<span class="term-zh">哈希碰撞</span> (<span class="term-en-full">Hash Collision</span>)。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">能夠自動選擇最重要的特徵。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">當處理具有極高基數 (<span class="term-en-full">Cardinality</span>) 的<span class="term-zh">類別特徵</span>時（例如，用戶ID、詞語），使用<span class="term-zh">獨熱編碼</span>會產生非常<span class="term-zh">高維</span>且<span class="term-zh">稀疏</span>的向量，佔用大量內存。<span class="highlight-keyword">特徵哈希</span>提供了一種替代方法：它使用一個<span class="highlight-keyword">哈希函數</span> (<span class="term-en-full">Hash Function</span>) 將原始的特徵（如詞語字符串）直接映射到一個<span class="highlight-keyword">固定長度</span>的向量的某個索引位置（通常是從 0 到 N-1，N 是預設的哈希空間大小）。然後可以在這個位置上記錄特徵的計數或 <span class="term-en-abbr">TF-IDF</span> 值等。這樣，無論原始特徵空間有多大，最終的特徵向量維度都是固定的 N。優點是<span class="highlight-keyword">無需構建和存儲龐大的詞彙表</span>，<span class="highlight-keyword">內存效率高</span>，且容易處理新出現的未知特徵（直接哈希即可），適合流式數據或<span class="highlight-keyword">在線學習</span>。缺點是可能發生<span class="highlight-keyword">哈希碰撞</span>，即不同的原始特徵被映射到同一個索引位置，可能損失一部分信息，但如果 N 設置得足夠大，碰撞的影響通常可以接受。</div>
                     <br>
                     <img src="image/Feature Hashing.png" class="responsive-img">
                 </div>
            </div>
            
            <!-- Question 25 -->
            <div class="question-card" data-direction="8" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#25</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-en-abbr">AdaBoost</span> (<span class="term-en-full">Adaptive Boosting</span>) 算法在訓練過程中會如何調整樣本的權重？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">所有樣本的權重始終保持相等。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">提高</span>那些被前一個<span class="term-zh">弱學習器錯誤分類</span>的樣本的<span class="highlight-keyword">權重</span>，<span class="highlight-keyword">降低</span>被<span class="highlight-keyword">正確分類</span>樣本的<span class="highlight-keyword">權重</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">隨機調整樣本權重。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">只保留被錯誤分類的樣本。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-en-abbr">AdaBoost</span> 是 <span class="term-zh">Boosting</span> <span class="term-zh">系集學習</span>算法的代表之一。它<span class="highlight-keyword">循序</span>地訓練一系列<span class="term-zh">弱學習器</span>（通常是<span class="term-zh">決策樁</span> <span class="term-en-full">Decision Stumps</span> 或淺層<span class="term-zh">決策樹</span>）。在每一輪迭代中，<span class="term-en-abbr">AdaBoost</span> 會根據前一輪學習器的表現來<span class="highlight-keyword">更新訓練樣本的權重</span>分佈。那些被前一個<span class="term-zh">弱學習器</span><span class="highlight-keyword">錯誤分類</span>的樣本，在下一輪訓練中會獲得<span class="highlight-keyword">更高的權重</span>，使得下一個<span class="term-zh">弱學習器</span>更加關注這些「<span class="highlight-keyword">難分</span>」的樣本。而被<span class="highlight-keyword">正確分類</span>的樣本權重則會<span class="highlight-keyword">降低</span>。最終的模型是所有<span class="term-zh">弱學習器</span>的<span class="highlight-keyword">加權組合</span>，其中表現較好（錯誤率較低）的<span class="term-zh">弱學習器</span>會獲得更高的權重。這種機制使得 <span class="term-en-abbr">AdaBoost</span> 能夠逐步聚焦於困難樣本，構建出強大的分類器。</div>
                     <br>
                     <img src="image/AdaBoost.png" class="responsive-img">
                 </div>
            </div>
            
             <!-- Question 26 -->
            <div class="question-card" data-direction="1" data-stars="1">
                <div class="question-header">
                    <div class="question-id">#26</div>
                    <div class="question-frequency">★</div>
                </div>
                <div class="question-content"><span class="term-zh">機器學習</span>模型訓練的最終目標是？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">在<span class="term-zh">訓練集</span>上達到 100% 的<span class="term-zh">準確率</span>。</div>
                    </div>
                    <div class="option-item correct" data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text">獲得一個能夠很好地<span class="highlight-keyword">泛化</span> (<span class="term-en-full">Generalize</span>) 到<span class="highlight-keyword">未見過的新數據</span>的模型。</div>
                    </div>
                    <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text">使用盡可能多的模型參數。</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">使模型盡可能複雜。</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">雖然我們希望模型在<span class="term-zh">訓練集</span>上表現良好，但<span class="term-zh">機器學習</span>的真正目標是讓模型在遇到<span class="highlight-keyword">新的、從未見過</span>的數據時也能做出準確的預測或判斷。這種能力被稱為模型的<span class="highlight-keyword">泛化能力</span>。僅僅在<span class="term-zh">訓練集</span>上達到高精度（甚至100%）可能意味著模型發生了<span class="highlight-keyword">過擬合</span>，它只是「死記硬背」了訓練數據，而沒有學到潛在的規律。因此，評估和優化模型的<span class="term-zh">泛化能力</span>（通常通過<span class="term-zh">驗證集</span>和<span class="term-zh">測試集</span>來衡量）才是模型訓練的最終目標。</div>
                </div>
            </div>

             <!-- Question 27 -->
            <div class="question-card" data-direction="2" data-stars="2">
                <div class="question-header">
                    <div class="question-id">#27</div>
                    <div class="question-frequency">★★</div>
                </div>
                <div class="question-content">簡單<span class="term-zh">線性回歸</span>假設<span class="term-zh">自變數</span> X 和<span class="term-zh">應變數</span> Y 之間存在什麼樣的關係？</div>
                <div class="options-container">
                    <div class="option-item correct" data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text"><span class="highlight-keyword">線性關係</span> (<span class="term-en-full">Linear Relationship</span>)</div>
                    </div>
                    <div class="option-item " data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text">指數關係 (<span class="term-en-full">Exponential Relationship</span>)</div>
                    </div>
                    <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text">對數關係 (<span class="term-en-full">Logarithmic Relationship</span>)</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">任何非線性關係</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">簡單<span class="term-zh">線性回歸</span>模型的基本形式是 <span class="highlight-keyword">y = β₀ + β₁x + ε</span>。這個模型<span class="highlight-keyword">假設</span><span class="term-zh">應變數</span> y 的期望值 E[y] 與<span class="term-zh">自變數</span> x 之間存在<span class="highlight-keyword">直線關係</span>，即 E[y] = β₀ + β₁x。如果數據點大致散佈在一條直線周圍，則<span class="term-zh">線性回歸</span>是一個合適的模型。如果關係明顯是<span class="term-zh">非線性</span>的，則可能需要使用<span class="term-zh">多項式迴歸</span>、<span class="term-zh">非線性迴歸</span>或更複雜的模型。</div>
                    <br>
                    <img src="image/Linear Regression.jpg" class="responsive-img">
                </div>
            </div>

             <!-- Question 28 -->
             <div class="question-card" data-direction="3" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#28</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">K-近鄰</span> (<span class="term-en-full">K-Nearest Neighbors</span>, <span class="term-en-abbr">KNN</span>) <span class="term-zh">分類</span>算法是如何預測一個新樣本的類別的？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">計算新樣本到所有訓練樣本的平均距離。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">找到訓練集中與新樣本<span class="highlight-keyword">距離最近的 K 個鄰居</span>，然後根據這 K 個鄰居中<span class="highlight-keyword">最多的類別</span>（<span class="highlight-keyword">多數投票</span>）來決定新樣本的類別。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">構建一棵<span class="term-zh">決策樹</span>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">計算新樣本屬於每個類別的機率。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-en-abbr">KNN</span> 是一種<span class="highlight-keyword">基於實例的學習</span> (<span class="term-en-full">Instance-based Learning</span>) 或<span class="highlight-keyword">惰性學習</span> (<span class="term-en-full">Lazy Learning</span>) 算法。它不做顯式的模型訓練，而是直接利用訓練數據進行預測。對於一個新的、未標註的樣本點，<span class="term-en-abbr">KNN</span> 的預測步驟如下：
                     <ol>
                         <li>計算新樣本與訓練集中所有樣本之間的<span class="highlight-keyword">距離</span>（常用<span class="term-zh">歐幾里得距離</span>）。</li>
                         <li>找出<span class="highlight-keyword">距離最小</span>（即最相似）的 <span class="highlight-keyword">K 個訓練樣本</span>（稱為 K 個最近鄰）。K 是一個需要用戶指定的<span class="term-zh">超參數</span>。</li>
                         <li>對於<span class="term-zh">分類</span>問題，查看這 K 個鄰居的類別標籤，採用<span class="highlight-keyword">多數投票</span> (<span class="term-en-full">Majority Voting</span>) 的方式，將出現次數最多的那個類別賦予新樣本。</li>
                         <li>對於<span class="term-zh">迴歸</span>問題，通常是計算這 K 個鄰居目標值的平均值或加權平均值作為新樣本的預測值。</li>
                     </ol>
                     <span class="term-en-abbr">KNN</span> 的優點是簡單直觀，對數據分佈沒有假設；缺點是計算成本高（需要計算與所有訓練樣本的距離），對 K 值和距離度量敏感，且在<span class="term-zh">高維空間</span>中表現可能不佳（<span class="term-zh">維度災難</span>）。</div>
                     <br>
                     <img src="image/KNN.webp" class="responsive-img">
                 </div>
            </div>

            <!-- Question 29 -->
             <div class="question-card" data-direction="4" data-stars="1">
                 <div class="question-header">
                     <div class="question-id">#29</div>
                     <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">非監督式學習</span>與<span class="term-zh">監督式學習</span>最根本的區別在於訓練數據是否包含？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">特徵</span> (<span class="term-en-full">Features</span>)</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">標籤</span> (<span class="term-en-full">Labels</span>) 或<span class="highlight-keyword">目標輸出</span></div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">數值數據</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">類別數據</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">監督式學習</span>需要使用帶有「正確答案」（即<span class="highlight-keyword">標籤</span>或<span class="highlight-keyword">目標值</span>）的數據進行訓練，模型學習的是從輸入到已知輸出的映射。<span class="term-zh">非監督式學習</span>的訓練數據是<span class="highlight-keyword">沒有標籤</span>的，算法需要<span class="highlight-keyword">自行從數據中發現</span>潛在的結構、模式或關係，例如將相似的數據點歸為一類（<span class="term-zh">分群</span>），或者找到數據的主要變化方向以降低維度（<span class="term-zh">降維</span>）。</div>
                     <br>
                     <img src="image/Supervised_and_unsupervised_learning.png" class="responsive-img">
                 </div>
            </div>

            <!-- Question 30 -->
            <div class="question-card" data-direction="5" data-stars="1">
                <div class="question-header">
                    <div class="question-id">#30</div>
                    <div class="question-frequency">★</div>
                </div>
                <div class="question-content">下列哪項是<span class="term-zh">降維</span> (<span class="term-en-full">Dimensionality Reduction</span>) 技術的潛在好處？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">增加模型的解釋難度。</div>
                    </div>
                    <div class="option-item correct" data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><span class="highlight-keyword">降低計算複雜度</span>和<span class="highlight-keyword">儲存需求</span>，可能提高模型性能（通過去噪或去除冗餘），方便<span class="highlight-keyword">數據視覺化</span>。</div>
                    </div>
                    <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text">使得模型只能處理低維數據。</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">保證找到數據中的所有模式。</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">如第 #5 和 #39 題所述，<span class="term-zh">降維</span>的主要好處包括：(1) 克服<span class="term-zh">維度災難</span>；(2) 降低後續模型訓練和預測的<span class="highlight-keyword">計算複雜度</span>；(3) 減少數據<span class="highlight-keyword">儲存空間</span>；(4) 可能通過去除噪聲或冗餘信息來提高模型的<span class="highlight-keyword">泛化性能</span>；(5) 將數據降至 2 維或 3 維以便進行<span class="highlight-keyword">視覺化</span>探索。當然，<span class="term-zh">降維</span>也可能損失一部分信息，需要在維度降低程度和信息保留之間進行權衡。選項 A 可能對，但不是好處。</div>
                </div>
            </div>
            
            <!-- Question 31 -->
             <div class="question-card" data-direction="6" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#31</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-en-abbr">F1</span> 分數 (<span class="term-en-full">F1 Score</span>) 是綜合考慮了哪兩個<span class="term-zh">分類</span>評估指標的<span class="term-zh">調和平均數</span>？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">準確率</span> (<span class="term-en-full">Accuracy</span>) 和 <span class="term-zh">召回率</span> (<span class="term-en-full">Recall</span>)</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">精確率</span> (<span class="term-en-full">Precision</span>) 和 <span class="highlight-keyword">召回率</span> (<span class="term-en-full">Recall</span>)</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">精確率</span> (<span class="term-en-full">Precision</span>) 和 <span class="term-zh">特異度</span> (<span class="term-en-full">Specificity</span>)</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">召回率</span> (<span class="term-en-full">Recall</span>) 和 <span class="term-zh">假正率</span> (<span class="term-en-full">False Positive Rate</span>)</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-en-abbr">F1</span> 分數是<span class="highlight-keyword">精確率</span> (<span class="term-en-full">Precision</span>) 和<span class="highlight-keyword">召回率</span> (<span class="term-en-full">Recall</span>) 的<span class="highlight-keyword">調和平均數</span> (<span class="term-en-full">Harmonic Mean</span>)，計算公式為 <span class="highlight-keyword">F1 = 2 * (Precision * Recall) / (Precision + Recall)</span>。它試圖在<span class="term-zh">精確率</span>和<span class="term-zh">召回率</span>之間取得平衡。當兩者都很重要，或者當數據存在<span class="term-zh">類別不平衡</span>時，<span class="term-en-abbr">F1</span> 分數通常被認為是比<span class="term-zh">準確率</span>更合適的評估指標。<span class="term-en-abbr">F1</span> 分數的取值範圍也是 [0, 1]，值越接近 1 表示性能越好。</div>
                     <br>
                     <img src="image/Confusion-matrix-Precision-Recall-Accuracy-and-F1-score.png" class="responsive-img">
                 </div>
            </div>

             <!-- Question 32 -->
             <div class="question-card" data-direction="7" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#32</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content">對於包含文本數據的特徵，在將其輸入<span class="term-zh">機器學習</span>模型前，通常需要將文本轉換為數值表示。下列哪項「<span class="highlight-keyword">不</span>」是常用的文本數值化方法？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">詞袋模型</span> (<span class="term-en-full">Bag-of-Words</span>, <span class="term-en-abbr">BoW</span>)</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text"><span class="term-en-abbr">TF-IDF</span> (<span class="term-en-full">Term Frequency-Inverse Document Frequency</span>)</div></div>
                     <div class="option-item correct" data-option="C"><div class="option-label">C</div><div class="option-text"><span class="highlight-keyword">主成分分析</span> (<span class="term-en-abbr">PCA</span>)</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">詞嵌入</span> (<span class="term-en-full">Word Embeddings</span>)，如 <span class="term-en-abbr">Word2Vec</span>, <span class="term-en-abbr">GloVe</span>, <span class="term-en-abbr">FastText</span></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">將文本轉換為機器可處理的數值形式是<span class="term-zh">自然語言處理</span> (<span class="term-en-abbr">NLP</span>) 的基礎步驟。常用方法包括：
                     <ul>
                         <li><span class="highlight-keyword">詞袋模型 (<span class="term-en-abbr">BoW</span>)</span>：忽略詞序和語法，將文檔表示為一個向量，向量的每個維度對應詞彙表中的一個詞，值通常是該詞在文檔中出現的次數（<span class="term-zh">詞頻</span>）。</li>
                         <li><span class="highlight-keyword"><span class="term-en-abbr">TF-IDF</span></span>：對 <span class="term-en-abbr">BoW</span> 的改進，不僅考慮<span class="term-zh">詞頻</span> (<span class="term-en-abbr">TF</span>)，還考慮該詞在整個文檔集合中的<span class="term-zh">逆文檔頻率</span> (<span class="term-en-abbr">IDF</span>)，以降低常見詞的權重，突出具有區分性的詞語。</li>
                         <li><span class="highlight-keyword">詞嵌入 (<span class="term-en-full">Word Embeddings</span>)</span>：將每個詞語映射到一個低維（通常幾十到幾百維）的<span class="highlight-keyword">稠密實數向量</span>，使得語義相似的詞語在向量空間中距離更近。如 <span class="term-en-abbr">Word2Vec</span>, <span class="term-en-abbr">GloVe</span>, <span class="term-en-abbr">FastText</span> 等。近年來，基於 <span class="term-zh">Transformer</span> 的模型（如 <span class="term-en-abbr">BERT</span>）產生的上下文相關<span class="term-zh">詞嵌入</span>效果更好。</li>
                     </ul>
                     <span class="highlight-keyword">主成分分析 (<span class="term-en-abbr">PCA</span>)</span> 是一種<span class="term-zh">降維</span>技術，通常應用於已經是數值型的特徵，<span class="highlight-keyword">而不是直接用於將文本轉換為數值表示</span>的方法（儘管它可以應用於 <span class="term-en-abbr">BoW</span> 或 <span class="term-en-abbr">TF-IDF</span> 之後的降維）。</div>
                     <br>
                     <img src="image/PCA.jpg" class="responsive-img">
                 </div>
            </div>

             <!-- Question 33 -->
             <div class="question-card" data-direction="8" data-stars="4">
                 <div class="question-header">
                     <div class="question-id">#33</div>
                     <div class="question-frequency">★★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">系集學習</span> (<span class="term-en-full">Ensemble Learning</span>) 方法的基本思想是？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">只使用一個非常強大的模型。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">結合多個</span>（通常是較弱的）<span class="highlight-keyword">基學習器</span>的預測結果，以獲得比單個學習器<span class="highlight-keyword">更好、更穩健的性能</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">只使用數據集中的一小部分特徵。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">對模型參數進行隨機初始化。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">系集學習</span>的核心思想是「三個臭皮匠，勝過一個諸葛亮」。它不是依賴單一的模型來做決策，而是<span class="highlight-keyword">構建多個模型</span>（稱為<span class="term-zh">基學習器</span>或<span class="term-zh">弱學習器</span>），然後將它們的預測結果以某種方式<span class="highlight-keyword">結合起來</span>（例如，<span class="term-zh">投票</span>、<span class="term-zh">平均</span>、<span class="term-zh">加權平均</span>），形成最終的預測。如果<span class="term-zh">基學習器</span>之間具有一定的<span class="highlight-keyword">差異性</span> (<span class="term-en-full">Diversity</span>)，並且每個<span class="term-zh">基學習器</span>的性能都比隨機猜測好，那麼<span class="term-zh">系集模型</span>的性能通常會優於任何單個<span class="term-zh">基學習器</span>，並且更加穩定和魯棒。常見的<span class="term-zh">系集方法</span>包括 <span class="term-zh">Bagging</span>（如<span class="term-zh">隨機森林</span>）、<span class="term-zh">Boosting</span>（如 <span class="term-en-abbr">AdaBoost</span>, <span class="term-en-abbr">GBDT</span>）和 <span class="term-zh">Stacking</span>。</div>
                     <br>
                     <img src="image/ensemble-learning.png" class="responsive-img">
                 </div>
            </div>

             <!-- Question 34 -->
             <div class="question-card" data-direction="1" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#34</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content">在<span class="term-zh">機器學習</span>流程中，「<span class="term-zh">特徵</span>」 (<span class="term-en-full">Feature</span>) 指的是什麼？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">模型的預測結果。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">用於描述<span class="highlight-keyword">輸入數據</span>的<span class="highlight-keyword">可測量的、獨立的屬性或特性</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">訓練數據集中的樣本數量。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">模型的<span class="term-zh">超參數</span>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">特徵</span>，也稱為<span class="term-zh">屬性</span> (<span class="term-en-full">Attribute</span>)、<span class="term-zh">預測變數</span> (<span class="term-en-full">Predictor Variable</span>) 或<span class="term-zh">自變數</span> (<span class="term-en-full">Independent Variable</span>)，是從原始數據中提取出來的、用於表示每個數據樣本的<span class="highlight-keyword">可量化特性</span>。<span class="term-zh">機器學習</span>模型利用這些<span class="term-zh">特徵</span>來進行學習和預測。例如，在預測房價的任務中，房屋的大小、房間數量、位置經緯度、建造年份等都可以作為<span class="term-zh">特徵</span>。選擇和構建好的<span class="term-zh">特徵</span>（<span class="term-zh">特徵工程</span>）對於模型的性能至關重要。</div>
                 </div>
            </div>

            <!-- Question 35 -->
            <div class="question-card" data-direction="2" data-stars="1">
                <div class="question-header">
                    <div class="question-id">#35</div>
                    <div class="question-frequency">★</div>
                </div>
                <div class="question-content"><span class="term-zh">線性回歸</span>模型屬於哪種<span class="term-zh">機器學習</span>類型？</div>
                <div class="options-container">
                    <div class="option-item correct" data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text"><span class="highlight-keyword">監督式學習</span> (<span class="term-en-full">Supervised Learning</span>)</div>
                    </div>
                    <div class="option-item " data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><span class="term-zh">非監督式學習</span> (<span class="term-en-full">Unsupervised Learning</span>)</div>
                    </div>
                    <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text"><span class="term-zh">強化學習</span> (<span class="term-en-full">Reinforcement Learning</span>)</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text"><span class="term-zh">半監督式學習</span> (<span class="term-en-full">Semi-supervised Learning</span>)</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content"><span class="term-zh">線性回歸</span>模型用於預測一個<span class="highlight-keyword">連續的目標變數</span>，其訓練過程需要使用帶有<span class="highlight-keyword">已知目標值</span>的輸入數據（即<span class="highlight-keyword">帶標籤數據</span>）。模型學習輸入特徵與目標值之間的線性關係。由於它依賴於<span class="term-zh">帶標籤</span>的數據來學習映射關係，因此<span class="term-zh">線性回歸</span>屬於<span class="highlight-keyword">監督式學習</span>的範疇。</div>
                    <br>
                    <img src="image/Linear Regression.jpg" class="responsive-img">
                </div>
            </div>

             <!-- Question 36 -->
             <div class="question-card" data-direction="3" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#36</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">決策樹</span> (<span class="term-en-full">Decision Tree</span>) <span class="term-zh">分類器</span>是如何進行預測的？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">計算樣本到所有類別中心的距離。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">根據樣本的<span class="term-zh">特徵值</span>，沿著樹從<span class="highlight-keyword">根節點走到某個葉節點</span>，該<span class="term-zh">葉節點</span>代表的類別（通常是該<span class="term-zh">葉節點</span>中樣本最多的類別）即為預測結果。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">找到 K 個最近鄰居並投票。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">應用 <span class="term-en-full">Sigmoid</span> 函數計算機率。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">決策樹</span>是一種<span class="highlight-keyword">樹狀結構</span>的模型，其中每個<span class="highlight-keyword">內部節點</span>代表對一個<span class="term-zh">特徵</span>的測試（例如，「年齡 < 30?」），每個<span class="highlight-keyword">分支</span>代表測試的一個結果（例如，「是」或「否」），每個<span class="highlight-keyword">葉節點</span>代表一個<span class="highlight-keyword">類別標籤</span>（對於<span class="term-zh">分類樹</span>）或一個預測值（對於<span class="term-zh">迴歸樹</span>）。要對一個新樣本進行預測，我們從<span class="term-zh">根節點</span>開始，根據樣本的<span class="term-zh">特徵值</span>執行節點上的測試，然後沿著對應的分支向下走，重複這個過程直到到達一個<span class="term-zh">葉節點</span>。該<span class="term-zh">葉節點</span>所代表的類別或值就是模型的預測結果。</div>
                     <br>
                     <img src="image/Decision-Tree.webp" class="responsive-img">
                 </div>
            </div>

             <!-- Question 37 -->
            <div class="question-card" data-direction="4" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#37</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><span class="term-en-abbr">DBSCAN</span> (<span class="term-en-full">Density-Based Spatial Clustering of Applications with Noise</span>) 是一種<span class="highlight-keyword">基於密度</span>的<span class="term-zh">分群</span>算法，它與 <span class="term-en-abbr">K-means</span> 的主要不同之處在於？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-en-abbr">DBSCAN</span> 需要預先指定群數 K。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="term-en-abbr">DBSCAN</span> 可以發現<span class="highlight-keyword">任意形狀</span>的群集，並且能夠<span class="highlight-keyword">識別出噪聲點</span>（<span class="term-zh">離群值</span>），而<span class="highlight-keyword">不需要預先指定群數</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-en-abbr">DBSCAN</span> 只能處理二維數據。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-en-abbr">DBSCAN</span> 的結果總是一個<span class="term-zh">樹狀圖</span>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-en-abbr">DBSCAN</span> 與 <span class="term-en-abbr">K-means</span> 不同，它基於<span class="highlight-keyword">密度</span>的概念來定義群集：群集被定義為由高密度區域分隔開的連續區域。它有兩個關鍵參數：鄰域半徑 <span class="highlight-keyword">ε</span> (<span class="term-en-full">eps</span>) 和形成<span class="highlight-keyword">核心點</span>所需的最小鄰居數 <span class="highlight-keyword">MinPts</span>。算法從任意點開始，如果該點在其 ε 鄰域內有至少 <span class="term-en-abbr">MinPts</span> 個鄰居，則它是一個<span class="term-zh">核心點</span>，並開始擴展一個群集；如果一個點不是<span class="term-zh">核心點</span>但位於某個<span class="term-zh">核心點</span>的鄰域內，則它是<span class="term-zh">邊界點</span>；如果既不是<span class="term-zh">核心點</span>也不是<span class="term-zh">邊界點</span>，則它是<span class="highlight-keyword">噪聲點</span>。<span class="term-en-abbr">DBSCAN</span> 的優點包括：(1) <span class="highlight-keyword">不需要預先指定群集數量 K</span>。(2) 能夠發現<span class="highlight-keyword">任意形狀</span>（非球形）的群集。(3) 對<span class="highlight-keyword">噪聲點不敏感</span>，可以將其識別出來。缺點是對參數 ε 和 <span class="term-en-abbr">MinPts</span> 的選擇比較敏感，且對於密度變化較大的數據集可能效果不佳。</div>
                     <br>
                     <img src="image/DBSCAN.png" class="responsive-img">
                 </div>
            </div>

            <!-- Question 38 -->
            <div class="question-card" data-direction="6" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#38</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">均方誤差</span> (<span class="term-en-full">Mean Squared Error</span>, <span class="term-en-abbr">MSE</span>) 是評估哪類<span class="term-zh">機器學習</span>模型性能的常用指標？</div>
                 <div class="options-container">
                     <div class="option-item correct" data-option="A"><div class="option-label">A</div><div class="option-text"><span class="highlight-keyword">迴歸模型</span> (<span class="term-en-full">Regression Models</span>)</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text"><span class="term-zh">分類模型</span> (<span class="term-en-full">Classification Models</span>)</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">分群模型</span> (<span class="term-en-full">Clustering Models</span>)</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">降維模型</span> (<span class="term-en-full">Dimensionality Reduction Models</span>)</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">均方誤差</span> (<span class="term-en-abbr">MSE</span>) 計算的是模型預測值與實際目標值之間差值的<span class="highlight-keyword">平方的平均值</span>。公式為 <span class="highlight-keyword">MSE = (1/N) * Σ (yᵢ - ŷᵢ)²</span>，其中 N 是樣本數量，yᵢ 是第 i 個樣本的真實值，ŷᵢ 是模型對第 i 個樣本的預測值。由於它衡量的是預測值與<span class="highlight-keyword">連續真實值</span>之間的平均平方差異，因此 <span class="term-en-abbr">MSE</span> 是評估<span class="highlight-keyword">迴歸模型</span>性能的標準指標之一。<span class="term-en-abbr">MSE</span> 越小，表示模型的預測越接近真實值。其他常用的<span class="term-zh">迴歸</span>指標還包括<span class="term-zh">平均絕對誤差</span> (<span class="term-en-abbr">MAE</span>)、<span class="term-zh">均方根誤差</span> (<span class="term-en-abbr">RMSE</span>) 和 <span class="term-zh">R 平方</span>等。<span class="term-zh">分類模型</span>通常使用<span class="term-zh">準確率</span>、<span class="term-zh">精確率</span>、<span class="term-zh">召回率</span>、<span class="term-en-abbr">F1</span> 分數、<span class="term-en-abbr">AUC</span> 等指標。</div>
                     <br>
                     <img src="image/MSE.jpeg" class="responsive-img">
                 </div>
            </div>

             <!-- Question 39 -->
             <div class="question-card" data-direction="7" data-stars="1">
                 <div class="question-header">
                     <div class="question-id">#39</div>
                     <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content">為什麼在將原始數據輸入<span class="term-zh">機器學習</span>模型前，通常需要進行<span class="term-zh">資料預處理</span> (<span class="term-en-full">Data Preprocessing</span>)？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">為了增加數據的噪聲。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">因為真實世界的數據往往是<span class="highlight-keyword">不完整</span>（<span class="term-zh">缺失值</span>）、<span class="highlight-keyword">不一致</span>、包含<span class="highlight-keyword">噪聲</span>或<span class="highlight-keyword">格式不適合</span>模型直接使用，預處理有助於提高<span class="highlight-keyword">數據品質</span>和模型性能。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">為了減少數據集中的樣本數量。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">因為模型只能處理文字數據。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">原始的真實世界數據通常是「骯髒」的，直接用於訓練模型效果往往不佳。<span class="highlight-keyword">資料預處理</span>是<span class="term-zh">機器學習</span>流程中非常關鍵的一步，旨在將原始數據轉換為更適合模型學習的格式。常見的預處理任務包括：
                     <ul>
                         <li><span class="highlight-keyword">數據清洗 (<span class="term-en-full">Data Cleaning</span>)</span>：處理<span class="term-zh">缺失值</span>、處理<span class="term-zh">異常值</span> (<span class="term-zh">離群值</span>)、修正不一致的數據等。</li>
                         <li><span class="highlight-keyword">數據轉換 (<span class="term-en-full">Data Transformation</span>)</span>：<span class="term-zh">特徵縮放</span> (<span class="term-zh">標準化</span>、<span class="term-zh">歸一化</span>)、<span class="term-zh">類別特徵編碼</span> (<span class="term-zh">獨熱編碼</span>、<span class="term-zh">標籤編碼</span>)、數據變換（如<span class="term-zh">對數變換</span>）等。</li>
                         <li><span class="highlight-keyword">數據歸約 (<span class="term-en-full">Data Reduction</span>)</span>：<span class="term-zh">降維</span> (<span class="term-en-abbr">PCA</span>、<span class="term-en-abbr">LDA</span>)、<span class="term-zh">特徵選擇</span>等。</li>
                     </ul>
                     通過有效的預處理，可以顯著提高<span class="highlight-keyword">數據品質</span>，從而提升模型的<span class="term-zh">準確性</span>、穩定性和<span class="term-zh">泛化能力</span>。</div>
                     <br>
                     <img src="image/data-preprocessing.webp" class="responsive-img">
                 </div>
            </div>

            <!-- Question 40 -->
            <div class="question-card" data-direction="8" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#40</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">Stacking</span> (<span class="term-zh">堆疊泛化</span>) 是一種<span class="term-zh">系集學習</span>方法，它的基本流程是？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">訓練多個相同的模型並對結果進行平均。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">訓練多個不同的<span class="highlight-keyword">基學習器</span>（第一層），然後將它們的<span class="highlight-keyword">預測結果作為新的特徵</span>，再訓練一個<span class="highlight-keyword">元學習器</span> (<span class="term-en-full">Meta-learner</span>，第二層）來做出最終預測。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">循序訓練模型，每個模型修正前一個模型的錯誤。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">只選擇性能最好的那個<span class="term-zh">基學習器</span>。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">Stacking</span> 是一種較為複雜但可能獲得更高性能的<span class="term-zh">系集方法</span>。它包含<span class="highlight-keyword">兩個層級</span>的學習器：
                     <ol>
                         <li><span class="highlight-keyword">第一層 (Level 0)</span>：訓練多個不同的<span class="highlight-keyword">基學習器</span>（例如，<span class="term-zh">邏輯回歸</span>、<span class="term-en-abbr">SVM</span>、<span class="term-zh">隨機森林</span>、<span class="term-en-abbr">KNN</span> 等）在原始訓練數據上。為了避免<span class="term-zh">過擬合</span>，通常使用<span class="term-zh">交叉驗證</span>的方式來生成<span class="term-zh">基學習器</span>對訓練數據的「<span class="highlight-keyword">樣本外</span>」 (<span class="term-en-full">Out-of-Fold</span>) 預測。</li>
                         <li><span class="highlight-keyword">第二層 (Level 1)</span>：將第一層所有<span class="term-zh">基學習器</span>生成的（樣本外）<span class="highlight-keyword">預測結果作為新的特徵</span>，連同原始的目標標籤一起，用來訓練一個「<span class="highlight-keyword">元學習器</span>」 (<span class="term-en-full">Meta-learner</span>，例如<span class="term-zh">邏輯回歸</span>、<span class="term-zh">神經網路</span>等）。<span class="term-zh">元學習器</span>的任務是學習如何最好地<span class="highlight-keyword">結合</span>第一層<span class="term-zh">基學習器</span>的預測。</li>
                     </ol>
                     當有新的測試樣本需要預測時，先將其輸入到所有第一層的<span class="term-zh">基學習器</span>中得到預測，然後將這些預測作為輸入傳遞給第二層的<span class="term-zh">元學習器</span>，由<span class="term-zh">元學習器</span>做出最終的預測。<span class="term-zh">Stacking</span> 試圖學習如何智能地組合不同模型的優勢。</div>
                     <br>
                     <img src="image/stacking.png" class="responsive-img">
                 </div>
            </div>

             <!-- Question 41 -->
             <div class="question-card" data-direction="1" data-stars="1">
                 <div class="question-header">
                     <div class="question-id">#41</div>
                     <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">機器學習</span>模型通常從什麼中學習模式和規律？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">程式碼註解</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">數據</span> (<span class="term-en-full">Data</span>)</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">用戶介面設計</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">硬體規格</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">機器學習</span>的核心是讓計算機系統能夠從<span class="highlight-keyword">數據</span>中自動<span class="highlight-keyword">學習</span>和改進，而不需要進行明確的編程。<span class="highlight-keyword">數據</span>是<span class="term-zh">機器學習</span>模型的「養分」，模型通過分析大量的數據樣本來識別其中存在的模式、趨勢和關聯性，並將這些學習到的知識用於對新的、未見過的數據進行預測或決策。<span class="highlight-keyword">數據的品質和數量</span>直接影響模型的學習效果。</div>
                 </div>
            </div>
            
            <!-- Question 42 -->
            <div class="question-card" data-direction="2" data-stars="3">
                <div class="question-header">
                    <div class="question-id">#42</div>
                    <div class="question-frequency">★★★</div>
                </div>
                <div class="question-content"><span class="term-zh">多項式回歸</span> (<span class="term-en-full">Polynomial Regression</span>) 是<span class="term-zh">線性回歸</span>的一種擴展，它允許模型擬合什麼樣的數據關係？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">嚴格的線性關係。</div>
                    </div>
                    <div class="option-item correct" data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text"><span class="highlight-keyword">非線性的曲線關係</span>。</div>
                    </div>
                    <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text">類別關係。</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">時間序列關係。</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">標準<span class="term-zh">線性回歸</span>假設<span class="term-zh">應變數</span>和<span class="term-zh">自變數</span>之間是直線關係。然而，現實中的關係往往更複雜。<span class="highlight-keyword">多項式回歸</span>通過在原始<span class="term-zh">自變數</span> x 的基礎上，添加其<span class="highlight-keyword">高次冪</span>（如 x², x³, ...）作為新的特徵，然後對這些擴展後的特徵應用<span class="term-zh">線性回歸</span>模型。例如，二次<span class="term-zh">多項式回歸</span>模型為 <span class="highlight-keyword">y = β₀ + β₁x + β₂x² + ε</span>。雖然模型對於擴展後的特徵（1, x, x²）仍然是線性的，但它能夠擬合原始變數 x 和 y 之間的<span class="highlight-keyword">非線性曲線關係</span>。通過選擇合適的<span class="term-zh">多項式次數</span>，可以擬合更複雜的數據模式，但次數過高也可能導致<span class="term-zh">過擬合</span>。</div>
                    <br>
                    <img src="image/Linear-Regression-vs-Polynomial-Regression.webp" class="responsive-img">
                </div>
            </div>

            <!-- Question 43 -->
             <div class="question-card" data-direction="3" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#43</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content">哪種<span class="term-zh">分類</span>算法是基於計算樣本屬於各個類別的<span class="highlight-keyword">後驗機率</span>，並選擇<span class="term-zh">後驗機率最大</span>的那個類別作為預測結果？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">K-近鄰</span> (<span class="term-en-abbr">KNN</span>)</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">樸素貝氏分類器</span> (<span class="term-en-full">Naive Bayes Classifier</span>)</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">決策樹</span> (<span class="term-en-full">Decision Tree</span>)</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">支持向量機</span> (<span class="term-en-abbr">SVM</span>)（標準形式不直接輸出機率）</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="highlight-keyword">樸素貝氏分類器</span>直接應用<span class="highlight-keyword">貝氏定理</span>來進行分類。對於給定的輸入樣本 x（包含特徵 F1, ..., Fn），它計算該樣本屬於每個類別 C<sub>k</sub> 的<span class="highlight-keyword">後驗機率</span> P(C<sub>k</sub> | x) = P(C<sub>k</sub> | F1, ..., Fn)。根據<span class="term-zh">貝氏定理</span>，P(C<sub>k</sub> | x) ∝ P(x | C<sub>k</sub>) * P(C<sub>k</sub>) = P(F1, ..., Fn | C<sub>k</sub>) * P(C<sub>k</sub>)。利用<span class="highlight-keyword">樸素的條件獨立性假設</span>，P(F1, ..., Fn | C<sub>k</sub>) ≈ Π P(Fi | C<sub>k</sub>)。因此，算法計算每個類別的<span class="term-zh">後驗機率</span>（或其正比值），並選擇具有<span class="highlight-keyword">最大後驗機率</span>的那個類別作為最終的預測結果。這種基於<span class="term-zh">最大後驗機率</span>的決策準則被稱為<span class="highlight-keyword">貝氏最優分類器</span>（在假設準確的前提下）。<span class="term-zh">邏輯回歸</span>也輸出機率，但其模型形式不同。</div>
                     <br>
                     <img src="image/Naive Bayes.webp" class="responsive-img">
                 </div>
            </div>

            <!-- Question 44 -->
             <div class="question-card" data-direction="6" data-stars="3">
                 <div class="question-header">
                     <div class="question-id">#44</div>
                     <div class="question-frequency">★★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">混淆矩陣</span> (<span class="term-en-full">Confusion Matrix</span>) 主要用於評估哪類<span class="term-zh">機器學習</span>模型的性能？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">迴歸模型</span></div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">分類模型</span></div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">分群模型</span></div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">降維模型</span></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">混淆矩陣</span>是一個表格，用於視覺化和總結<span class="highlight-keyword">分類模型</span>的預測結果與實際類別標籤之間的關係。對於<span class="term-zh">二元分類</span>，它是一個 2x2 的矩陣，顯示了 <span class="term-en-abbr">TP</span>, <span class="term-en-abbr">FP</span>, <span class="term-en-abbr">TN</span>, <span class="term-en-abbr">FN</span> 的數量。對於<span class="term-zh">多元分類</span>，它是一個 C x C 的矩陣（C 是類別數），顯示了每個實際類別被預測為各個類別的樣本數量。<span class="term-zh">混淆矩陣</span>是計算各種<span class="highlight-keyword">分類評估指標</span>（如<span class="term-zh">準確率</span>、<span class="term-zh">精確率</span>、<span class="term-zh">召回率</span>、<span class="term-en-abbr">F1</span> 分數等）的基礎。</div>
                     <br>
                     <img src="image/confusion-matrix.png" class="responsive-img">
                 </div>
            </div>

            <!-- Question 45 -->
            <div class="question-card" data-direction="7" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#45</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">特徵選擇</span> (<span class="term-en-full">Feature Selection</span>) 的目的是從原始特徵集合中選出一個子集，這個子集應該具有什麼特性？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">包含所有可能的原始特徵。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">包含與<span class="term-zh">目標變數</span><span class="highlight-keyword">最相關</span>、<span class="highlight-keyword">冗餘度最低</span>的特徵，有助於提高模型性能、降低複雜度和提高<span class="term-zh">可解釋性</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">只包含數值型特徵。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">只包含與<span class="term-zh">目標變數</span>完全不相關的特徵。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">特徵選擇</span>是<span class="term-zh">特徵工程</span>的一部分，旨在從原始的大量特徵中挑選出一個<span class="highlight-keyword">最佳的子集</span>，用於模型訓練。理想的特徵子集應該：(1) 與<span class="term-zh">目標變數</span>（預測的輸出）<span class="highlight-keyword">高度相關</span>。(2) 特徵之間盡量<span class="highlight-keyword">相互獨立</span>，減少<span class="highlight-keyword">冗餘</span>信息。(3) <span class="highlight-keyword">數量盡可能少</span>，以降低模型複雜度。有效的<span class="term-zh">特徵選擇</span>可以帶來多種好處：<span class="highlight-keyword">簡化模型</span>、縮短訓練時間、<span class="highlight-keyword">降低過擬合風險</span>、提高模型的<span class="highlight-keyword">可解釋性</span>，有時甚至能提高預測精度（通過移除噪聲或無關特徵）。常用的<span class="term-zh">特徵選擇</span>方法包括<span class="term-zh">過濾法</span> (<span class="term-en-full">Filter Methods</span>，基於統計指標)、<span class="term-zh">包裹法</span> (<span class="term-en-full">Wrapper Methods</span>，基於模型性能評估) 和<span class="term-zh">嵌入法</span> (<span class="term-en-full">Embedded Methods</span>，模型訓練過程中自動選擇特徵，如 <span class="term-en-abbr">LASSO</span>)。</div>
                     <br>
                     <img src="image/Feature Selection.png" class="responsive-img">
                 </div>
            </div>
            
            <!-- Question 46 -->
             <div class="question-card" data-direction="8" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#46</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">自適應提升</span> (<span class="term-en-full">Adaptive Boosting</span>, <span class="term-en-abbr">AdaBoost</span>) 中的「<span class="term-zh">弱學習器</span>」(<span class="term-en-full">Weak Learner</span>) 通常指的是什麼樣的模型？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">性能非常強大、接近完美的模型。</div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text">性能僅<span class="highlight-keyword">略好於隨機猜測</span>的<span class="highlight-keyword">簡單模型</span>。</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">非監督式學習</span>模型。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">無法進行訓練的模型。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">Boosting</span> 算法的核心思想是將多個「<span class="highlight-keyword">弱</span>」學習器組合成一個「<span class="highlight-keyword">強</span>」學習器。<span class="term-zh">弱學習器</span>的定義是，其預測性能（例如，分類<span class="term-zh">準確率</span>）僅僅比<span class="highlight-keyword">隨機猜測好一點點</span>（例如，對於<span class="term-zh">二元分類</span>，<span class="term-zh">準確率</span>略高於 50%）。<span class="term-en-abbr">AdaBoost</span> 理論證明，只要<span class="term-zh">基學習器</span>是<span class="term-zh">弱學習器</span>，通過 <span class="term-zh">Boosting</span> 的方式循序訓練並加權組合，最終可以得到性能任意接近完美的強學習器（只要<span class="term-zh">弱學習器</span>足夠多）。在實踐中，<span class="term-en-abbr">AdaBoost</span> 常用的<span class="term-zh">弱學習器</span>是<span class="highlight-keyword">決策樁</span> (<span class="term-en-full">Decision Stump</span>)，即只有一個分裂節點的<span class="term-zh">決策樹</span>。</div>
                     <br>
                     <img src="image/Weak Learner.png" class="responsive-img">
                 </div>
            </div>

            <!-- Question 47 -->
             <div class="question-card" data-direction="1" data-stars="2">
                 <div class="question-header">
                     <div class="question-id">#47</div>
                     <div class="question-frequency">★★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">半監督式學習</span> (<span class="term-en-full">Semi-supervised Learning</span>) 指的是使用哪種類型的數據進行訓練？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text">完全帶<span class="term-zh">標籤</span>的數據。</div></div>
                     <div class="option-item " data-option="B"><div class="option-label">B</div><div class="option-text">完全<span class="term-zh">未標註</span>的數據。</div></div>
                     <div class="option-item correct" data-option="C"><div class="option-label">C</div><div class="option-text">包含<span class="highlight-keyword">少量帶標籤數據</span>和<span class="highlight-keyword">大量未標註數據</span>的<span class="highlight-keyword">混合數據集</span>。</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text">只包含獎勵信號的數據。</div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content">在許多實際應用中，獲取大量<span class="term-zh">帶標籤</span>的數據成本高昂，而<span class="term-zh">未標註</span>的數據則相對容易獲得。<span class="highlight-keyword">半監督式學習</span>旨在利用這種情況，<span class="highlight-keyword">結合使用少量</span>的<span class="term-zh">帶標籤數據</span>和<span class="highlight-keyword">大量</span>的<span class="term-zh">未標註數據</span>來訓練模型。其基本假設是<span class="term-zh">未標註</span>的數據中也包含了有助於學習任務（通常是分類或迴歸）的結構信息（例如，數據的分佈、聚類結構等）。通過利用<span class="term-zh">未標註</span>數據，<span class="term-zh">半監督學習</span>有望在<span class="term-zh">標籤數據有限</span>的情況下，獲得比僅使用少量<span class="term-zh">標籤數據</span>的純<span class="term-zh">監督學習</span>更好的性能。常見的<span class="term-zh">半監督學習</span>方法包括<span class="term-zh">自訓練</span> (<span class="term-en-full">Self-training</span>)、<span class="term-zh">協同訓練</span> (<span class="term-en-full">Co-training</span>)、生成模型方法、基於圖的方法等。</div>
                     <br>
                     <img src="image/Semi-supervised Learning.png" class="responsive-img">
                 </div>
            </div>

            <!-- Question 48 -->
            <div class="question-card" data-direction="3" data-stars="1">
                 <div class="question-header">
                     <div class="question-id">#48</div>
                     <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content"><span class="term-zh">交叉熵損失</span> (<span class="term-en-full">Cross-Entropy Loss</span>) 通常用於優化哪類<span class="term-zh">機器學習</span>模型？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">迴歸模型</span></div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">分類模型</span>（特別是輸出機率的模型）</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text"><span class="term-zh">分群模型</span></div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">降維模型</span></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="term-zh">交叉熵損失</span>衡量的是模型預測的類別<span class="highlight-keyword">機率分佈</span>與真實的類別分佈（通常是 <span class="term-zh">one-hot</span> 向量）之間的差異。因此，它特別適用於<span class="highlight-keyword">分類問題</span>的場景，尤其是當模型的輸出是各個類別的<span class="highlight-keyword">機率</span>時（例如，通過 <span class="term-en-full">Softmax</span> 或 <span class="term-en-full">Sigmoid</span> 函數得到）。最小化<span class="term-zh">交叉熵損失</span>可以驅使模型輸出的機率分佈盡可能地接近真實的類別分佈。例如，<span class="term-zh">邏輯回歸</span>和<span class="term-zh">深度學習</span>中的<span class="term-zh">分類</span>任務普遍使用<span class="term-zh">交叉熵</span>作為<span class="term-zh">損失函數</span>。</div>
                     <br>
                     <img src="image/Cross-Entropy Loss.png" class="responsive-img">
                 </div>
            </div>

            <!-- Question 49 -->
            <div class="question-card" data-direction="6" data-stars="1">
                <div class="question-header">
                    <div class="question-id">#49</div>
                    <div class="question-frequency">★</div>
                </div>
                <div class="question-content"><span class="term-zh">模型選擇</span> (<span class="term-en-full">Model Selection</span>) 的目的是？</div>
                <div class="options-container">
                    <div class="option-item " data-option="A">
                        <div class="option-label">A</div>
                        <div class="option-text">選擇訓練速度最快的模型。</div>
                    </div>
                    <div class="option-item correct" data-option="B">
                        <div class="option-label">B</div>
                        <div class="option-text">從一組候選模型中，選擇在<span class="highlight-keyword">未見數據</span>上預期<span class="highlight-keyword">表現最好</span>（<span class="highlight-keyword">泛化能力最強</span>）的模型。</div>
                    </div>
                    <div class="option-item " data-option="C">
                        <div class="option-label">C</div>
                        <div class="option-text">選擇參數數量最多的模型。</div>
                    </div>
                    <div class="option-item " data-option="D">
                        <div class="option-label">D</div>
                        <div class="option-text">選擇在<span class="term-zh">訓練集</span>上誤差最小的模型。</div>
                    </div>
                </div>
                <div class="explanation-container">
                    <div class="explanation-header">答案解析</div>
                    <div class="explanation-content">在解決一個<span class="term-zh">機器學習</span>問題時，通常有多種不同的算法或模型架構可供選擇（例如，<span class="term-zh">線性模型</span>、<span class="term-zh">決策樹</span>、<span class="term-en-abbr">SVM</span>、<span class="term-zh">神經網路</span>等），或者同一種模型可以有不同的<span class="term-zh">超參數</span>配置。<span class="highlight-keyword">模型選擇</span>的過程就是比較這些不同的候選模型，並選出那個預期在未來的<span class="highlight-keyword">新數據</span>上能夠<span class="highlight-keyword">表現最好</span>的模型。這通常通過在<span class="highlight-keyword">驗證集</span>上評估各個模型的<span class="highlight-keyword">泛化性能</span>（例如，使用<span class="term-zh">交叉驗證</span>）來完成，而不是僅僅基於<span class="term-zh">訓練集</span>上的性能（因為那可能導致選擇<span class="term-zh">過擬合</span>的模型）。<span class="term-zh">模型選擇</span>需要在模型的複雜度（可能導致<span class="term-zh">過擬合</span>）和簡單度（可能導致<span class="term-zh">欠擬合</span>）之間找到平衡。</div>
                    <br>
                    <img src="image/Model Selection.jpg" class="responsive-img">
                </div>
            </div>

            <!-- Question 50 -->
            <div class="question-card" data-direction="7" data-stars="1">
                 <div class="question-header">
                     <div class="question-id">#50</div>
                     <div class="question-frequency">★</div>
                 </div>
                 <div class="question-content">將<span class="term-zh">日期時間特徵</span>（例如 "2023-10-27 10:30:00"）轉換為多個數值特徵（如年、月、日、星期幾、小時等）的過程屬於？</div>
                 <div class="options-container">
                     <div class="option-item " data-option="A"><div class="option-label">A</div><div class="option-text"><span class="term-zh">數據清洗</span></div></div>
                     <div class="option-item correct" data-option="B"><div class="option-label">B</div><div class="option-text"><span class="highlight-keyword">特徵工程</span> (<span class="term-en-full">Feature Engineering</span>)</div></div>
                     <div class="option-item " data-option="C"><div class="option-label">C</div><div class="option-text">模型評估</div></div>
                     <div class="option-item " data-option="D"><div class="option-label">D</div><div class="option-text"><span class="term-zh">降維</span></div></div>
                 </div>
                 <div class="explanation-container">
                     <div class="explanation-header">答案解析</div>
                     <div class="explanation-content"><span class="highlight-keyword">特徵工程</span>是指利用<span class="term-zh">領域知識</span>和數據分析技術，從原始數據中<span class="highlight-keyword">創建、轉換或選擇</span>最能代表潛在問題的<span class="highlight-keyword">特徵</span>，以提高<span class="term-zh">機器學習模型</span>性能的過程。原始的<span class="term-zh">日期時間戳</span>通常不適合直接作為模型的輸入。將其<span class="highlight-keyword">分解</span>為更具體的、可能有預測意義的數值或類別特徵（如年份、月份、星期幾、是否為週末、小時等）是一種常見的<span class="term-zh">特徵工程</span>手段，使得模型能夠更容易地捕捉時間相關的模式（如季節性、週期性）。</div>
                     <br>
                     <img src="image/Feature-Engineering.png" class="responsive-img">
                 </div>
            </div>

        </div>

        <div id="noResultsMessage" style="display: none; text-align: center; padding: 20px; color: rgb(119, 119, 119);">沒有找到符合條件的題目。</div>

        <div class="back-to-top" id="backToTop">↑</div>
    </div>

    <!-- Script section remains unchanged -->
    <script>
        let explanationsVisible = true; // Explanations start visible
        let answersVisible = true; // Answers start visible
        let correctAnswers = []; // Store information about correct answers
        const allQuestions = document.querySelectorAll(".question-card"); // Cache all questions

        // Progress bar
        const progressBar = document.getElementById("progressBar");
        window.onscroll = function() {
            updateProgressBar();
            toggleBackToTopButton();
        };

        function updateProgressBar() {
            let winScroll = document.body.scrollTop || document.documentElement.scrollTop;
            let height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
             if (height > 0) {
                 let scrolled = (winScroll / height) * 100;
                 progressBar.style.width = scrolled + "%";
             } else {
                  progressBar.style.width = "0%"; // Handle case where content height is less than viewport
             }
        }

        // Back to top button
        const backToTopButton = document.getElementById("backToTop");

        function toggleBackToTopButton() {
             if (document.body.scrollTop > 100 || document.documentElement.scrollTop > 100) {
                backToTopButton.style.display = "flex";
            } else {
                backToTopButton.style.display = "none";
            }
        }

        backToTopButton.addEventListener("click", function() {
            window.scrollTo({top: 0, behavior: 'smooth'});
        });

        // Filter elements
        const directionFilter = document.getElementById("directionFilter");
        const starFilter = document.getElementById("starFilter");
        const searchInput = document.getElementById("searchInput");
        const searchButton = document.getElementById("searchButton");
        const noResultsMessage = document.getElementById('noResultsMessage');

        // Filter by direction (called from direction items)
        function filterByDirection(directionNumber) {
            directionFilter.value = directionNumber === 'all' ? 'all' : String(directionNumber);
             // Reset search when direction is clicked
            searchInput.value = "";
            runFiltersAndSearch();
        }

        // Event listeners for filters and search
        directionFilter.addEventListener("change", runFiltersAndSearch);
        starFilter.addEventListener("change", runFiltersAndSearch);
        searchButton.addEventListener("click", runFiltersAndSearch);
        searchInput.addEventListener("keyup", function(event) {
            // Trigger search on Enter key or when input is cleared
            if (event.key === "Enter" || searchInput.value === "") {
                 runFiltersAndSearch();
            }
        });

        // Combined filter and search function
        function runFiltersAndSearch() {
            let direction = directionFilter.value;
            let stars = starFilter.value;
            let searchText = searchInput.value.toLowerCase().trim();
            let anyVisible = false;

            allQuestions.forEach(function(question) {
                const matchesDirection = (direction === "all" || question.dataset.direction === direction);
                const matchesStars = (stars === "all" || question.dataset.stars === stars);
                const questionText = question.textContent.toLowerCase();
                const matchesSearch = (searchText === "" || questionText.includes(searchText));

                if (matchesDirection && matchesStars && matchesSearch) {
                    question.style.display = "block";
                    anyVisible = true;
                } else {
                    question.style.display = "none";
                }
            });

            // Show or hide the 'no results' message
            if (noResultsMessage) {
                 noResultsMessage.style.display = anyVisible ? 'none' : 'block';
                 if (!anyVisible) { // Update message if nothing is visible
                     if(searchText !== "") {
                          noResultsMessage.textContent = '沒有找到符合所有篩選條件和搜尋關鍵字的題目。';
                     } else {
                          noResultsMessage.textContent = '沒有找到符合條件的題目。';
                     }
                 }
            }
             // Update progress bar after filtering potentially changes page height
             updateProgressBar();
        }


        // Toggle explanations visibility
        const toggleExplanationsButton = document.getElementById("toggleExplanations");
        toggleExplanationsButton.addEventListener("click", function() {
            let explanations = document.querySelectorAll(".explanation-container");
            explanationsVisible = !explanationsVisible;

            explanations.forEach(function(explanation) {
                explanation.style.display = explanationsVisible ? "block" : "none";
            });

            toggleExplanationsButton.textContent = explanationsVisible ? "隱藏全部解析" : "顯示全部解析";
        });

        // Click options (no grading logic, just for potential interaction feedback)


        // Initialize correct answers data
        function initializeCorrectAnswers() {
            let correctOptions = document.querySelectorAll(".option-item.correct");
            correctAnswers = [];
            
            correctOptions.forEach(function(option) {
                let strongElements = option.querySelectorAll("strong[style*='background-color'], .highlight-keyword, .term-en-full, .term-zh");
                let strongData = [];
                
                strongElements.forEach(function(strong) {
                    strongData.push({
                        element: strong,
                        originalStyle: strong.getAttribute('style'),
                        text: strong.textContent
                    });
                });
                
                correctAnswers.push({
                    element: option,
                    strongElements: strongData
                });
            });
        }

        // Toggle answers visibility
        document.getElementById("toggleAnswers").addEventListener("click", function() {
            answersVisible = !answersVisible;
            let button = document.getElementById("toggleAnswers");
              correctAnswers.forEach(function(correctAnswer) {
                if (answersVisible) {
                    // Show answers: restore correct class and strong styling
                    correctAnswer.element.classList.add("correct");
                    correctAnswer.strongElements.forEach(function(strongData) {
                        if (strongData.element.classList.contains('highlight-keyword') || 
                            strongData.element.classList.contains('term-en-full') || 
                            strongData.element.classList.contains('term-zh')) {
                            // For CSS class elements, restore the classes
                            strongData.element.style.backgroundColor = "#ffff0030";
                            strongData.element.style.fontWeight = "bold";
                        } else {
                            // For inline style elements
                            strongData.element.style.backgroundColor = "#ffff0030";
                            strongData.element.style.fontWeight = "bold";
                        }
                    });
                } else {
                    // Hide answers: remove correct class and strong styling
                    correctAnswer.element.classList.remove("correct");
                    correctAnswer.strongElements.forEach(function(strongData) {
                        if (strongData.element.classList.contains('highlight-keyword') || 
                            strongData.element.classList.contains('term-en-full') || 
                            strongData.element.classList.contains('term-zh')) {
                            // For CSS class elements, override the class styles
                            strongData.element.style.backgroundColor = "transparent";
                            strongData.element.style.fontWeight = "normal";
                        } else {
                            // For inline style elements
                            strongData.element.style.backgroundColor = "";
                            strongData.element.style.fontWeight = "normal";
                        }
                    });
                }
            });
            
            button.textContent = answersVisible ? "隱藏全部解答" : "顯示全部解答";
        });        let options = document.querySelectorAll(".option-item");
        options.forEach(function(option) {
            option.addEventListener("click", function() {
                // Optional: Add visual feedback on click if desired
            });
        });

         // Initial setup
         
         initializeCorrectAnswers(); // Initialize correct answers data
         toggleBackToTopButton(); // Check initial scroll position
         updateProgressBar(); // Set initial progress bar state
         runFiltersAndSearch(); // Apply default filters (all/all) on load
         // Set initial state for toggle button text
         toggleExplanationsButton.textContent = explanationsVisible ? "隱藏全部解析" : "顯示全部解析";
         // Ensure the message div exists and setup initial text
        if (!document.getElementById('noResultsMessage')) {
             const questionsContainer = document.getElementById('questionsContainer');
             const messageDiv = document.createElement('div');
             messageDiv.id = 'noResultsMessage';
             messageDiv.style.display = 'none';
             messageDiv.style.textAlign = 'center';
             messageDiv.style.marginTop = '20px';
             messageDiv.style.padding = '20px'; // Added padding
             messageDiv.style.color = '#777'; // Kept grey for less critical messages
             questionsContainer.insertAdjacentElement('afterend', messageDiv);
        }
         // Set initial message
        document.getElementById('noResultsMessage').textContent = '沒有找到符合條件的題目。';

    </script>
</body>
</html>